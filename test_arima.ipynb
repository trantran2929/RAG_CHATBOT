{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d2e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings, math, re\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5293f820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ohlc(symbol: str, start=\"2025-10-20\", end=None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Trả về DataFrame: ['date','open','high','low','close','volume'] (tăng dần theo date)\n",
    "    - Ưu tiên: vnstock3\n",
    "    - Fallback: yfinance (mã VN -> 'VCB.VN'; chỉ số -> '^VNINDEX')\n",
    "    \"\"\"\n",
    "    # 1) vnstock3\n",
    "    try:\n",
    "        from vnstock3 import Vnstock\n",
    "        api = Vnstock()\n",
    "        df = api.stock(symbol=symbol).historical_data(\n",
    "            start=start, end=end, interval=\"1D\", type=\"stock\"\n",
    "        )\n",
    "        df = df.rename(columns={\"time\": \"date\"})\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.sort_values(\"date\")\n",
    "        return df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].copy()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # 2) yfinance\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        if symbol.upper() in {\"VNINDEX\", \"^VNINDEX\"}:\n",
    "            yf_symbol = \"^VNINDEX\"\n",
    "        else:\n",
    "            yf_symbol = f\"{symbol}.VN\"\n",
    "        hist = yf.Ticker(yf_symbol).history(\n",
    "            start=start, end=end, interval=\"1d\", auto_adjust=False\n",
    "        )\n",
    "        if hist is None or len(hist) == 0:\n",
    "            raise RuntimeError(f\"Yahoo Finance không có dữ liệu cho {yf_symbol}\")\n",
    "        hist = hist.reset_index().rename(columns={\n",
    "            \"Date\":\"date\", \"Open\":\"open\", \"High\":\"high\",\n",
    "            \"Low\":\"low\", \"Close\":\"close\", \"Volume\":\"volume\"\n",
    "        })\n",
    "        hist[\"date\"] = pd.to_datetime(hist[\"date\"])\n",
    "        hist[\"volume\"] = hist[\"volume\"].fillna(0)\n",
    "        df = hist[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].sort_values(\"date\").copy()\n",
    "        df = df.dropna(subset=[\"close\"])\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\n",
    "            \"Không tải được dữ liệu bằng vnstock3 hoặc yfinance. Kiểm tra mã/Internet.\"\n",
    "        ) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3db9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def test_fetch_prices(symbol=\"VCB\", start=None, end=None, min_len=250, max_years_back=10):\n",
    "    \"\"\"\n",
    "    Tải dữ liệu giá cho symbol. Nếu start quá gần hiện tại và chuỗi ngắn,\n",
    "    tự động lùi mốc start lùi dần 1,2,3,5,10 năm (tối đa max_years_back) cho đến khi đủ min_len.\n",
    "    \"\"\"\n",
    "    # nếu người dùng không truyền start -> tự thử lùi dần\n",
    "    tried = []\n",
    "    if start is None:\n",
    "        candidates_years = [1, 2, 3, 5, max_years_back]\n",
    "        for yrs in candidates_years:\n",
    "            s = (pd.Timestamp.today().normalize() - pd.DateOffset(years=yrs)).strftime(\"%Y-%m-%d\")\n",
    "            df = load_ohlc(symbol, start=s, end=end)\n",
    "            tried.append((s, len(df)))\n",
    "            if len(df) >= min_len:\n",
    "                assert set([\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]).issubset(df.columns)\n",
    "                print(f\"[OK] Tải {symbol}: {len(df)} dòng, {df['date'].min().date()} → {df['date'].max().date()} (start={s})\")\n",
    "                return df\n",
    "        # nếu vẫn không đủ\n",
    "        raise AssertionError(f\"Không đủ dữ liệu (>= {min_len} phiên). Các mốc đã thử: {tried}\")\n",
    "    else:\n",
    "        # có start do người dùng chỉ định: nếu ngắn -> tự lùi thêm\n",
    "        df = load_ohlc(symbol, start=start, end=end)\n",
    "        if len(df) >= min_len:\n",
    "            assert set([\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]).issubset(df.columns)\n",
    "            print(f\"[OK] Tải {symbol}: {len(df)} dòng, {df['date'].min().date()} → {df['date'].max().date()} (start={start})\")\n",
    "            return df\n",
    "        # lùi thêm tối đa max_years_back năm\n",
    "        base = pd.to_datetime(start)\n",
    "        for yrs in [1, 2, 3, 5, max_years_back]:\n",
    "            s = (base - pd.DateOffset(years=yrs)).strftime(\"%Y-%m-%d\")\n",
    "            df2 = load_ohlc(symbol, start=s, end=end)\n",
    "            tried.append((s, len(df2)))\n",
    "            if len(df2) >= min_len:\n",
    "                assert set([\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]).issubset(df2.columns)\n",
    "                print(f\"[OK] Tải {symbol}: {len(df2)} dòng, {df2['date'].min().date()} → {df2['date'].max().date()} (start={s})\")\n",
    "                return df2\n",
    "        raise AssertionError(f\"Không đủ dữ liệu (>= {min_len} phiên) kể cả khi lùi từ {start}. Các mốc đã thử: {tried}\")\n",
    "    \n",
    "df = test_fetch_prices(symbol=\"VCB\", start=None, min_len=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde9bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_log_returns(price: pd.Series) -> pd.Series:\n",
    "    \"\"\"r_t = log(P_t / P_{t-1}). Điền phần tử đầu bằng mean để tránh NaN.\"\"\"\n",
    "    r = np.log(price / price.shift(1))\n",
    "    if r.isna().any():\n",
    "        if len(r) > 1:\n",
    "            r.iloc[0] = r.iloc[1:].mean()\n",
    "        else:\n",
    "            r.iloc[0] = 0.0\n",
    "    return r\n",
    "\n",
    "def returns_to_price(last_price: float, returns_forecast: np.ndarray) -> pd.Series:\n",
    "    \"\"\"Chuyển chuỗi returns dự báo -> đường giá dự báo, tính từ last_price.\"\"\"\n",
    "    cum = np.cumsum(returns_forecast)\n",
    "    return pd.Series(last_price * np.exp(cum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60053a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_preprocess_to_returns(df: pd.DataFrame):\n",
    "    \"\"\"Test 2: chuyển giá -> returns và kiểm tra dừng cơ bản.\"\"\"\n",
    "    r = to_log_returns(df[\"close\"])\n",
    "    assert len(r) == len(df), \"Returns không khớp số điểm.\"\n",
    "    print(f\"[OK] Tạo returns: mean={r.mean():.6f}, std={r.std():.6f}\")\n",
    "    return r\n",
    "\n",
    "r = test_preprocess_to_returns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e65d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Chọn mô hình ARIMA tự động\n",
    "#    - Có pmdarima: dùng auto_arima(stepwise)\n",
    "#    - Không có pmdarima: fallback SARIMAX (grid nhỏ theo AIC)\n",
    "# =========================================================\n",
    "try:\n",
    "    from pmdarima import auto_arima as _pm_auto_arima\n",
    "    HAVE_PMDA = True\n",
    "except Exception:\n",
    "    HAVE_PMDA = False\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "class _ARIMAWrapper:\n",
    "    \"\"\"Chuẩn hoá API: có .order và .predict(n_periods=...).\"\"\"\n",
    "    def __init__(self, fitted, order):\n",
    "        self.fitted = fitted\n",
    "        self.order = order\n",
    "    def predict(self, n_periods: int) -> np.ndarray:\n",
    "        fc = self.fitted.get_forecast(steps=n_periods)\n",
    "        return fc.predicted_mean.values\n",
    "\n",
    "def auto_arima_select(y: pd.Series, d: int = 0, max_p: int = 5, max_q: int = 5) -> _ARIMAWrapper:\n",
    "    \"\"\"Tự chọn (p,d,q). Ưu tiên pmdarima; nếu không có dùng grid SARIMAX theo AIC.\"\"\"\n",
    "    y = pd.Series(y).astype(float)\n",
    "    if HAVE_PMDA:\n",
    "        model = _pm_auto_arima(\n",
    "            y, d=d, start_p=0, start_q=0, max_p=max_p, max_q=max_q,\n",
    "            seasonal=False, stepwise=True,\n",
    "            suppress_warnings=True, error_action=\"ignore\", maxiter=200\n",
    "        )\n",
    "        # Bọc lại cho đồng nhất API\n",
    "        class _PMWrap:\n",
    "            def __init__(self, m): self.m = m; self.order = m.order\n",
    "            def predict(self, n_periods): return self.m.predict(n_periods=n_periods)\n",
    "        return _PMWrap(model)\n",
    "\n",
    "    # Fallback: SARIMAX grid nhỏ\n",
    "    best = {\"aic\": np.inf, \"fit\": None, \"order\": None}\n",
    "    for p in range(max_p+1):\n",
    "        for q in range(max_q+1):\n",
    "            try:\n",
    "                res = SARIMAX(\n",
    "                    y, order=(p,d,q), seasonal_order=(0,0,0,0),\n",
    "                    trend=\"n\", enforce_stationarity=False, enforce_invertibility=False\n",
    "                ).fit(disp=False)\n",
    "                if res.aic < best[\"aic\"]:\n",
    "                    best = {\"aic\": res.aic, \"fit\": res, \"order\": (p,d,q)}\n",
    "            except Exception:\n",
    "                pass\n",
    "    if best[\"fit\"] is None:\n",
    "        raise RuntimeError(\"Không fit được ARIMA với lưới (p,q). Hãy giảm max_p/max_q hoặc kiểm tra dữ liệu.\")\n",
    "    return _ARIMAWrapper(best[\"fit\"], best[\"order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_arima_on_returns(r_train: pd.Series, d: int = 0, max_p: int = 5, max_q: int = 5):\n",
    "    \"\"\"Chọn và fit ARIMA trên chuỗi returns train.\"\"\"\n",
    "    model = auto_arima_select(r_train, d=d, max_p=max_p, max_q=max_q)\n",
    "    return model  # có .order, .predict\n",
    "\n",
    "def forecast_prices_from_returns(model, last_train_price: float, steps: int) -> pd.Series:\n",
    "    \"\"\"Dự báo returns bằng model -> chuyển về giá.\"\"\"\n",
    "    fc_r = model.predict(n_periods=steps)\n",
    "    fc_p = returns_to_price(last_train_price, fc_r)\n",
    "    return fc_p\n",
    "\n",
    "def evaluate_forecast(y_true_price: pd.Series, y_pred_price: pd.Series) -> dict:\n",
    "    \"\"\"RMSE/MAE/MAPE + Directional Accuracy (đúng chiều).\"\"\"\n",
    "    yt, yp = np.asarray(y_true_price), np.asarray(y_pred_price)\n",
    "    rmse = math.sqrt(np.mean((yt - yp) ** 2))\n",
    "    mae  = float(np.mean(np.abs(yt - yp)))\n",
    "    mape = float(np.mean(np.abs((yt - yp) / np.clip(np.abs(yt), 1e-9, None))))\n",
    "    # đúng chiều tăng/giảm\n",
    "    true_diff = yt[1:] - yt[:-1]\n",
    "    pred_diff = yp[1:] - yp[:-1]\n",
    "    dir_acc = float((np.sign(true_diff) == np.sign(pred_diff)).mean()) if len(yt) > 1 else np.nan\n",
    "    return {\"RMSE\": rmse, \"MAE\": mae, \"MAPE\": mape, \"DIR_ACC\": dir_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6695c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_arima(r: pd.Series, train_ratio: float = 0.8, d: int = 0, max_p: int = 5, max_q: int = 5):\n",
    "    \"\"\"Test 3: tách train/test returns và train ARIMA.\"\"\"\n",
    "    n = len(r); n_train = max(200, int(n * train_ratio))\n",
    "    r_train, r_test = r.iloc[:n_train], r.iloc[n_train:]\n",
    "    model = train_arima_on_returns(r_train, d=d, max_p=max_p, max_q=max_q)\n",
    "    print(f\"[OK] Chọn ARIMA order={getattr(model, 'order', None)}, train_len={len(r_train)}, test_len={len(r_test)}\")\n",
    "    return model, r_train, r_test\n",
    "\n",
    "model, r_train, r_test = test_train_arima(r, train_ratio=0.8, d=0, max_p=5, max_q=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb910e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forecast_future_prices(df: pd.DataFrame, r_train: pd.Series, r_test: pd.Series, model):\n",
    "    \"\"\"Test 4: dự báo giá test từ returns model và đánh giá.\"\"\"\n",
    "    # Giá thật: chia train/test cùng index\n",
    "    n_train = len(r_train)\n",
    "    price_train = df[\"close\"].iloc[:n_train]\n",
    "    price_test  = df[\"close\"].iloc[n_train:]\n",
    "\n",
    "    last_train_price = float(price_train.iloc[-1])\n",
    "    pred_price_test = forecast_prices_from_returns(model, last_train_price, steps=len(r_test))\n",
    "    pred_price_test.index = price_test.index  # căn index cho đẹp (nếu cần)\n",
    "\n",
    "    metrics = evaluate_forecast(price_test, pred_price_test)\n",
    "    print(f\"[OK] Đánh giá: RMSE={metrics['RMSE']:.4f}  MAE={metrics['MAE']:.4f}  \"\n",
    "          f\"MAPE={metrics['MAPE']*100:.2f}%  DIR_ACC={metrics['DIR_ACC']*100:.1f}%\")\n",
    "\n",
    "    # Vẽ nhanh phần cuối chuỗi\n",
    "    tail = 180\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(df[\"date\"].iloc[-(len(price_test)+tail):], df[\"close\"].iloc[-(len(price_test)+tail):], label=\"Giá thực tế\")\n",
    "    plt.plot(df[\"date\"].iloc[n_train:], pred_price_test.values, linestyle=\"--\", label=\"Dự báo (ARIMA)\")\n",
    "    plt.title(\"So sánh giá thực tế vs. dự báo (ARIMA trên returns)\")\n",
    "    plt.xlabel(\"Ngày\"); plt.ylabel(\"Giá đóng cửa\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    return pred_price_test, metrics\n",
    "\n",
    "# Test 4: dự báo & đánh giá trên tập test\n",
    "pred_price_test, metrics = test_forecast_future_prices(df, r_train, r_test, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4587e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forecast_next_days(df: pd.DataFrame, model, future_days: int = 5):\n",
    "    \"\"\"Test 5: dự báo K phiên tới (không có giá thật để chấm điểm).\"\"\"\n",
    "    last_price = float(df[\"close\"].iloc[-1])\n",
    "    pred_next = forecast_prices_from_returns(model, last_price, steps=future_days)\n",
    "    # Tạo index là ngày làm việc kế tiếp\n",
    "    future_idx = pd.bdate_range(start=df[\"date\"].iloc[-1] + pd.Timedelta(days=1), periods=future_days)\n",
    "    pred_next.index = future_idx\n",
    "    print(f\"[OK] Dự báo {future_days} phiên tới:\")\n",
    "    print(pred_next.round(2))\n",
    "    return pred_next\n",
    "\n",
    "# Test 5: dự báo K phiên tới\n",
    "pred_price_test = test_forecast_next_days(df, model, future_days=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29cd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings, math, numpy as np, pandas as pd, datetime as dt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ===================== Thời gian & phiên =====================\n",
    "ICT = dt.timezone(dt.timedelta(hours=7))  # Asia/Ho_Chi_Minh\n",
    "\n",
    "def is_vn_trading_time(now: dt.datetime | None = None) -> bool:\n",
    "    \"\"\"HOSE: 09:00–11:30, 13:00–15:00 (Mon–Fri, ICT).\"\"\"\n",
    "    now = now.astimezone(ICT) if now else dt.datetime.now(ICT)\n",
    "    if now.weekday() >= 5:\n",
    "        return False\n",
    "    t = now.time()\n",
    "    return (dt.time(9,0) <= t < dt.time(11,30)) or (dt.time(13,0) <= t < dt.time(15,0))\n",
    "\n",
    "# ===================== Load dữ liệu =====================\n",
    "def load_daily_ohlc(symbol: str, start=\"2023-01-01\", end=None) -> pd.DataFrame:\n",
    "    \"\"\"Daily OHLC: ưu tiên vnstock3; fallback yfinance (VCB->VCB.VN; VNINDEX->^VNINDEX).\"\"\"\n",
    "    # vnstock3\n",
    "    try:\n",
    "        from vnstock3 import Vnstock\n",
    "        api = Vnstock()\n",
    "        df = api.stock(symbol=symbol).historical_data(\n",
    "            start=start, end=end, interval=\"1D\", type=\"stock\"\n",
    "        ).rename(columns={\"time\":\"date\"})\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "        df = df.sort_values(\"date\")\n",
    "        return df[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].dropna(subset=[\"close\"]).copy()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # yfinance\n",
    "    import yfinance as yf\n",
    "    yf_symbol = \"^VNINDEX\" if symbol.upper() in {\"VNINDEX\",\"^VNINDEX\"} else f\"{symbol}.VN\"\n",
    "    hist = yf.Ticker(yf_symbol).history(start=start, end=end, interval=\"1d\", auto_adjust=False)\n",
    "    if hist is None or len(hist)==0:\n",
    "        raise RuntimeError(f\"Không có daily OHLC cho {symbol}\")\n",
    "    hist = hist.reset_index().rename(columns={\"Date\":\"date\",\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "    hist[\"date\"] = pd.to_datetime(hist[\"date\"])\n",
    "    hist[\"volume\"] = hist[\"volume\"].fillna(0)\n",
    "    return hist[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].sort_values(\"date\").dropna(subset=[\"close\"]).copy()\n",
    "\n",
    "def load_intraday(symbol: str, interval=\"5m\", period=\"1d\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Intraday OHLCV từ yfinance. Trả về ['dt','open','high','low','close','volume'] trong ngày hiện tại (ICT).\n",
    "    Có thể không có với .VN -> caller nên fallback daily.\n",
    "    \"\"\"\n",
    "    import yfinance as yf\n",
    "    yf_symbol = \"^VNINDEX\" if symbol.upper() in {\"VNINDEX\",\"^VNINDEX\"} else f\"{symbol}.VN\"\n",
    "    hist = yf.Ticker(yf_symbol).history(period=period, interval=interval, auto_adjust=False)\n",
    "    if hist is None or len(hist)==0:\n",
    "        raise RuntimeError(f\"Không có intraday cho {symbol} ({yf_symbol})\")\n",
    "    hist = hist.reset_index().rename(columns={\"Datetime\":\"dt\",\"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Volume\":\"volume\"})\n",
    "    hist[\"dt\"] = pd.to_datetime(hist[\"dt\"])\n",
    "    # yfinance intraday thường là UTC → chuyển về ICT nếu có tz info, nếu không thì localize\n",
    "    if hist[\"dt\"].dt.tz is not None:\n",
    "        hist[\"dt\"] = hist[\"dt\"].dt.tz_convert(ICT)\n",
    "    else:\n",
    "        hist[\"dt\"] = hist[\"dt\"].dt.tz_localize(ICT)\n",
    "    today = dt.datetime.now(ICT).date()\n",
    "    hist = hist[hist[\"dt\"].dt.date == today]\n",
    "    if len(hist) == 0:\n",
    "        raise RuntimeError(\"Intraday không có dữ liệu của hôm nay.\")\n",
    "    return hist[[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"]].sort_values(\"dt\").dropna(subset=[\"close\"]).copy()\n",
    "\n",
    "# ===================== Returns helpers =====================\n",
    "def to_log_returns(series: pd.Series) -> pd.Series:\n",
    "    r = np.log(series/series.shift(1))\n",
    "    if r.isna().any():\n",
    "        if len(r) > 1:\n",
    "            r.iloc[0] = r.iloc[1:].mean()\n",
    "        else:\n",
    "            r.iloc[0] = 0.0\n",
    "    return r\n",
    "\n",
    "def returns_to_price(last_price: float, r_fore: np.ndarray) -> pd.Series:\n",
    "    return pd.Series(last_price * np.exp(np.cumsum(r_fore)))\n",
    "\n",
    "# ===================== ARIMA chọn theo AIC (thử trend) =====================\n",
    "def arima_select_fit(y: pd.Series, d=0, max_p=5, max_q=5, trends=(\"n\",\"c\")):\n",
    "    \"\"\"\n",
    "    Chọn (p,d,q) + trend theo AIC. Dùng SARIMAX non-seasonal.\n",
    "    Trả về (fitted_model, order, trend).\n",
    "    \"\"\"\n",
    "    best = {\"aic\": np.inf, \"fit\": None, \"order\": None, \"trend\": None}\n",
    "    y = pd.Series(y).astype(float)\n",
    "    for tr in trends:\n",
    "        for p in range(max_p+1):\n",
    "            for q in range(max_q+1):\n",
    "                try:\n",
    "                    res = SARIMAX(y, order=(p,d,q),\n",
    "                                  seasonal_order=(0,0,0,0),\n",
    "                                  trend=tr,\n",
    "                                  enforce_stationarity=False,\n",
    "                                  enforce_invertibility=False).fit(disp=False)\n",
    "                    if res.aic < best[\"aic\"]:\n",
    "                        best = {\"aic\": res.aic, \"fit\": res, \"order\": (p,d,q), \"trend\": tr}\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best[\"fit\"] is None:\n",
    "        raise RuntimeError(\"ARIMA grid không hội tụ — thử giảm max_p/max_q hoặc kiểm tra dữ liệu.\")\n",
    "    return best[\"fit\"], best[\"order\"], best[\"trend\"]\n",
    "\n",
    "def arima_select_best_of_returns_or_logprice(close: pd.Series, max_p=5, max_q=5):\n",
    "    \"\"\"\n",
    "    So sánh 2 ứng viên:\n",
    "      - returns (d=0, trend in {'n','c'})\n",
    "      - log-price (d=1, trend in {'n','c'})\n",
    "    Chọn mô hình có AIC thấp nhất. Trả về (kind, fit, order, trend, aic).\n",
    "    \"\"\"\n",
    "    cand = []\n",
    "    # (A) returns\n",
    "    r = to_log_returns(close)\n",
    "    fit_r, ord_r, tr_r = arima_select_fit(r, d=0, max_p=max_p, max_q=max_q, trends=(\"n\",\"c\"))\n",
    "    cand.append((\"returns\", fit_r, ord_r, tr_r, fit_r.aic))\n",
    "    # (B) log-price\n",
    "    lp = np.log(close)\n",
    "    fit_l, ord_l, tr_l = arima_select_fit(lp, d=1, max_p=max_p, max_q=max_q, trends=(\"n\",\"c\"))\n",
    "    cand.append((\"logprice\", fit_l, ord_l, tr_l, fit_l.aic))\n",
    "    cand.sort(key=lambda x: x[4])\n",
    "    return cand[0]\n",
    "\n",
    "# ===================== Trong phiên =====================\n",
    "def predict_in_session(symbol: str, interval=\"5m\"):\n",
    "    \"\"\"\n",
    "    Lấy intraday hôm nay, fit ARIMA trên returns, dự báo đến hết phiên hiện tại (11:30 hoặc 15:00).\n",
    "    \"\"\"\n",
    "    df = load_intraday(symbol, interval=interval, period=\"1d\")\n",
    "    close = df[\"close\"]\n",
    "    r = to_log_returns(close)\n",
    "\n",
    "    # số bước còn lại\n",
    "    last_dt = df[\"dt\"].iloc[-1]\n",
    "    now_t = last_dt.timetz()\n",
    "    session_end = dt.time(11,30, tzinfo=ICT) if now_t < dt.time(11,30, tzinfo=ICT) else dt.time(15,0, tzinfo=ICT)\n",
    "    step_min = int(interval.replace(\"m\",\"\"))\n",
    "    rem_minutes = ((dt.datetime.combine(last_dt.date(), session_end) -\n",
    "                    dt.datetime.combine(last_dt.date(), now_t)).seconds) // 60\n",
    "    steps = max(1, rem_minutes // step_min)\n",
    "\n",
    "    # ARIMA trên returns (intraday dùng grid nhỏ cho nhanh)\n",
    "    fit, order, trend = arima_select_fit(r, d=0, max_p=3, max_q=3, trends=(\"n\",\"c\"))\n",
    "    r_fore = fit.get_forecast(steps=steps).predicted_mean.values\n",
    "    y_pred = returns_to_price(float(close.iloc[-1]), r_fore)\n",
    "\n",
    "    future_times = pd.date_range(last_dt + pd.Timedelta(minutes=step_min),\n",
    "                                 periods=steps, freq=f\"{step_min}min\", tz=ICT)\n",
    "    y_pred.index = future_times\n",
    "    direction = np.sign(y_pred.values - np.r_[close.iloc[-1], y_pred.values[:-1]])\n",
    "    direction = pd.Series(direction, index=y_pred.index).map({-1:\"↓\", 0:\"=\", 1:\"↑\"})\n",
    "\n",
    "    info = {\"order\": order, \"trend\": trend, \"last_price\": float(close.iloc[-1]), \"pred_until\": future_times[-1]}\n",
    "    print(f\"[Trong phiên] {symbol} | ARIMA{order} trend={trend} | last={info['last_price']:.2f} | đến {info['pred_until']}\")\n",
    "    return df, y_pred, direction, info\n",
    "\n",
    "# ===================== Ngoài giờ =====================\n",
    "def predict_out_of_session(symbol: str, lookback_days=180):\n",
    "    \"\"\"\n",
    "    Daily ~6 tháng gần nhất (tail 120). Chọn tốt nhất giữa returns(d=0) và log-price(d=1),\n",
    "    có trend 'n'/'c'. Dự báo 1 phiên kế tiếp.\n",
    "    \"\"\"\n",
    "    start = (pd.Timestamp.now(ICT) - pd.Timedelta(days=lookback_days)).strftime(\"%Y-%m-%d\")\n",
    "    df = load_daily_ohlc(symbol, start=start)\n",
    "    df = df.tail(120)  # ~6 tháng\n",
    "    close = df[\"close\"]\n",
    "\n",
    "    kind, fit, order, trend, _aic = arima_select_best_of_returns_or_logprice(close, max_p=5, max_q=5)\n",
    "\n",
    "    if kind == \"returns\":\n",
    "        r_fore = fit.get_forecast(steps=1).predicted_mean.values\n",
    "        next_price = returns_to_price(float(close.iloc[-1]), r_fore)\n",
    "    else:\n",
    "        lp_fore = fit.get_forecast(steps=1).predicted_mean.values\n",
    "        next_price = pd.Series(np.exp(lp_fore))\n",
    "\n",
    "    next_bd = pd.bdate_range(start=df[\"date\"].iloc[-1] + pd.Timedelta(days=1), periods=1)\n",
    "    next_price.index = next_bd\n",
    "    direction = \"↑\" if next_price.iloc[0] > close.iloc[-1] else (\"↓\" if next_price.iloc[0] < close.iloc[-1] else \"=\")\n",
    "\n",
    "    info = {\"mode\": kind, \"order\": order, \"trend\": trend, \"last_close\": float(close.iloc[-1]), \"last_close_date\": df[\"date\"].iloc[-1].date()}\n",
    "    print(f\"[Ngoài giờ] {symbol} | {kind.upper()} ARIMA{order} trend={trend} | last={info['last_close']:.2f} ({info['last_close_date']})\")\n",
    "    return df, next_price, direction, info\n",
    "\n",
    "# ===================== Bộ điều phối =====================\n",
    "def smart_predict(symbol: str, interval=\"5m\", lookback_days=180):\n",
    "    \"\"\"\n",
    "    Trong phiên → intraday; ngoài giờ → daily. Nếu intraday lỗi → fallback daily.\n",
    "    \"\"\"\n",
    "    if is_vn_trading_time():\n",
    "        try:\n",
    "            return {\"mode\":\"intraday\", **dict(zip([\"df\",\"pred\",\"direction\",\"info\"], predict_in_session(symbol, interval=interval)))}\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Intraday lỗi ({e}). Fallback sang daily.\")\n",
    "    return {\"mode\":\"daily\", **dict(zip([\"df\",\"pred\",\"direction\",\"info\"], predict_out_of_session(symbol, lookback_days=lookback_days)))}\n",
    "\n",
    "# ===================== Ví dụ dùng =====================\n",
    "# Gọi tự động theo thời điểm:\n",
    "result = smart_predict(\"VCB\", interval=\"5m\", lookback_days=180)\n",
    "if result[\"mode\"] == \"intraday\":\n",
    "    display(result[\"pred\"].round(2).to_frame(\"pred_price\"))\n",
    "    display(result[\"direction\"].to_frame(\"dir\"))\n",
    "else:\n",
    "    print(\"Dự báo phiên kế tiếp:\")\n",
    "    print(result[\"pred\"].round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f85fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import warnings, numpy as np, pandas as pd, datetime as dt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ===================== Thời gian & phiên =====================\n",
    "ICT = dt.timezone(dt.timedelta(hours=7))   # Asia/Ho_Chi_Minh\n",
    "VN_HOLIDAYS = set()  # có thể thêm \"2025-04-30\",\"2025-05-01\",\"2025-09-02\",...\n",
    "\n",
    "def is_vn_holiday(d: dt.date) -> bool:\n",
    "    return d.strftime(\"%Y-%m-%d\") in VN_HOLIDAYS\n",
    "\n",
    "def is_vn_trading_time(now: dt.datetime | None = None) -> bool:\n",
    "    \"\"\"HOSE: 09:00–11:30, 13:00–15:00 (Mon–Fri, ICT)\"\"\"\n",
    "    now = now.astimezone(ICT) if now else dt.datetime.now(ICT)\n",
    "    if now.weekday() >= 5 or is_vn_holiday(now.date()):\n",
    "        return False\n",
    "    t = now.time()\n",
    "    return (dt.time(9,0) <= t < dt.time(11,30)) or (dt.time(13,0) <= t < dt.time(15,0))\n",
    "\n",
    "def next_trading_day(d: dt.date | pd.Timestamp) -> dt.date:\n",
    "    if isinstance(d, pd.Timestamp):\n",
    "        d = d.date()\n",
    "    nxt = d + dt.timedelta(days=1)\n",
    "    while nxt.weekday() >= 5 or is_vn_holiday(nxt):\n",
    "        nxt += dt.timedelta(days=1)\n",
    "    return nxt\n",
    "\n",
    "# ===================== vnstock loaders =====================\n",
    "def load_daily_ohlc_vnstock(symbol: str, start=\"2024-01-01\", end=None, source=\"VCI\") -> pd.DataFrame:\n",
    "    \"\"\"Daily OHLC trực tiếp từ vnstock → ['date','open','high','low','close','volume']\"\"\"\n",
    "    from vnstock import Vnstock\n",
    "    stock = Vnstock().stock(symbol=symbol, source=source)\n",
    "    df = stock.quote.history(start=start, end=end, interval='1D')\n",
    "    if df is None or len(df) == 0:\n",
    "        raise RuntimeError(f\"vnstock.history rỗng cho {symbol}\")\n",
    "    df = df.rename(columns={\"time\":\"date\"}).dropna(subset=[\"close\"]).copy()\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    return df.sort_values(\"date\")[[\"date\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "def _vnstock_intraday_once(symbol: str, page_size=20000, source=\"VCI\", show_log=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lấy intraday TICKS của NGÀY GẦN NHẤT (không trading_date) → ['dt','price','volume','date'] (tz=ICT)\n",
    "    \"\"\"\n",
    "    from vnstock import Vnstock\n",
    "    stock = Vnstock().stock(symbol=symbol, source=source)\n",
    "    df = stock.quote.intraday(symbol=symbol, page_size=page_size, show_log=show_log)\n",
    "    if df is None or len(df) == 0:\n",
    "        raise RuntimeError(\"vnstock intraday trả về rỗng.\")\n",
    "\n",
    "    time_col = \"time\" if \"time\" in df.columns else (\"time_report\" if \"time_report\" in df.columns else None)\n",
    "    price_col = \"price\" if \"price\" in df.columns else (\"close\" if \"close\" in df.columns else None)\n",
    "    volume_col = \"volume\" if \"volume\" in df.columns else (\"match_volume\" if \"match_volume\" in df.columns else None)\n",
    "    if not time_col or not price_col:\n",
    "        raise RuntimeError(\"Không nhận diện được cột thời gian/giá từ intraday tick.\")\n",
    "\n",
    "    sub = df.rename(columns={time_col:\"dt\", price_col:\"price\"}).copy()\n",
    "    sub[\"volume\"] = df[volume_col] if volume_col and volume_col in df.columns else 0\n",
    "    sub[\"dt\"] = pd.to_datetime(sub[\"dt\"], errors=\"coerce\")\n",
    "    sub = sub.dropna(subset=[\"dt\",\"price\"]).copy()\n",
    "    if sub[\"dt\"].dt.tz is None:\n",
    "        sub[\"dt\"] = sub[\"dt\"].dt.tz_localize(ICT)\n",
    "    else:\n",
    "        sub[\"dt\"] = sub[\"dt\"].dt.tz_convert(ICT)\n",
    "    sub[\"date\"] = sub[\"dt\"].dt.date\n",
    "    return sub.sort_values(\"dt\")[[\"dt\",\"price\",\"volume\",\"date\"]]\n",
    "\n",
    "def resample_to_5m_ohlcv(tick_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ticks → 5 phút OHLCV  → ['dt','open','high','low','close','volume']\"\"\"\n",
    "    tick = tick_df.set_index(\"dt\")\n",
    "    ohlc = tick[\"price\"].resample(\"5min\").ohlc()\n",
    "    vol  = tick[\"volume\"].resample(\"5min\").sum()\n",
    "    df5  = pd.concat([ohlc, vol], axis=1).dropna(subset=[\"close\"]).reset_index()\n",
    "    return df5[[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "# ===================== Returns & ARIMA helpers =====================\n",
    "def to_log_returns(series: pd.Series) -> pd.Series:\n",
    "    r = np.log(series/series.shift(1))\n",
    "    if r.isna().any():\n",
    "        r.iloc[0] = r.iloc[1:].mean() if len(r) > 1 else 0.0\n",
    "    return r\n",
    "\n",
    "def returns_to_price(last_price: float, r_fore: np.ndarray) -> pd.Series:\n",
    "    return pd.Series(last_price * np.exp(np.cumsum(r_fore)))\n",
    "\n",
    "def session_returns_from_intraday(intra_5m: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Từ intraday 5m → theo ngày: ['date','P_0900','P_1130','P_1300','P_1500','AM_return','PM_return']\n",
    "    \"\"\"\n",
    "    df = intra_5m.copy()\n",
    "    df[\"date\"] = df[\"dt\"].dt.date\n",
    "    out = []\n",
    "    for d, g in df.groupby(\"date\"):\n",
    "        g = g.sort_values(\"dt\")\n",
    "        p_0900 = g.loc[g[\"dt\"].dt.time >= dt.time(9,0),  \"close\"].head(1)\n",
    "        p_1130 = g.loc[g[\"dt\"].dt.time <= dt.time(11,30), \"close\"].tail(1)\n",
    "        p_1300 = g.loc[g[\"dt\"].dt.time >= dt.time(13,0), \"close\"].head(1)\n",
    "        p_1500 = g.loc[g[\"dt\"].dt.time <= dt.time(15,0), \"close\"].tail(1)\n",
    "        if len(p_0900)==0 or len(p_1130)==0 or len(p_1300)==0 or len(p_1500)==0:\n",
    "            continue\n",
    "        p0900, p1130, p1300, p1500 = map(float,[p_0900.iloc[0],p_1130.iloc[0],p_1300.iloc[0],p_1500.iloc[0]])\n",
    "        out.append({\n",
    "            \"date\": pd.to_datetime(d),\n",
    "            \"P_0900\": p0900, \"P_1130\": p1130, \"P_1300\": p1300, \"P_1500\": p1500,\n",
    "            \"AM_return\": np.log(p1130/p0900),\n",
    "            \"PM_return\": np.log(p1500/p1300),\n",
    "        })\n",
    "    if not out:\n",
    "        raise RuntimeError(\"Không trích được AM/PM (thiếu mốc 09:00/11:30/13:00/15:00).\")\n",
    "    return pd.DataFrame(out).sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "def arima_select_fit(y: pd.Series, d=0, max_p=5, max_q=5, trends=(\"n\",\"c\")):\n",
    "    \"\"\"Grid (p,d,q,trend) theo AIC, non-seasonal. Trả (fit, order, trend).\"\"\"\n",
    "    best = {\"aic\": np.inf, \"fit\": None, \"order\": None, \"trend\": None}\n",
    "    y = pd.Series(y).astype(float)\n",
    "    for tr in trends:\n",
    "        for p in range(max_p+1):\n",
    "            for q in range(max_q+1):\n",
    "                try:\n",
    "                    res = SARIMAX(y, order=(p,d,q),\n",
    "                                  seasonal_order=(0,0,0,0),\n",
    "                                  trend=tr,\n",
    "                                  enforce_stationarity=False,\n",
    "                                  enforce_invertibility=False).fit(disp=False)\n",
    "                    if res.aic < best[\"aic\"]:\n",
    "                        best = {\"aic\": res.aic, \"fit\": res, \"order\": (p,d,q), \"trend\": tr}\n",
    "                except Exception:\n",
    "                    pass\n",
    "    if best[\"fit\"] is None:\n",
    "        raise RuntimeError(\"ARIMA grid không hội tụ — kiểm tra dữ liệu hoặc giảm max_p/max_q.\")\n",
    "    return best[\"fit\"], best[\"order\"], best[\"trend\"]\n",
    "\n",
    "# ===================== Dự báo TRONG phiên =====================\n",
    "def predict_in_session(symbol: str, source=\"VCI\"):\n",
    "    \"\"\"Dùng intraday hôm nay (5m) → dự báo đến hết phiên hiện tại.\"\"\"\n",
    "    tick = _vnstock_intraday_once(symbol, page_size=20000, source=source, show_log=False)\n",
    "    intra = resample_to_5m_ohlcv(tick)\n",
    "    close = intra[\"close\"]; r = to_log_returns(close)\n",
    "\n",
    "    last_dt = intra[\"dt\"].iloc[-1]\n",
    "    now_t = last_dt.timetz()\n",
    "    session_end = dt.time(11,30, tzinfo=ICT) if now_t < dt.time(11,30, tzinfo=ICT) else dt.time(15,0, tzinfo=ICT)\n",
    "    step_min = 5\n",
    "    rem_minutes = ((dt.datetime.combine(last_dt.date(), session_end) -\n",
    "                    dt.datetime.combine(last_dt.date(), now_t)).seconds) // 60\n",
    "    steps = max(1, rem_minutes // step_min)\n",
    "\n",
    "    fit, order, trend = arima_select_fit(r, d=0, max_p=3, max_q=3, trends=(\"n\",\"c\"))\n",
    "    r_fore = fit.get_forecast(steps=steps).predicted_mean.values\n",
    "    y_pred = returns_to_price(float(close.iloc[-1]), r_fore)\n",
    "\n",
    "    future_times = pd.date_range(last_dt + pd.Timedelta(minutes=step_min),\n",
    "                                 periods=steps, freq=f\"{step_min}min\", tz=ICT)\n",
    "    y_pred.index = future_times\n",
    "    direction = np.sign(y_pred.values - np.r_[close.iloc[-1], y_pred.values[:-1]])\n",
    "    direction = pd.Series(direction, index=y_pred.index).map({-1:\"↓\", 0:\"=\", 1:\"↑\"})\n",
    "\n",
    "    info = {\"order\": order, \"trend\": trend, \"last_price\": float(close.iloc[-1]), \"pred_until\": future_times[-1]}\n",
    "    print(f\"[Trong phiên] {symbol} | ARIMA{order} trend={trend} | last={info['last_price']:.2f} | đến {info['pred_until']}\")\n",
    "    return intra, y_pred, direction, info\n",
    "\n",
    "# ===================== AM/PM (ngoài giờ) – KHÔNG CACHE =====================\n",
    "def forecast_tomorrow_sessions_no_cache(symbol: str,\n",
    "                                        source: str = \"VCI\",\n",
    "                                        max_p: int = 5, max_q: int = 5,\n",
    "                                        alpha: float = 0.10):\n",
    "    \"\"\"\n",
    "    Dùng intraday NGÀY GẦN NHẤT (thường chỉ 1 ngày) → tính AM/PM returns theo ngày.\n",
    "    Nếu số ngày < 10 → fallback trung bình (mean ± CI); nếu chỉ 1 ngày → CI mặc định ±0.5%.\n",
    "    \"\"\"\n",
    "    intra5 = resample_to_5m_ohlcv(_vnstock_intraday_once(symbol, page_size=20000, source=source, show_log=False))\n",
    "    sess = session_returns_from_intraday(intra5)\n",
    "    n = len(sess)\n",
    "    if n < 10:\n",
    "        print(f\"[FALLBACK] Lịch sử AM/PM chỉ có {n} ngày → dùng trung bình thay ARIMA.\")\n",
    "        def stat_block(col: str):\n",
    "            mean = float(sess[col].mean())\n",
    "            std  = float(sess[col].std(ddof=1)) if n >= 2 else 0.0\n",
    "            z = 1.645\n",
    "            lo, hi = (mean - z*std, mean + z*std) if (n >= 2 and std > 0) else (mean - 0.005, mean + 0.005)\n",
    "            direction = \"↑\" if mean > 0 else (\"↓\" if mean < 0 else \"=\")\n",
    "            return {\"direction\": direction, \"ret_pred\": mean, \"ret_ci\": [lo, hi],\n",
    "                    \"order\": (\"mean\",\"-\",\"-\"), \"trend\": \"n\"}\n",
    "        AM = stat_block(\"AM_return\"); PM = stat_block(\"PM_return\")\n",
    "    else:\n",
    "        am_fit, am_order, am_trend = arima_select_fit(sess[\"AM_return\"], d=0, max_p=max_p, max_q=max_q, trends=(\"n\",\"c\"))\n",
    "        pm_fit, pm_order, pm_trend = arima_select_fit(sess[\"PM_return\"], d=0, max_p=max_p, max_q=max_q, trends=(\"n\",\"c\"))\n",
    "        am_fc = am_fit.get_forecast(steps=1); pm_fc = pm_fit.get_forecast(steps=1)\n",
    "        am_mean = float(am_fc.predicted_mean.values[0]); am_ci = am_fc.conf_int(alpha=alpha).values[0].tolist()\n",
    "        pm_mean = float(pm_fc.predicted_mean.values[0]); pm_ci = pm_fc.conf_int(alpha=alpha).values[0].tolist()\n",
    "        AM = {\"direction\": \"↑\" if am_mean > 0 else (\"↓\" if am_mean < 0 else \"=\"),\n",
    "              \"ret_pred\": am_mean, \"ret_ci\": am_ci, \"order\": am_order, \"trend\": am_trend}\n",
    "        PM = {\"direction\": \"↑\" if pm_mean > 0 else (\"↓\" if pm_mean < 0 else \"=\"),\n",
    "              \"ret_pred\": pm_mean, \"ret_ci\": pm_ci, \"order\": pm_order, \"trend\": pm_trend}\n",
    "\n",
    "    last_date = sess[\"date\"].iloc[-1].date()\n",
    "    target_day = next_trading_day(last_date)\n",
    "    return {\"target_day\": target_day, \"history\": sess, \"AM\": AM, \"PM\": PM}\n",
    "\n",
    "# ===================== GAP (OPEN vs CLOSE hôm qua) & quy đổi sang GIÁ =====================\n",
    "def price_from_ret(open_price: float, ret_mean: float, ret_ci: list[float]) -> dict:\n",
    "    mean_px = open_price * np.exp(ret_mean)\n",
    "    lo_px   = open_price * np.exp(ret_ci[0])\n",
    "    hi_px   = open_price * np.exp(ret_ci[1])\n",
    "    return {\"px_mean\": float(mean_px), \"px_lo\": float(lo_px), \"px_hi\": float(hi_px)}\n",
    "\n",
    "def forecast_gap_open_vs_prev_close(symbol: str, lookback_days=240, source=\"VCI\"):\n",
    "    \"\"\"\n",
    "    Dự báo log-return GAP (OPEN mai vs CLOSE hôm qua) bằng daily ARIMA trên CLOSE (xấp xỉ).\n",
    "    \"\"\"\n",
    "    start = (pd.Timestamp.now(ICT) - pd.Timedelta(days=lookback_days)).strftime(\"%Y-%m-%d\")\n",
    "    df = load_daily_ohlc_vnstock(symbol, start=start, source=source).dropna(subset=[\"close\"]).copy()\n",
    "    close = df[\"close\"]\n",
    "    r = np.log(close/close.shift(1)).dropna()\n",
    "    fit, order, trend = arima_select_fit(pd.Series(r), d=0, max_p=3, max_q=3, trends=(\"n\",\"c\"))\n",
    "    fc = fit.get_forecast(steps=1)\n",
    "    ret_mean = float(fc.predicted_mean.values[0])\n",
    "    ci = fc.conf_int(alpha=0.10).values[0].tolist()  # CI 90%\n",
    "    return {\"gap_ret_mean\": ret_mean, \"gap_ret_ci\": ci, \"order\": order, \"trend\": trend, \"last_close\": float(close.iloc[-1])}\n",
    "\n",
    "def apply_gap_then_sessions(gap_fc: dict, ampm_fc: dict):\n",
    "    \"\"\"Tạo dải GIÁ dự kiến: OPEN 09:00 -> 11:30 -> 15:00.\"\"\"\n",
    "    last_close = gap_fc[\"last_close\"]\n",
    "    open_am = price_from_ret(last_close, gap_fc[\"gap_ret_mean\"], gap_fc[\"gap_ret_ci\"])\n",
    "    am_px   = price_from_ret(open_am[\"px_mean\"], ampm_fc[\"AM\"][\"ret_pred\"], ampm_fc[\"AM\"][\"ret_ci\"])\n",
    "    pm_px   = price_from_ret(am_px[\"px_mean\"], ampm_fc[\"PM\"][\"ret_pred\"], ampm_fc[\"PM\"][\"ret_ci\"])\n",
    "    return {\"OPEN_am\": open_am, \"AM_px\": am_px, \"PM_px\": pm_px}\n",
    "\n",
    "# ===================== Hàm gộp: DỰ BÁO NGÀY MAI (không cache) =====================\n",
    "def predict_tomorrow_full(symbol: str, source: str = \"VCI\", alpha: float = 0.10):\n",
    "    \"\"\"\n",
    "    Dự báo NGÀY MAI: GAP (OPEN 09:00), AM (09:00→11:30), PM (13:00→15:00) và quy đổi ra band GIÁ.\n",
    "    Không lưu CSV; chỉ gọi vnstock trực tiếp.\n",
    "    \"\"\"\n",
    "    # AM/PM từ intraday ngày gần nhất\n",
    "    ampm = forecast_tomorrow_sessions_no_cache(symbol, source=source, max_p=5, max_q=5, alpha=alpha)\n",
    "    target_day = ampm[\"target_day\"]; AM, PM = ampm[\"AM\"], ampm[\"PM\"]\n",
    "\n",
    "    # GAP từ daily\n",
    "    try:\n",
    "        gap = forecast_gap_open_vs_prev_close(symbol, lookback_days=240, source=source)\n",
    "        gap_dir = \"↑\" if gap[\"gap_ret_mean\"] > 0 else (\"↓\" if gap[\"gap_ret_mean\"] < 0 else \"=\")\n",
    "    except Exception as e:\n",
    "        # nếu daily lỗi, dùng last close và CI ±0.5%\n",
    "        df_daily = load_daily_ohlc_vnstock(symbol, start=(pd.Timestamp.now(ICT)-pd.Timedelta(days=30)).strftime(\"%Y-%m-%d\"), source=source)\n",
    "        last_close = float(df_daily[\"close\"].iloc[-1])\n",
    "        gap = {\"gap_ret_mean\": 0.0, \"gap_ret_ci\": [-0.005, 0.005], \"last_close\": last_close}\n",
    "        gap_dir = \"=\"\n",
    "        print(f\"[WARN] GAP ARIMA lỗi ({e}). Fallback OPEN≈last_close ±0.5%.\")\n",
    "\n",
    "    bands = apply_gap_then_sessions(gap, ampm)\n",
    "\n",
    "    def pct(x): return f\"{x*100:.2f}%\"\n",
    "    print(f\"=== {symbol} | Dự báo NGÀY MAI {target_day} ===\")\n",
    "    print(f\"GAP (OPEN 09:00 vs CLOSE hôm qua): {gap_dir} | ret≈{pct(gap['gap_ret_mean'])} | CI90% ~ [{pct(gap['gap_ret_ci'][0])}, {pct(gap['gap_ret_ci'][1])}]\")\n",
    "    print(f\"  → OPEN 09:00 ~ {bands['OPEN_am']['px_mean']:.0f}  (CI90% {bands['OPEN_am']['px_lo']:.0f}–{bands['OPEN_am']['px_hi']:.0f})\")\n",
    "\n",
    "    print(f\"AM (09:00→11:30): {AM['direction']} | ret≈{pct(AM['ret_pred'])} | CI90% ~ [{pct(AM['ret_ci'][0])}, {pct(AM['ret_ci'][1])}]\")\n",
    "    print(f\"  → 11:30 ~ {bands['AM_px']['px_mean']:.0f}  (CI90% {bands['AM_px']['px_lo']:.0f}–{bands['AM_px']['px_hi']:.0f})\")\n",
    "\n",
    "    print(f\"PM (13:00→15:00): {PM['direction']} | ret≈{pct(PM['ret_pred'])} | CI90% ~ [{pct(PM['ret_ci'][0])}, {pct(PM['ret_ci'][1])}]\")\n",
    "    print(f\"  → 15:00 ~ {bands['PM_px']['px_mean']:.0f}  (CI90% {bands['PM_px']['px_lo']:.0f}–{bands['PM_px']['px_hi']:.0f})\")\n",
    "\n",
    "    return {\"target_day\": target_day, \"gap\": gap, \"ampm\": ampm, \"bands\": bands}\n",
    "\n",
    "# ===================== Ví dụ dùng =====================\n",
    "# Ngoài giờ (khuyến nghị): \n",
    "out = predict_tomorrow_full(\"VCB\", source=\"VCI\", alpha=0.10)\n",
    "\n",
    "# Trong giờ:\n",
    "intra, pred, direction, info = predict_in_session(\"VCB\", source=\"VCI\")\n",
    "display(pred.round(2).to_frame(\"pred_price\")); display(direction.to_frame(\"dir\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2165f3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json, math, time, datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Literal\n",
    "\n",
    "# ============== Thời gian ==============\n",
    "ICT = dt.timezone(dt.timedelta(hours=7))\n",
    "\n",
    "# ============== vnstock loaders ==============\n",
    "def _vnstock_intraday_once(symbol: str, page_size=20000, source=\"VCI\", show_log=False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lấy intraday ticks NGÀY GẦN NHẤT qua vnstock. Trả: ['dt','price','volume','date'] (tz=ICT)\n",
    "    \"\"\"\n",
    "    from vnstock import Vnstock\n",
    "    stock = Vnstock().stock(symbol=symbol, source=source)\n",
    "    df = stock.quote.intraday(symbol=symbol, page_size=page_size, show_log=show_log)\n",
    "    if df is None or len(df) == 0:\n",
    "        raise RuntimeError(\"vnstock intraday trả về rỗng.\")\n",
    "\n",
    "    time_col = \"time\" if \"time\" in df.columns else (\"time_report\" if \"time_report\" in df.columns else None)\n",
    "    price_col = \"price\" if \"price\" in df.columns else (\"close\" if \"close\" in df.columns else None)\n",
    "    vol_col   = \"volume\" if \"volume\" in df.columns else (\"match_volume\" if \"match_volume\" in df.columns else None)\n",
    "    if not time_col or not price_col:\n",
    "        raise RuntimeError(\"Không nhận diện được cột thời gian/giá từ intraday tick.\")\n",
    "\n",
    "    sub = df.rename(columns={time_col:\"dt\", price_col:\"price\"}).copy()\n",
    "    sub[\"volume\"] = df[vol_col] if vol_col and vol_col in df.columns else 0\n",
    "    sub[\"dt\"] = pd.to_datetime(sub[\"dt\"], errors=\"coerce\")\n",
    "    sub = sub.dropna(subset=[\"dt\",\"price\"]).copy()\n",
    "    # tz → ICT\n",
    "    if sub[\"dt\"].dt.tz is None:\n",
    "        sub[\"dt\"] = sub[\"dt\"].dt.tz_localize(ICT)\n",
    "    else:\n",
    "        sub[\"dt\"] = sub[\"dt\"].dt.tz_convert(ICT)\n",
    "    sub[\"date\"] = sub[\"dt\"].dt.date\n",
    "    return sub.sort_values(\"dt\")[[\"dt\",\"price\",\"volume\",\"date\"]]\n",
    "\n",
    "def resample_to_5m_ohlcv(tick_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Ticks → 5m OHLCV: ['dt','open','high','low','close','volume']\"\"\"\n",
    "    tick = tick_df.set_index(\"dt\")\n",
    "    ohlc = tick[\"price\"].resample(\"5min\").ohlc()\n",
    "    vol  = tick[\"volume\"].resample(\"5min\").sum()\n",
    "    df5  = pd.concat([ohlc, vol], axis=1).dropna(subset=[\"close\"]).reset_index()\n",
    "    return df5[[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "# ============== Backend 1: Redis ==============\n",
    "\"\"\"\n",
    "Thiết kế:\n",
    "- Mỗi symbol lưu trong 1 Sorted Set: key = f\"intra:{symbol}:5m\"\n",
    "- score = epoch seconds (UTC), member = JSON packed candle {ts,open,high,low,close,volume}\n",
    "- Truy xuất theo khoảng thời gian (ZRANGEBYSCORE)\n",
    "Ưu điểm: cực nhanh, đúng bài time-series, không cần lưu file.\n",
    "\"\"\"\n",
    "\n",
    "def redis_connect(host=\"localhost\", port=6379, db=0, password=None):\n",
    "    import redis\n",
    "    return redis.Redis(host=host, port=port, db=db, password=password, decode_responses=True)\n",
    "\n",
    "def candle_row_to_json(row: pd.Series) -> str:\n",
    "    # lưu ts ở epoch seconds UTC để range dễ\n",
    "    ts = int(row[\"dt\"].tz_convert(\"UTC\").timestamp()) if hasattr(row[\"dt\"], \"tzinfo\") and row[\"dt\"].tzinfo else int(pd.Timestamp(row[\"dt\"]).tz_localize(\"UTC\").timestamp())\n",
    "    payload = {\n",
    "        \"ts\": ts,\n",
    "        \"open\": float(row[\"open\"]),\n",
    "        \"high\": float(row[\"high\"]),\n",
    "        \"low\":  float(row[\"low\"]),\n",
    "        \"close\":float(row[\"close\"]),\n",
    "        \"volume\": float(row.get(\"volume\", 0.0))\n",
    "    }\n",
    "    return json.dumps(payload), ts\n",
    "\n",
    "def redis_upsert_intraday_5m(r, symbol: str, df5: pd.DataFrame) -> int:\n",
    "    key = f\"intra:{symbol}:5m\"\n",
    "    pipe = r.pipeline(transaction=False)\n",
    "    n=0\n",
    "    for _, row in df5.iterrows():\n",
    "        member, score = candle_row_to_json(row)\n",
    "        pipe.zadd(key, {member: score})\n",
    "        n += 1\n",
    "    pipe.execute()\n",
    "    return n\n",
    "\n",
    "def redis_fetch_last_days_5m(r, symbol: str, days: int = 10) -> pd.DataFrame:\n",
    "    key = f\"intra:{symbol}:5m\"\n",
    "    now = pd.Timestamp.now(\"UTC\")\n",
    "    start = int((now - pd.Timedelta(days=days)).timestamp())\n",
    "    end   = int(now.timestamp())\n",
    "    members = r.zrangebyscore(key, start, end)\n",
    "    if not members:\n",
    "        return pd.DataFrame(columns=[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"])\n",
    "    recs = [json.loads(m) for m in members]\n",
    "    df = pd.DataFrame(recs)\n",
    "    df[\"dt\"] = pd.to_datetime(df[\"ts\"], unit=\"s\", utc=True).dt.tz_convert(ICT)\n",
    "    return df.sort_values(\"dt\")[[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "# ============== Backend 2: Qdrant ==============\n",
    "\"\"\"\n",
    "Qdrant chủ yếu cho vector search, nhưng ta vẫn có thể lưu candle làm \"point\":\n",
    "- collection = \"intraday_5m\"\n",
    "- vector_dim = 1 (dummy) hoặc tính vector đặc trưng nếu bạn muốn similarity\n",
    "- payload: {symbol, ts, open, high, low, close, volume}\n",
    "- id: int(f\"{ts}{hash(symbol)%1000}\") hoặc tự sinh\n",
    "Truy xuất: dùng filter symbol & ts range → scroll, sau đó sort theo ts.\n",
    "\"\"\"\n",
    "\n",
    "def qdrant_connect(host=\"localhost\", port=6333, api_key: Optional[str]=None):\n",
    "    from qdrant_client import QdrantClient\n",
    "    return QdrantClient(host=host, port=port, api_key=api_key)\n",
    "\n",
    "def qdrant_ensure_collection(client, collection=\"intraday_5m\", vector_size=1, distance=\"Cosine\"):\n",
    "    from qdrant_client.http.models import VectorParams, Distance\n",
    "    dist = getattr(Distance, distance)\n",
    "    client.recreate_collection(collection_name=collection, vectors_config=VectorParams(size=vector_size, distance=dist))\n",
    "\n",
    "def qdrant_upsert_intraday_5m(client, symbol: str, df5: pd.DataFrame, collection=\"intraday_5m\") -> int:\n",
    "    from qdrant_client.http.models import PointStruct\n",
    "    points = []\n",
    "    for _, row in df5.iterrows():\n",
    "        ts = int(row[\"dt\"].tz_convert(\"UTC\").timestamp()) if hasattr(row[\"dt\"], \"tzinfo\") and row[\"dt\"].tzinfo else int(pd.Timestamp(row[\"dt\"]).tz_localize(\"UTC\").timestamp())\n",
    "        payload = {\n",
    "            \"symbol\": symbol,\n",
    "            \"ts\": ts,\n",
    "            \"open\": float(row[\"open\"]),\n",
    "            \"high\": float(row[\"high\"]),\n",
    "            \"low\":  float(row[\"low\"]),\n",
    "            \"close\":float(row[\"close\"]),\n",
    "            \"volume\": float(row.get(\"volume\", 0.0))\n",
    "        }\n",
    "        # dummy vector (1D), bạn có thể thay bằng feature thực tế\n",
    "        vec = [float(row[\"close\"])]\n",
    "        pid = int(f\"{ts}{abs(hash(symbol))%1000}\")\n",
    "        points.append(PointStruct(id=pid, vector=vec, payload=payload))\n",
    "    if points:\n",
    "        client.upsert(collection_name=collection, points=points)\n",
    "    return len(points)\n",
    "\n",
    "def qdrant_fetch_last_days_5m(client, symbol: str, days: int = 10, collection=\"intraday_5m\") -> pd.DataFrame:\n",
    "    from qdrant_client.http.models import Filter, FieldCondition, Range, ScrollRequest, MatchValue\n",
    "\n",
    "    now = int(pd.Timestamp.now(\"UTC\").timestamp())\n",
    "    start = int((pd.Timestamp.now(\"UTC\") - pd.Timedelta(days=days)).timestamp())\n",
    "    cond = Filter(\n",
    "        must=[\n",
    "            FieldCondition(key=\"symbol\", match=MatchValue(value=symbol)),\n",
    "            FieldCondition(key=\"ts\", range=Range(gte=start, lte=now))\n",
    "        ]\n",
    "    )\n",
    "    points = []\n",
    "    next_page = None\n",
    "    while True:\n",
    "        res = client.scroll(collection_name=collection, scroll_filter=cond, limit=2000, with_payload=True, with_vectors=False, offset=next_page)\n",
    "        points.extend(res[0])\n",
    "        next_page = res[1]\n",
    "        if next_page is None:\n",
    "            break\n",
    "    if not points:\n",
    "        return pd.DataFrame(columns=[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"])\n",
    "    rows = [p.payload for p in points]\n",
    "    df = pd.DataFrame(rows)\n",
    "    df[\"dt\"] = pd.to_datetime(df[\"ts\"], unit=\"s\", utc=True).dt.tz_convert(ICT)\n",
    "    return df.sort_values(\"dt\")[[\"dt\",\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "# ============== Orchestrator: cập nhật & truy vấn không cần CSV ==============\n",
    "def update_store_today(symbol: str,\n",
    "                       source: str = \"VCI\",\n",
    "                       backend: Literal[\"redis\",\"qdrant\"]=\"redis\",\n",
    "                       redis_cfg: dict = None,\n",
    "                       qdrant_cfg: dict = None,\n",
    "                       qdrant_collection: str = \"intraday_5m\") -> int:\n",
    "    \"\"\"\n",
    "    - Gọi vnstock lấy intraday NGÀY GẦN NHẤT\n",
    "    - Resample 5m\n",
    "    - Lưu vào Redis hoặc Qdrant\n",
    "    - Trả số bản ghi đã lưu\n",
    "    \"\"\"\n",
    "    ticks = _vnstock_intraday_once(symbol, page_size=20000, source=source, show_log=False)\n",
    "    df5 = resample_to_5m_ohlcv(ticks)\n",
    "\n",
    "    if backend == \"redis\":\n",
    "        redis_cfg = redis_cfg or {}\n",
    "        r = redis_connect(**redis_cfg)\n",
    "        n = redis_upsert_intraday_5m(r, symbol, df5)\n",
    "        return n\n",
    "    else:\n",
    "        qdrant_cfg = qdrant_cfg or {}\n",
    "        client = qdrant_connect(**qdrant_cfg)\n",
    "        # gọi 1 lần để chắc chắn collection tồn tại (chỉ cần chạy khi mới tạo)\n",
    "        # qdrant_ensure_collection(client, collection=qdrant_collection)\n",
    "        n = qdrant_upsert_intraday_5m(client, symbol, df5, collection=qdrant_collection)\n",
    "        return n\n",
    "\n",
    "def load_last_days(symbol: str,\n",
    "                   days: int = 15,\n",
    "                   backend: Literal[\"redis\",\"qdrant\"]=\"redis\",\n",
    "                   redis_cfg: dict = None,\n",
    "                   qdrant_cfg: dict = None,\n",
    "                   qdrant_collection: str = \"intraday_5m\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lấy lại intraday 5m của N ngày gần nhất từ kho đã lưu (Redis/Qdrant).\n",
    "    \"\"\"\n",
    "    if backend == \"redis\":\n",
    "        redis_cfg = redis_cfg or {}\n",
    "        r = redis_connect(**redis_cfg)\n",
    "        return redis_fetch_last_days_5m(r, symbol, days=days)\n",
    "    else:\n",
    "        qdrant_cfg = qdrant_cfg or {}\n",
    "        client = qdrant_connect(**qdrant_cfg)\n",
    "        return qdrant_fetch_last_days_5m(client, symbol, days=days, collection=qdrant_collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011a56fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_ml_pipeline.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Standalone test runner cho ML ARIMA (SARIMAX + exog tin tức):\n",
    "- Không dùng pytest\n",
    "- Không cần __file__\n",
    "- Chạy được trong notebook hoặc CLI\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# ---- modules under test ----\n",
    "# Lưu ý: đường dẫn phải khớp với project của bạn: modules/ml/...\n",
    "from modules.ML import pipeline as ml_pipe\n",
    "from modules.ML import registry as ml_registry\n",
    "\n",
    "# ========= redirect MODEL_DIR về thư mục tạm cho test =========\n",
    "TMP_MODELS_DIR = tempfile.mkdtemp(prefix=\"models_\")\n",
    "os.environ[\"MODEL_DIR\"] = TMP_MODELS_DIR\n",
    "importlib.reload(ml_registry)  # ensure registry đọc MODEL_DIR mới\n",
    "\n",
    "# ========= helpers (synthetic data) =========\n",
    "def _make_price_series(days=300, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # random walk trên log-price\n",
    "    rets = rng.normal(loc=0.0005, scale=0.01, size=days)  # ~0.05% drift\n",
    "    logp = np.cumsum(rets) + math.log(100.0)\n",
    "    prices = np.exp(logp)\n",
    "    idx = pd.date_range(end=pd.Timestamp.now().normalize(), periods=days, freq=\"D\")\n",
    "    s = pd.Series(prices, index=idx, name=\"close\")\n",
    "    return s\n",
    "\n",
    "def _make_news_features(start_ts, end_ts, days=300, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = pd.date_range(end=pd.Timestamp.fromtimestamp(end_ts).normalize(), periods=days, freq=\"D\")\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": idx,\n",
    "        \"news_count\": rng.integers(0, 8, size=days),\n",
    "        \"pos_count\":  rng.integers(0, 5, size=days),\n",
    "        \"neg_count\":  rng.integers(0, 5, size=days),\n",
    "        \"mean_sent\":  rng.normal(0, 0.2, size=days),\n",
    "        \"sum_sent\":   rng.normal(0, 1.0, size=days),\n",
    "    })\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# ========= simple patching utility (thay cho pytest.monkeypatch) =========\n",
    "@contextmanager\n",
    "def patch_attr(module, attr_name, new_value):\n",
    "    old = getattr(module, attr_name, None)\n",
    "    setattr(module, attr_name, new_value)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(module, attr_name, old)\n",
    "\n",
    "# ========= simple test runner =========\n",
    "PASSED, FAILED = 0, 0\n",
    "def run_test(name, fn):\n",
    "    global PASSED, FAILED\n",
    "    try:\n",
    "        fn()\n",
    "        print(f\"✅ PASS: {name}\")\n",
    "        PASSED += 1\n",
    "    except AssertionError as e:\n",
    "        print(f\"❌ FAIL: {name} -> {e}\")\n",
    "        FAILED += 1\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR: {name} -> {type(e).__name__}: {e}\")\n",
    "        FAILED += 1\n",
    "\n",
    "def summary():\n",
    "    print(f\"\\nKết quả: {PASSED} passed / {FAILED} failed\\n\")\n",
    "\n",
    "# ========= tests =========\n",
    "def test_train_gap_model_with_exog():\n",
    "    # Patches: close series, prices df, news features, time\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "    fake_time = lambda: \"01-01-2025 09:00:00\"\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features), \\\n",
    "         patch_attr(ml_pipe, \"get_time_vn\", fake_time):\n",
    "        out = ml_pipe.train_gap_model(\"VCB\", lookback_days=240)\n",
    "        assert out[\"symbol\"] == \"VCB\"\n",
    "        assert isinstance(out[\"order\"], tuple)\n",
    "        assert out[\"trend\"] in (\"n\", \"c\")\n",
    "        assert out[\"use_exog\"] is True\n",
    "        assert os.path.exists(out[\"saved\"])\n",
    "\n",
    "def test_train_gap_model_without_news():\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return pd.DataFrame(columns=[\"date\",\"news_count\",\"pos_count\",\"neg_count\",\"mean_sent\",\"sum_sent\"])\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        out = ml_pipe.train_gap_model(\"HPG\", lookback_days=240)\n",
    "        assert out[\"symbol\"] == \"HPG\"\n",
    "        assert out[\"use_exog\"] is False\n",
    "\n",
    "def test_forecast_gap_after_training():\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        ml_pipe.train_gap_model(\"VNM\", lookback_days=240)\n",
    "        res = ml_pipe.forecast_gap(\"VNM\", alpha=0.10)\n",
    "        assert isinstance(res[\"gap_ret_mean\"], float)\n",
    "        assert len(res[\"gap_ret_ci\"]) == 2\n",
    "        assert isinstance(res[\"last_close\"], float)\n",
    "        assert res[\"use_exog\"] is True\n",
    "\n",
    "def test_predict_tomorrow_full_exog_structure():\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        res = ml_pipe.predict_tomorrow_full_exog(\"VCB\", alpha=0.10)\n",
    "        assert \"target_day\" in res\n",
    "        assert \"gap\" in res and \"bands\" in res and \"ampm\" in res\n",
    "        bands = res[\"bands\"]\n",
    "        for k in (\"OPEN_am\", \"AM_px\", \"PM_px\"):\n",
    "            assert k in bands and all(sub in bands[k] for sub in (\"px_mean\",\"px_lo\",\"px_hi\"))\n",
    "\n",
    "def test_smart_predict_in_session():\n",
    "    # ép trạng thái trong phiên + fake intraday predictor\n",
    "    fake_is_trading = lambda: True\n",
    "    fake_pred = {\n",
    "        \"last_dt\": pd.Timestamp.now(),\n",
    "        \"last_price\": 100.0,\n",
    "        \"next_price\": 100.2,\n",
    "        \"next_step_dir\": \"↑\",\n",
    "        \"order\": (1,0,1),\n",
    "        \"trend\": \"c\",\n",
    "        \"path_pred\": pd.Series([100.2, 100.4], index=pd.date_range(pd.Timestamp.now(), periods=2, freq=\"5min\"))\n",
    "    }\n",
    "    with patch_attr(ml_pipe, \"is_vn_trading_time\", fake_is_trading), \\\n",
    "         patch_attr(ml_pipe, \"predict_next_step_in_session\", lambda s, source=\"VCI\": fake_pred), \\\n",
    "         patch_attr(ml_pipe, \"get_time_vn\", lambda: \"01-01-2025 10:00:00\"):\n",
    "        res = ml_pipe.smart_predict(\"VCB\")\n",
    "        assert res[\"mode\"] == \"in_session\"\n",
    "        assert res[\"next_step_dir\"] == \"↑\"\n",
    "        assert \"pred_path\" in res and isinstance(res[\"pred_path\"], pd.Series)\n",
    "\n",
    "def test_smart_predict_out_of_session():\n",
    "    # ép trạng thái ngoài giờ + fake predict_tomorrow\n",
    "    fake_is_trading = lambda: False\n",
    "    fake_out = {\n",
    "        \"target_day\": pd.Timestamp.now().date(),\n",
    "        \"gap\": {\"gap_ret_mean\": 0.001, \"gap_ret_ci\": [-0.002, 0.003], \"last_close\": 100.0, \"use_exog\": True},\n",
    "        \"ampm\": {\"AM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]}, \"PM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]}},\n",
    "        \"bands\": {\"OPEN_am\": {\"px_mean\": 100.1, \"px_lo\": 99.8, \"px_hi\": 100.4},\n",
    "                  \"AM_px\":   {\"px_mean\": 100.1, \"px_lo\": 99.6, \"px_hi\": 100.6},\n",
    "                  \"PM_px\":   {\"px_mean\": 100.1, \"px_lo\": 99.3, \"px_hi\": 100.9}},\n",
    "        \"timestamp\": \"01-01-2025 20:00:00\"\n",
    "    }\n",
    "    with patch_attr(ml_pipe, \"is_vn_trading_time\", fake_is_trading), \\\n",
    "         patch_attr(ml_pipe, \"predict_tomorrow_full_exog\", lambda sym, alpha=0.10: fake_out):\n",
    "        res = ml_pipe.smart_predict(\"VCB\")\n",
    "        assert res[\"mode\"] == \"out_of_session\"\n",
    "        assert \"bands\" in res and \"gap\" in res\n",
    "\n",
    "# ========= run all immediately =========\n",
    "if __name__ == \"__main__\" or True:\n",
    "    print(f\"MODEL_DIR test: {TMP_MODELS_DIR}\")\n",
    "    tests = [\n",
    "        (\"train_gap_model_with_exog\", test_train_gap_model_with_exog),\n",
    "        (\"train_gap_model_without_news\", test_train_gap_model_without_news),\n",
    "        (\"forecast_gap_after_training\", test_forecast_gap_after_training),\n",
    "        (\"predict_tomorrow_full_exog_structure\", test_predict_tomorrow_full_exog_structure),\n",
    "        (\"smart_predict_in_session\", test_smart_predict_in_session),\n",
    "        (\"smart_predict_out_of_session\", test_smart_predict_out_of_session),\n",
    "    ]\n",
    "    for name, fn in tests:\n",
    "        run_test(name, fn)\n",
    "    summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e697351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- thêm ở đầu file (nếu chưa có) ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Tuple, Dict, Any\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "from modules.api.stock_api import get_close_series, get_prices_df, get_time_vn\n",
    "from modules.ML.features import build_news_features\n",
    "from modules.ML.registry import save_model, load_model, MODEL_DIR\n",
    "\n",
    "# ===== helper: build exog matrix theo same index của y & shift T-1 =====\n",
    "def _build_exog_matrix(symbol: str, y: pd.Series, shift: int = 1) -> Tuple[pd.DataFrame, list[str]]:\n",
    "    \"\"\"\n",
    "    Tạo ma trận exog (news features) khớp theo index của y (daily close series),\n",
    "    rồi dịch (shift) 1 ngày để dùng X_{t-1} -> dự báo r_t (T+1).\n",
    "    Trả: (X_aligned, feature_cols)\n",
    "    \"\"\"\n",
    "    if y is None or y.empty:\n",
    "        return pd.DataFrame(index=pd.Index([], name=\"date\")), []\n",
    "\n",
    "    start_ts = int(y.index.min().timestamp())\n",
    "    end_ts   = int(y.index.max().timestamp())\n",
    "\n",
    "    news = build_news_features(symbol, start_ts, end_ts)\n",
    "    if news is None or news.empty:\n",
    "        return pd.DataFrame(index=y.index), []\n",
    "\n",
    "    # đảm bảo 'date' là DatetimeIndex để join\n",
    "    news = news.copy()\n",
    "    if \"date\" in news.columns:\n",
    "        news[\"date\"] = pd.to_datetime(news[\"date\"])\n",
    "        news = news.set_index(\"date\")\n",
    "    news = news.sort_index()\n",
    "\n",
    "    # chọn các cột numeric làm exog\n",
    "    feature_cols = [c for c in news.columns if pd.api.types.is_numeric_dtype(news[c])]\n",
    "    if not feature_cols:\n",
    "        return pd.DataFrame(index=y.index), []\n",
    "\n",
    "    X = news[feature_cols].reindex(y.index).ffill().fillna(0.0)\n",
    "\n",
    "    # dịch T-1: dùng thông tin ngày T để dự báo ngày T+1\n",
    "    if shift:\n",
    "        X = X.shift(1).ffill().fillna(0.0)\n",
    "\n",
    "    return X, feature_cols\n",
    "\n",
    "\n",
    "# ===== Train GAP model (ARIMAX nếu có exog) =====\n",
    "def train_gap_model(symbol: str, lookback_days: int = 240) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Train ARIMA trên log-returns (close) với exog tin tức (T-1).\n",
    "    Lưu model + meta (gồm feature_cols) để predict sau này.\n",
    "    \"\"\"\n",
    "    s = get_close_series(symbol, days=lookback_days + 10)  # buffer vài ngày\n",
    "    # returns daily\n",
    "    r = np.log(s / s.shift(1)).dropna()\n",
    "    if r.empty:\n",
    "        raise ValueError(\"Không có đủ dữ liệu returns để train.\")\n",
    "\n",
    "    # exog matrix (shifted)\n",
    "    X, feature_cols = _build_exog_matrix(symbol, r.index.to_series().rename(\"date\").to_frame().index, shift=1)\n",
    "    # Align exog theo r.index (nếu _build_exog_matrix nhận y là Series thay vì index, ta sửa lại):\n",
    "    X, feature_cols = _build_exog_matrix(symbol, r, shift=1)\n",
    "\n",
    "    use_exog = len(feature_cols) > 0 and not X.reindex(r.index).isna().all(axis=1).all()\n",
    "    if use_exog:\n",
    "        X_train = X.reindex(r.index).fillna(0.0)\n",
    "    else:\n",
    "        X_train = None\n",
    "\n",
    "    # Grid nhỏ để ổn định\n",
    "    best = {\"aic\": np.inf, \"fit\": None, \"order\": None, \"trend\": None}\n",
    "    for tr in (\"n\", \"c\"):\n",
    "        for p in range(0, 3):\n",
    "            for q in range(0, 3):\n",
    "                try:\n",
    "                    m = SARIMAX(\n",
    "                        r.astype(\"float64\"),\n",
    "                        order=(p, 0, q),\n",
    "                        seasonal_order=(0, 0, 0, 0),\n",
    "                        trend=tr,\n",
    "                        exog=X_train if use_exog else None,\n",
    "                        enforce_stationarity=False,\n",
    "                        enforce_invertibility=False,\n",
    "                    )\n",
    "                    res = m.fit(disp=False)\n",
    "                    if res.aic < best[\"aic\"]:\n",
    "                        best = {\"aic\": res.aic, \"fit\": res, \"order\": (p, 0, q), \"trend\": tr}\n",
    "                except Exception:\n",
    "                    continue\n",
    "\n",
    "    if best[\"fit\"] is None:\n",
    "        raise RuntimeError(\"ARIMA grid không hội tụ — thử giảm p/q.\")\n",
    "\n",
    "    meta = {\n",
    "        \"symbol\": symbol,\n",
    "        \"order\": best[\"order\"],\n",
    "        \"trend\": best[\"trend\"],\n",
    "        \"use_exog\": use_exog,\n",
    "        \"feature_cols\": feature_cols if use_exog else [],\n",
    "        \"trained_until\": str(r.index.max()),\n",
    "    }\n",
    "    saved_path = save_model(symbol=symbol, model=best[\"fit\"], meta=meta, tag=\"gap\")\n",
    "\n",
    "    return {\n",
    "        \"symbol\": symbol,\n",
    "        \"order\": best[\"order\"],\n",
    "        \"trend\": best[\"trend\"],\n",
    "        \"use_exog\": use_exog,\n",
    "        \"feature_cols\": feature_cols,\n",
    "        \"saved\": saved_path,\n",
    "    }\n",
    "\n",
    "\n",
    "# ===== Forecast GAP (1 bước) =====\n",
    "def forecast_gap(symbol: str, alpha: float = 0.10) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Load model đã train; nếu model có exog → build X1 đúng thứ tự cột và truyền vào get_forecast.\n",
    "    \"\"\"\n",
    "    fit, meta = load_model(symbol=symbol, tag=\"gap\")  # bạn đã có hàm load_model_meta\n",
    "    if fit is None:\n",
    "        # chưa train thì train nhanh rồi forecast\n",
    "        _ = train_gap_model(symbol)\n",
    "        fit, meta = load_model(symbol=symbol, tag=\"gap\")\n",
    "\n",
    "    use_exog = bool(meta.get(\"use_exog\"))\n",
    "    feature_cols = meta.get(\"feature_cols\", [])\n",
    "\n",
    "    # Lấy last_close để quy đổi giá\n",
    "    last_close = float(get_prices_df(symbol, days=5)[\"close\"].iloc[-1])\n",
    "\n",
    "    X1 = None\n",
    "    if use_exog and feature_cols:\n",
    "        # tái tạo exog cho toàn bộ lịch sử returns để lấy hàng cuối\n",
    "        s = get_close_series(symbol, days=260)\n",
    "        r = np.log(s / s.shift(1)).dropna()\n",
    "\n",
    "        X_full, feat_cols_now = _build_exog_matrix(symbol, r, shift=1)\n",
    "        # đảm bảo đúng thứ tự cột (như khi train)\n",
    "        X_full = X_full.reindex(columns=feature_cols).fillna(0.0)\n",
    "\n",
    "        if not X_full.empty:\n",
    "            # 1-step ahead exog: dùng hàng cuối cùng làm proxy cho tương lai\n",
    "            X1 = X_full.iloc[[-1]]  # shape (1, k)\n",
    "\n",
    "    # Forecast\n",
    "    if use_exog and X1 is not None:\n",
    "        fc = fit.get_forecast(steps=1, exog=X1)\n",
    "    else:\n",
    "        # fallback nếu thiếu exog\n",
    "        fc = fit.get_forecast(steps=1)\n",
    "\n",
    "    ret_mean = float(fc.predicted_mean.values[0])\n",
    "    ci = fc.conf_int(alpha=alpha).values[0].tolist()\n",
    "\n",
    "    return {\n",
    "        \"gap_ret_mean\": ret_mean,\n",
    "        \"gap_ret_ci\": ci,\n",
    "        \"last_close\": last_close,\n",
    "        \"use_exog\": use_exog and (X1 is not None),\n",
    "    }\n",
    "\n",
    "\n",
    "# ===== Dùng forecast_gap + fallback AM/PM để tạo bands =====\n",
    "def _price_from_ret(open_price: float, ret_mean: float, ret_ci: list[float]) -> dict:\n",
    "    mean_px = open_price * np.exp(ret_mean)\n",
    "    lo_px   = open_price * np.exp(ret_ci[0])\n",
    "    hi_px   = open_price * np.exp(ret_ci[1])\n",
    "    return {\"px_mean\": float(mean_px), \"px_lo\": float(lo_px), \"px_hi\": float(hi_px)}\n",
    "\n",
    "def _fallback_am_pm() -> dict:\n",
    "    # Bạn có thể thay bằng block AM/PM intraday của bạn\n",
    "    return {\n",
    "        \"AM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]},\n",
    "        \"PM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]},\n",
    "    }\n",
    "\n",
    "def predict_tomorrow_full_exog(symbol: str, alpha: float = 0.10) -> dict:\n",
    "    gap = forecast_gap(symbol, alpha=alpha)\n",
    "    ampm = _fallback_am_pm()\n",
    "\n",
    "    open_am = _price_from_ret(gap[\"last_close\"], gap[\"gap_ret_mean\"], gap[\"gap_ret_ci\"])\n",
    "    am_px   = _price_from_ret(open_am[\"px_mean\"], ampm[\"AM\"][\"ret_pred\"], ampm[\"AM\"][\"ret_ci\"])\n",
    "    pm_px   = _price_from_ret(am_px[\"px_mean\"], ampm[\"PM\"][\"ret_pred\"], ampm[\"PM\"][\"ret_ci\"])\n",
    "\n",
    "    return {\n",
    "        \"target_day\": pd.Timestamp.today(tz=\"Asia/Ho_Chi_Minh\").normalize().date() + pd.Timedelta(days=1),\n",
    "        \"gap\": gap,\n",
    "        \"ampm\": ampm,\n",
    "        \"bands\": {\"OPEN_am\": open_am, \"AM_px\": am_px, \"PM_px\": pm_px},\n",
    "        \"timestamp\": get_time_vn(),\n",
    "    }\n",
    "\n",
    "\n",
    "# ===== Router thông minh (giữ như trước) =====\n",
    "from modules.ML.intraday import is_vn_trading_time, predict_next_step_in_session\n",
    "\n",
    "def smart_predict(symbol: str, alpha: float = 0.10, source: str = \"VCI\") -> dict:\n",
    "    if is_vn_trading_time():\n",
    "        intra = predict_next_step_in_session(symbol, source=source)\n",
    "        return {\n",
    "            \"mode\": \"in_session\",\n",
    "            \"symbol\": symbol,\n",
    "            \"next_step_dir\": intra[\"next_step_dir\"],\n",
    "            \"last_price\": intra[\"last_price\"],\n",
    "            \"next_price\": intra[\"next_price\"],\n",
    "            \"order\": intra[\"order\"], \"trend\": intra[\"trend\"],\n",
    "            \"pred_path\": intra[\"path_pred\"],\n",
    "            \"timestamp\": get_time_vn(),\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"mode\": \"out_of_session\",\n",
    "            \"symbol\": symbol,\n",
    "            **predict_tomorrow_full_exog(symbol, alpha=alpha),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdb63e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests/test_ml_pipeline.py\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Standalone test runner cho modules.ml.pipeline:\n",
    "- Kiểm tra train với exog (news) + meta (feature_cols, k_exog)\n",
    "- Kiểm tra forecast có exog (truyền đúng vào get_forecast)\n",
    "- Kiểm tra fallback zero-vector khi training có exog nhưng lúc dự báo thiếu news\n",
    "- Kiểm tra trường hợp không có news (use_exog=False)\n",
    "- Kiểm tra cấu trúc predict_tomorrow_full_exog\n",
    "- Kiểm tra smart router trong/ngoài phiên\n",
    "Chạy được trong notebook hoặc CLI: python tests/test_ml_pipeline.py\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import math\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# ===== Project imports\n",
    "from modules.ML import pipeline as ml_pipe\n",
    "from modules.ML import registry as ml_registry\n",
    "\n",
    "# ===== Redirect MODEL_DIR vào thư mục tạm để test không ghi đè model thật\n",
    "TMP_MODELS_DIR = tempfile.mkdtemp(prefix=\"models_\")\n",
    "os.environ[\"MODEL_DIR\"] = TMP_MODELS_DIR\n",
    "importlib.reload(ml_registry)  # để registry đọc env mới\n",
    "\n",
    "# ===== Utilities\n",
    "@contextmanager\n",
    "def patch_attr(module, attr_name, new_value):\n",
    "    old = getattr(module, attr_name, None)\n",
    "    setattr(module, attr_name, new_value)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        setattr(module, attr_name, old)\n",
    "\n",
    "def _make_price_series(days=300, seed=42):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    rets = rng.normal(loc=0.0005, scale=0.01, size=days)  # drift ~0.05%\n",
    "    logp = np.cumsum(rets) + math.log(100.0)\n",
    "    prices = np.exp(logp)\n",
    "    idx = pd.date_range(end=pd.Timestamp.now().normalize(), periods=days, freq=\"D\")\n",
    "    return pd.Series(prices, index=idx, name=\"close\")\n",
    "\n",
    "def _make_news_features(start_ts, end_ts, days=300, seed=123):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    idx = pd.date_range(end=pd.Timestamp.fromtimestamp(end_ts).normalize(), periods=days, freq=\"D\")\n",
    "    df = pd.DataFrame({\n",
    "        \"date\": idx,\n",
    "        \"news_count\": rng.integers(0, 8, size=days),\n",
    "        \"pos_count\":  rng.integers(0, 5, size=days),\n",
    "        \"neg_count\":  rng.integers(0, 5, size=days),\n",
    "        \"mean_sent\":  rng.normal(0, 0.2, size=days),\n",
    "        \"sum_sent\":   rng.normal(0, 1.0, size=days),\n",
    "    })\n",
    "    return df.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "# ===== Tiny runner (không dùng pytest)\n",
    "PASSED, FAILED = 0, 0\n",
    "def run_test(name, fn):\n",
    "    global PASSED, FAILED\n",
    "    try:\n",
    "        fn()\n",
    "        print(f\"✅ PASS: {name}\")\n",
    "        PASSED += 1\n",
    "    except AssertionError as e:\n",
    "        print(f\"❌ FAIL:  {name} -> {e}\")\n",
    "        FAILED += 1\n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR: {name} -> {type(e).__name__}: {e}\")\n",
    "        FAILED += 1\n",
    "\n",
    "def summary():\n",
    "    print(f\"\\nKết quả: {PASSED} passed / {FAILED} failed\")\n",
    "\n",
    "# ===== Tests\n",
    "\n",
    "def test_train_with_exog_meta():\n",
    "    \"\"\"\n",
    "    Train có tin (exog) -> meta ghi nhận feature_cols & k_exog > 0\n",
    "    \"\"\"\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        out = ml_pipe.train_gap_model(\"VCB\", lookback_days=240)\n",
    "        assert out[\"symbol\"] == \"VCB\"\n",
    "        assert isinstance(out[\"order\"], tuple)\n",
    "        assert out[\"trend\"] in (\"n\", \"c\")\n",
    "        assert out[\"use_exog\"] is True\n",
    "        assert len(out[\"feature_cols\"]) > 0\n",
    "        # meta có k_exog\n",
    "        fit, meta = ml_registry.load_model_meta(symbol=\"VCB\", tag=\"gap\")\n",
    "        assert fit is not None and isinstance(meta, dict)\n",
    "        assert meta.get(\"use_exog\") is True\n",
    "        assert int(meta.get(\"k_exog\", 0)) == len(out[\"feature_cols\"])\n",
    "        assert os.path.exists(out[\"saved\"])\n",
    "\n",
    "def test_forecast_gap_with_exog():\n",
    "    \"\"\"\n",
    "    Sau khi train có exog -> forecast truyền exog (shape 1,k) và res['use_exog'] True\n",
    "    \"\"\"\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        ml_pipe.train_gap_model(\"HPG\", lookback_days=240)\n",
    "        res = ml_pipe.forecast_gap(\"HPG\", alpha=0.10)\n",
    "        assert isinstance(res[\"gap_ret_mean\"], float)\n",
    "        assert len(res[\"gap_ret_ci\"]) == 2\n",
    "        assert isinstance(res[\"last_close\"], float)\n",
    "        assert res[\"use_exog\"] is True  # vì có news, X1 được build\n",
    "\n",
    "def test_forecast_gap_zero_vector_fallback_when_news_missing_now():\n",
    "    \"\"\"\n",
    "    Trường hợp train có exog nhưng lúc dự báo news trống:\n",
    "    -> _build_exog_for_forecast fallback zero-vector (shape 1,k_exog)\n",
    "    -> res['use_exog'] vẫn True (vì model cần exog, ta truyền vector 0)\n",
    "    \"\"\"\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    # train với exog\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        ml_pipe.train_gap_model(\"VNM\", lookback_days=240)\n",
    "\n",
    "    # forecast: news trống -> zero vector fallback\n",
    "    def empty_news(symbol, start_ts, end_ts):\n",
    "        return pd.DataFrame(columns=[\"date\",\"news_count\",\"pos_count\",\"neg_count\",\"mean_sent\",\"sum_sent\"])\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", empty_news):\n",
    "        res = ml_pipe.forecast_gap(\"VNM\", alpha=0.10)\n",
    "        assert isinstance(res[\"gap_ret_mean\"], float)\n",
    "        assert len(res[\"gap_ret_ci\"]) == 2\n",
    "        assert isinstance(res[\"last_close\"], float)\n",
    "        # vẫn True vì model có exog và ta đã cấp fallback vector 0\n",
    "        assert res[\"use_exog\"] is True\n",
    "\n",
    "def test_train_without_news_then_forecast_no_exog():\n",
    "    \"\"\"\n",
    "    Không có news ngay từ đầu -> model ARIMA (không exog).\n",
    "    Forecast không dùng exog -> res['use_exog'] False\n",
    "    \"\"\"\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def empty_news(symbol, start_ts, end_ts):\n",
    "        return pd.DataFrame(columns=[\"date\",\"news_count\",\"pos_count\",\"neg_count\",\"mean_sent\",\"sum_sent\"])\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", empty_news):\n",
    "        out = ml_pipe.train_gap_model(\"FPT\", lookback_days=240)\n",
    "        assert out[\"use_exog\"] is False\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", empty_news):\n",
    "        res = ml_pipe.forecast_gap(\"FPT\", alpha=0.10)\n",
    "        assert isinstance(res[\"gap_ret_mean\"], float)\n",
    "        assert len(res[\"gap_ret_ci\"]) == 2\n",
    "        assert isinstance(res[\"last_close\"], float)\n",
    "        assert res[\"use_exog\"] is False\n",
    "\n",
    "def test_predict_tomorrow_full_exog_structure():\n",
    "    \"\"\"\n",
    "    Cấu trúc output predict_tomorrow_full_exog\n",
    "    \"\"\"\n",
    "    def fake_get_close_series(symbol, days=395):\n",
    "        return _make_price_series(days=days)\n",
    "    def fake_get_prices_df(symbol, days=5):\n",
    "        s = _make_price_series(days=days)\n",
    "        return pd.DataFrame({\"close\": s.values}, index=s.index)\n",
    "    def fake_build_news_features(symbol, start_ts, end_ts):\n",
    "        return _make_news_features(start_ts, end_ts, days=300)\n",
    "\n",
    "    with patch_attr(ml_pipe, \"get_close_series\", fake_get_close_series), \\\n",
    "         patch_attr(ml_pipe, \"get_prices_df\", fake_get_prices_df), \\\n",
    "         patch_attr(ml_pipe, \"build_news_features\", fake_build_news_features):\n",
    "        res = ml_pipe.predict_tomorrow_full_exog(\"VCB\", alpha=0.10)\n",
    "        assert \"target_day\" in res and \"gap\" in res and \"ampm\" in res and \"bands\" in res\n",
    "        bands = res[\"bands\"]\n",
    "        for k in (\"OPEN_am\", \"AM_px\", \"PM_px\"):\n",
    "            assert k in bands and all(sub in bands[k] for sub in (\"px_mean\",\"px_lo\",\"px_hi\"))\n",
    "\n",
    "def test_smart_predict_in_session_router():\n",
    "    \"\"\"\n",
    "    Router: trong phiên -> dùng predict_next_step_in_session\n",
    "    \"\"\"\n",
    "    fake_is_trading = lambda: True\n",
    "    fake_pred = {\n",
    "        \"last_dt\": pd.Timestamp.now(),\n",
    "        \"last_price\": 100.0,\n",
    "        \"next_price\": 100.2,\n",
    "        \"next_step_dir\": \"↑\",\n",
    "        \"order\": (1,0,1),\n",
    "        \"trend\": \"c\",\n",
    "        \"path_pred\": pd.Series([100.2, 100.4], index=pd.date_range(pd.Timestamp.now(), periods=2, freq=\"5min\"))\n",
    "    }\n",
    "    with patch_attr(ml_pipe, \"is_vn_trading_time\", fake_is_trading), \\\n",
    "         patch_attr(ml_pipe, \"predict_next_step_in_session\", lambda s, source=\"VCI\": fake_pred), \\\n",
    "         patch_attr(ml_pipe, \"get_time_vn\", lambda: \"01-01-2025 10:00:00\"):\n",
    "        res = ml_pipe.smart_predict(\"VCB\")\n",
    "        assert res[\"mode\"] == \"in_session\"\n",
    "        assert res[\"next_step_dir\"] == \"↑\"\n",
    "        assert \"pred_path\" in res and isinstance(res[\"pred_path\"], pd.Series)\n",
    "\n",
    "def test_smart_predict_out_of_session_router():\n",
    "    \"\"\"\n",
    "    Router: ngoài giờ -> gọi predict_tomorrow_full_exog\n",
    "    \"\"\"\n",
    "    fake_is_trading = lambda: False\n",
    "    fake = {\n",
    "        \"target_day\": pd.Timestamp.now().date(),\n",
    "        \"gap\": {\"gap_ret_mean\": 0.001, \"gap_ret_ci\": [-0.002, 0.003], \"last_close\": 100.0, \"use_exog\": True},\n",
    "        \"ampm\": {\"AM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]}, \"PM\": {\"ret_pred\": 0.0, \"ret_ci\": [-0.005, 0.005]}},\n",
    "        \"bands\": {\"OPEN_am\": {\"px_mean\": 100.1, \"px_lo\": 99.8, \"px_hi\": 100.4},\n",
    "                  \"AM_px\":   {\"px_mean\": 100.1, \"px_lo\": 99.6, \"px_hi\": 100.6},\n",
    "                  \"PM_px\":   {\"px_mean\": 100.1, \"px_lo\": 99.3, \"px_hi\": 100.9}},\n",
    "        \"timestamp\": \"01-01-2025 20:00:00\"\n",
    "    }\n",
    "    with patch_attr(ml_pipe, \"is_vn_trading_time\", fake_is_trading), \\\n",
    "         patch_attr(ml_pipe, \"predict_tomorrow_full_exog\", lambda sym, alpha=0.10: fake):\n",
    "        res = ml_pipe.smart_predict(\"VCB\")\n",
    "        assert res[\"mode\"] == \"out_of_session\"\n",
    "        assert \"bands\" in res and \"gap\" in res\n",
    "\n",
    "# ===== Run all\n",
    "if __name__ == \"__main__\" or True:\n",
    "    print(f\"MODEL_DIR test: {TMP_MODELS_DIR}\")\n",
    "    tests = [\n",
    "        (\"train_with_exog_meta\", test_train_with_exog_meta),\n",
    "        (\"forecast_gap_with_exog\", test_forecast_gap_with_exog),\n",
    "        (\"forecast_gap_zero_vector_fallback_when_news_missing_now\", test_forecast_gap_zero_vector_fallback_when_news_missing_now),\n",
    "        (\"train_without_news_then_forecast_no_exog\", test_train_without_news_then_forecast_no_exog),\n",
    "        (\"predict_tomorrow_full_exog_structure\", test_predict_tomorrow_full_exog_structure),\n",
    "        (\"smart_predict_in_session_router\", test_smart_predict_in_session_router),\n",
    "        (\"smart_predict_out_of_session_router\", test_smart_predict_out_of_session_router),\n",
    "    ]\n",
    "    for name, fn in tests:\n",
    "        run_test(name, fn)\n",
    "    summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15335a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.intraday import predict_next_step_in_session\n",
    "from modules.api.stock_api import get_time_vn\n",
    "\n",
    "def predict_direction_in_session(symbol: str):\n",
    "    \"\"\"Trả về dict: hướng mũi tên, giá hiện tại, giá dự kiến kế tiếp.\"\"\"\n",
    "    sym = symbol.upper()\n",
    "    out = predict_next_step_in_session(sym)  # đã fit ARIMA trên 5m, nội suy đến hết phiên\n",
    "    arrow = out[\"next_step_dir\"]   # \"↑\" | \"↓\" | \"=\"\n",
    "    last_px = float(out[\"last_price\"])\n",
    "    next_px = float(out[\"next_price\"])\n",
    "    return {\n",
    "        \"symbol\": sym,\n",
    "        \"when\": get_time_vn(),\n",
    "        \"direction\": arrow,\n",
    "        \"last_price\": last_px,\n",
    "        \"next_price\": next_px,\n",
    "        \"delta\": round(next_px - last_px, 3),\n",
    "        \"pct\": round((next_px/last_px - 1.0)*100, 3) if last_px else 0.0\n",
    "    }\n",
    "\n",
    "# Ví dụ:\n",
    "res = predict_direction_in_session(\"VCB\")\n",
    "print(f\"⏱️ {res['when']} | {res['symbol']} • Next 5m: {res['direction']} \"\n",
    "      f\"( {res['last_price']:.2f} → {res['next_price']:.2f} | {res['delta']:+.2f} | {res['pct']:+.3f}% )\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import forecast_gap, predict_tomorrow_full_exog\n",
    "\n",
    "def direction_from_return(ret_value: float, eps: float = 1e-6) -> str:\n",
    "    if ret_value > eps:  return \"↑\"\n",
    "    if ret_value < -eps: return \"↓\"\n",
    "    return \"=\"\n",
    "\n",
    "def predict_direction_tomorrow(symbol: str, alpha: float = 0.10):\n",
    "    sym = symbol.upper()\n",
    "    gap = forecast_gap(sym, alpha=alpha)\n",
    "    bands_all = predict_tomorrow_full_exog(sym, alpha=alpha)[\"bands\"]\n",
    "\n",
    "    gap_dir = direction_from_return(gap[\"gap_ret_mean\"])\n",
    "    open_mean = bands_all[\"OPEN_am\"][\"px_mean\"]\n",
    "\n",
    "    return {\n",
    "        \"symbol\": sym,\n",
    "        \"gap_direction\": gap_dir,\n",
    "        \"gap_ret_mean\": gap[\"gap_ret_mean\"],\n",
    "        \"last_close\": gap[\"last_close\"],\n",
    "        \"open_mean\": open_mean,\n",
    "        \"open_ci90\": (bands_all[\"OPEN_am\"][\"px_lo\"], bands_all[\"OPEN_am\"][\"px_hi\"]),\n",
    "        \"use_exog\": gap.get(\"use_exog\", False),\n",
    "        \"at_11h30\": bands_all[\"AM_px\"],\n",
    "        \"at_15h00\": bands_all[\"PM_px\"],\n",
    "    }\n",
    "\n",
    "# Ví dụ:\n",
    "out = predict_direction_tomorrow(\"HPG\", alpha=0.10)\n",
    "print(\n",
    "    f\"📅 {out['symbol']} • GAP (OPEN vs CLOSE hôm qua): {out['gap_direction']} \"\n",
    "    f\"| last={out['last_close']:.0f} → OPEN~{out['open_mean']:.0f} \"\n",
    "    f\"(CI90% {out['open_ci90'][0]:.0f}-{out['open_ci90'][1]:.0f}) \"\n",
    "    f\"| exog_news={out['use_exog']}\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c54bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.api.stock_api import get_history_df_vnstock, get_prices_df\n",
    "\n",
    "df_raw = get_history_df_vnstock(\"HPG\")     # 1 năm gần nhất (mặc định)\n",
    "print(\"rows:\", len(df_raw)); display(df_raw.tail())\n",
    "\n",
    "df_model = get_prices_df(\"HPG\", days=365)  # đã chuẩn hóa cho model\n",
    "print(\"model rows:\", len(df_model)); display(df_model.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7593410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import (\n",
    "    train_gap_model, forecast_gap,\n",
    "    predict_tomorrow_full_exog,\n",
    "    predict_next_step_in_session, smart_predict\n",
    ")\n",
    "\n",
    "# Train (lần đầu cho mỗi mã)\n",
    "print(train_gap_model(\"VCB\", lookback_days=365))\n",
    "\n",
    "# Dự báo NGÀY MAI (ngoài giờ)\n",
    "print(predict_tomorrow_full_exog(\"VCB\", alpha=0.10))\n",
    "\n",
    "# Dự báo bước 5' tiếp theo (chỉ trong giờ giao dịch)\n",
    "print(predict_next_step_in_session(\"VCB\"))\n",
    "\n",
    "# Router tự quyết theo giờ VN\n",
    "print(smart_predict(\"VCB\", alpha=0.10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a548d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model\n",
    "print(train_gap_model(\"VCB\", lookback_days=365))  # kỳ vọng use_exog=True nếu có feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5f63d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import predict_tomorrow_full_exog\n",
    "res = predict_tomorrow_full_exog(\"VCB\", alpha=0.10)\n",
    "arrow = \"↑\" if res[\"gap\"][\"gap_ret_mean\"] > 0 else (\"↓\" if res[\"gap\"][\"gap_ret_mean\"] < 0 else \"=\")\n",
    "print(f\"VCB • GAP: {arrow} | OPEN~{res['bands']['OPEN_am']['px_mean']:.2f} \"\n",
    "      f\"(CI90% {res['bands']['OPEN_am']['px_lo']:.2f}-{res['bands']['OPEN_am']['px_hi']:.2f}) \"\n",
    "      f\"| exog={res['gap']['use_exog']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07381c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model, forecast_gap, predict_tomorrow_full_exog, predict_next_step_in_session, smart_predict\n",
    "\n",
    "print(train_gap_model(\"VCB\", lookback_days=365))\n",
    "print(predict_tomorrow_full_exog(\"VCB\", alpha=0.10))   # trước 09:00 / nghỉ trưa → target_day = hôm nay\n",
    "print(smart_predict(\"VCB\", alpha=0.10))                # tự chọn in/out theo giờ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import json\n",
    "from modules.ML.direction import predict_direction\n",
    "\n",
    "def run(symbol: str = \"VCB\", alpha: float = 0.10):\n",
    "    out = predict_direction(symbol, alpha)\n",
    "    print(json.dumps(out, ensure_ascii=False, default=str, indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # tránh lỗi tham số Jupyter, không parse argparse\n",
    "    run(\"VCB\", 0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa314591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.features import build_news_features\n",
    "import pandas as pd, pytz, time\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "end_ts = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = end_ts - 7*24*3600\n",
    "df_feat = build_news_features(\"VCB\", start_ts, end_ts)\n",
    "print(df_feat.head(3))\n",
    "print(df_feat.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.features import build_news_features\n",
    "import pandas as pd, pytz, time\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "end_ts = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = end_ts - 7*24*3600\n",
    "\n",
    "df_feat = build_news_features(\"VCB\", start_ts, end_ts)\n",
    "print(\"rows:\", len(df_feat))\n",
    "display(df_feat.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2bc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "cli = QdrantClient(host=\"localhost\", port=6333)\n",
    "pts, _ = cli.scroll(\"cafef_articles\", limit=3, with_payload=True)\n",
    "for p in pts:\n",
    "    print(p.payload)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc9e330",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.features import build_news_features\n",
    "import pandas as pd, pytz\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "end_ts = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = end_ts - 14*24*3600\n",
    "\n",
    "# Thử với mã chắc chắn có bài trong payload\n",
    "df_vix = build_news_features(\"VIX\", start_ts, end_ts)\n",
    "df_bid = build_news_features(\"BID\", start_ts, end_ts)\n",
    "\n",
    "# Trường hợp VCB – sẽ chỉ có nếu payload có 'symbol'=\"VCB\"\n",
    "# hoặc title/content có nhắc VCB/Vietcombank (alias ở trên)\n",
    "df_vcb = build_news_features(\"VCB\", start_ts, end_ts)\n",
    "\n",
    "display(df_vix.tail(3))\n",
    "display(df_bid.tail(3))\n",
    "display(df_vcb.tail(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9389d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.features import build_news_features\n",
    "import pandas as pd, pytz, os\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "end_ts = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = end_ts - 30*24*3600  # 30 ngày\n",
    "\n",
    "# 1) Thử lấy với alias mở rộng\n",
    "df_vcb = build_news_features(\"VCB\", start_ts, end_ts)\n",
    "print(\"rows:\", len(df_vcb))\n",
    "display(df_vcb.tail(10))\n",
    "\n",
    "# 2) Nếu vẫn rỗng, dump nhanh 5 bài mới nhất trong range để xem payload thực tế\n",
    "cli = QdrantClient(host=os.getenv(\"QDRANT_HOST\",\"localhost\"), port=int(os.getenv(\"QDRANT_PORT\",6333)))\n",
    "batch, _ = cli.scroll(collection_name=os.getenv(\"QDRANT_COLLECTION\",\"cafef_articles\"), limit=50, with_payload=True)\n",
    "cand = []\n",
    "for p in batch:\n",
    "    pl = p.payload or {}\n",
    "    ts = pl.get(\"timestamp\")\n",
    "    try:\n",
    "        ts = int(ts)\n",
    "        if ts > 10**12: ts//=1000\n",
    "    except:\n",
    "        continue\n",
    "    if start_ts <= ts <= end_ts:\n",
    "        cand.append(pl)\n",
    "\n",
    "print(\"Sample payloads in range:\", len(cand))\n",
    "for x in cand[:5]:\n",
    "    print({k: x.get(k) for k in [\"symbol\",\"title\",\"summary\",\"timestamp\",\"sentiment\"]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b4895",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model\n",
    "print(train_gap_model(\"VCB\", lookback_days=365))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7428ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import predict_tomorrow_full_exog, forecast_gap\n",
    "from modules.ML.pipeline import pick_target_trading_day\n",
    "\n",
    "def direction_from_return(x: float, eps: float = 1e-6) -> str:\n",
    "    return \"↑\" if x > eps else \"↓\" if x < -eps else \"=\"\n",
    "\n",
    "gap = forecast_gap(\"VCB\", alpha=0.10)         # trả về gap_ret_mean, CI, last_close, use_exog\n",
    "bands = predict_tomorrow_full_exog(\"VCB\", alpha=0.10)\n",
    "day  = pick_target_trading_day()              # chọn đúng “hôm nay” nếu đang pre_open/lunch; ngược lại là ngày kế tiếp\n",
    "\n",
    "arrow = direction_from_return(gap[\"gap_ret_mean\"])\n",
    "print(f\"🎯 {day} • {bands['gap']['symbol']}  GAP: {arrow} | last={gap['last_close']:.2f} \"\n",
    "      f\"→ OPEN~{bands['bands']['OPEN_am']['px_mean']:.2f} \"\n",
    "      f\"(CI90% {bands['bands']['OPEN_am']['px_lo']:.2f}-{bands['bands']['OPEN_am']['px_hi']:.2f}) \"\n",
    "      f\"| exog_news={gap['use_exog']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4825f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model, predict_direction_tomorrow, smart_predict\n",
    "\n",
    "print(train_gap_model(\"VCB\", lookback_days=365))\n",
    "\n",
    "sig = predict_direction_tomorrow(\"VCB\", alpha=0.10)\n",
    "print(\n",
    "    f\"🎯 {sig['target_day']} • {sig['symbol']}  GAP: {sig['gap_direction']} \"\n",
    "    f\"| last={sig['last_close']:.2f} → OPEN~{sig['open_mean']:.2f} \"\n",
    "    f\"(CI90% {sig['open_ci90'][0]:.2f}-{sig['open_ci90'][1]:.2f}) \"\n",
    "    f\"| exog_news={sig['use_exog']}\"\n",
    ")\n",
    "\n",
    "print(smart_predict(\"VCB\", alpha=0.10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716005a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model, predict_tomorrow_full_exog, predict_direction_tomorrow\n",
    "\n",
    "# Train (thêm exog từ index nếu muốn)\n",
    "print(train_gap_model(\"VCB\", lookback_days=365, add_index=[\"VNINDEX\",\"VN30\"]))\n",
    "\n",
    "# Dự báo phiên mục tiêu (ngoài/ trước giờ)\n",
    "print(predict_tomorrow_full_exog(\"VCB\", alpha=0.10))\n",
    "\n",
    "# Chỉ mũi tên tăng/giảm/đứng\n",
    "print(predict_direction_tomorrow(\"VCB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89c344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pytz\n",
    "from modules.ML.features import build_news_features\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "\n",
    "end_ts   = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = end_ts - 14*24*3600  # 14 ngày gần nhất\n",
    "\n",
    "fe = build_news_features(\"VCB\", start_ts, end_ts, add_index=[\"VNINDEX\",\"VN30\"])\n",
    "print(fe.tail(5))\n",
    "print(\"nonzero cols:\", {c:int((fe[c]!=0).sum()) for c in fe.columns if c!=\"date\"})\n",
    "print(\"mean_sent (VCB) last:\", fe[\"mean_sent\"].tail(5).values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234061db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "cli = QdrantClient(host=\"localhost\", port=6333)\n",
    "res = cli.scroll(\n",
    "    collection_name=\"cafef_articles\",\n",
    "    scroll_filter=models.Filter(\n",
    "        must=[models.FieldCondition(\n",
    "          key=\"index_codes\", match=models.MatchAny(any=[\"VNINDEX\"])\n",
    "        )]\n",
    "    ),\n",
    "    limit=5, with_payload=True\n",
    ")\n",
    "print(len(res[0]))  # >0 là có\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d7a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, pytz, time\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "\n",
    "now_ts  = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "start_ts = now_ts - 7*24*3600\n",
    "end_ts   = now_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29b3aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.utils.services import qdrant_services\n",
    "from qdrant_client import models\n",
    "pts, _ = qdrant_services.client.scroll(\n",
    "    collection_name=qdrant_services.collection_name,\n",
    "    scroll_filter=models.Filter(must=[\n",
    "        models.FieldCondition(key=\"index_codes\", match=models.MatchAny(any=[\"VNINDEX\"])),\n",
    "        models.FieldCondition(key=\"time_ts\", range=models.Range(gte=start_ts, lte=end_ts)),\n",
    "    ]),\n",
    "    with_payload=True,\n",
    "    limit=5\n",
    ")\n",
    "print(len(pts), [p.payload.get(\"title\") for p in pts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795b9388",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.features import build_news_features\n",
    "fe = build_news_features(\"VCB\", start_ts, end_ts, add_index=[\"VNINDEX\",\"VN30\"])\n",
    "print(fe.tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79fe3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules/ML/diagnostics.py\n",
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pytz\n",
    "from typing import Dict, Any, Optional, List, Tuple\n",
    "\n",
    "from modules.api.stock_api import get_close_series\n",
    "from modules.ML.features import build_news_features\n",
    "from modules.ML.predictors.sarimax_exog import arima_select_fit\n",
    "from modules.ML.registry import load_model_meta\n",
    "\n",
    "ICT = pytz.timezone(\"Asia/Ho_Chi_Minh\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers (local, độc lập)\n",
    "# -----------------------------\n",
    "def _to_returns(close_s: pd.Series) -> pd.Series:\n",
    "    \"\"\"Log-return theo ngày (drop NA).\"\"\"\n",
    "    r = np.log(close_s / close_s.shift(1))\n",
    "    return r.dropna()\n",
    "\n",
    "\n",
    "def _align_exog_to_y(\n",
    "    symbol: str,\n",
    "    y: pd.Series,\n",
    "    add_index: Optional[List[str]] = None,\n",
    "    shift: int = 1\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Dựng exog (tin tức) theo index của y.\n",
    "    - shift=1 để tránh look-ahead (tin hôm nay ảnh hưởng ngày mai).\n",
    "    \"\"\"\n",
    "    if y.empty:\n",
    "        return pd.DataFrame(index=y.index)\n",
    "\n",
    "    start_ts = int(pd.Timestamp(y.index[0], tz=ICT).timestamp())\n",
    "    end_ts   = int(pd.Timestamp(y.index[-1], tz=ICT).timestamp())\n",
    "\n",
    "    feats = build_news_features(symbol, start_ts, end_ts, add_index=add_index or [])\n",
    "    if feats.empty:\n",
    "        return pd.DataFrame(index=y.index)\n",
    "\n",
    "    X = feats.set_index(\"date\")\n",
    "    # đảm bảo tz-naive và cùng index y\n",
    "    X.index = pd.DatetimeIndex(X.index).tz_localize(None)\n",
    "    X = X.reindex(pd.DatetimeIndex(y.index).tz_localize(None)).fillna(0.0)\n",
    "\n",
    "    if shift:\n",
    "        X = X.shift(shift).fillna(0.0)\n",
    "\n",
    "    # đảm bảo numeric\n",
    "    for c in X.columns:\n",
    "        X[c] = pd.to_numeric(X[c], errors=\"coerce\").fillna(0.0)\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def _directional_accuracy(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"Tỷ lệ đúng hướng (↑/↓/=) trên returns.\"\"\"\n",
    "    eps = 1e-12\n",
    "    s_true = np.sign(np.where(np.abs(y_true) <= eps, 0.0, y_true))\n",
    "    s_pred = np.sign(np.where(np.abs(y_pred) <= eps, 0.0, y_pred))\n",
    "    return float((s_true == s_pred).mean())\n",
    "\n",
    "\n",
    "def _series_1d_from_endog(endog_obj, index) -> pd.Series:\n",
    "    \"\"\"Chuẩn hoá endog (có thể là ndarray 1D/2D, Series/DataFrame) → Series 1D.\"\"\"\n",
    "    if isinstance(endog_obj, pd.Series):\n",
    "        y = endog_obj.copy()\n",
    "        y.index = pd.DatetimeIndex(index).tz_localize(None)\n",
    "        return y\n",
    "    if isinstance(endog_obj, pd.DataFrame):\n",
    "        arr = np.asarray(endog_obj.values).reshape(-1)\n",
    "    else:\n",
    "        arr = np.asarray(endog_obj).reshape(-1)\n",
    "    return pd.Series(arr, index=pd.DatetimeIndex(index).tz_localize(None))\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) News coverage (sanity)\n",
    "# -----------------------------\n",
    "def recent_news_coverage(\n",
    "    symbol: str,\n",
    "    days: int = 90,\n",
    "    add_index: Optional[List[str]] = None\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Kiểm tra mức phủ tin trong N ngày gần nhất.\n",
    "    Trả về:\n",
    "      - rows, nonzero_days\n",
    "      - nonzero_cols: cột nào có giá trị khác 0 trong cửa sổ\n",
    "      - sample_tail: 5 dòng cuối (để bạn nhìn nhanh)\n",
    "    \"\"\"\n",
    "    end_ts   = int(pd.Timestamp.now(tz=ICT).timestamp())\n",
    "    start_ts = end_ts - days * 24 * 3600\n",
    "\n",
    "    fe = build_news_features(symbol, start_ts, end_ts, add_index=add_index or [])\n",
    "    if fe.empty:\n",
    "        return {\n",
    "            \"symbol\": symbol.upper(),\n",
    "            \"days_window\": days,\n",
    "            \"rows\": 0,\n",
    "            \"nonzero_days\": 0,\n",
    "            \"nonzero_cols\": {},\n",
    "            \"sample_tail\": pd.DataFrame(columns=[\"date\"])\n",
    "        }\n",
    "\n",
    "    nonzero_cols = {c: int((fe[c].fillna(0) != 0).any()) for c in fe.columns if c != \"date\"}\n",
    "    nonzero_days = int((fe.get(\"news_count\", pd.Series([0]*len(fe))) > 0).sum())\n",
    "    return {\n",
    "        \"symbol\": symbol.upper(),\n",
    "        \"days_window\": days,\n",
    "        \"rows\": int(len(fe)),\n",
    "        \"nonzero_days\": nonzero_days,\n",
    "        \"nonzero_cols\": nonzero_cols,\n",
    "        \"sample_tail\": fe.tail(5),\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Exog alignment vs model meta\n",
    "# -----------------------------\n",
    "def check_exog_alignment(symbol: str, add_index: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "    sym = symbol.upper()\n",
    "    fit, meta = load_model_meta(sym, \"gap\")\n",
    "    if fit is None or meta is None:\n",
    "        return {\"ok\": False, \"error\": \"Model/meta chưa tồn tại. Hãy train trước.\"}\n",
    "\n",
    "    use_exog = bool(meta.get(\"use_exog\", False))\n",
    "    feat_cols: List[str] = list(meta.get(\"feature_cols\", []))\n",
    "\n",
    "    # endog -> Series 1D\n",
    "    endog_idx = pd.DatetimeIndex(fit.model.data.row_labels).tz_localize(None)\n",
    "    y = _series_1d_from_endog(fit.model.endog, endog_idx)\n",
    "\n",
    "    # build exog theo cùng index\n",
    "    X = _align_exog_to_y(sym, y, add_index=add_index or [], shift=1)\n",
    "\n",
    "    report: Dict[str, Any] = {\n",
    "        \"symbol\": sym,\n",
    "        \"use_exog_meta\": use_exog,\n",
    "        \"meta_feature_cols\": feat_cols,\n",
    "        \"built_X_shape\": X.shape,\n",
    "        \"built_cols\": list(X.columns),\n",
    "        \"issues\": [],\n",
    "        \"ok\": True,\n",
    "    }\n",
    "\n",
    "    if not use_exog:\n",
    "        # Model đã train không dùng exog → không cần so chiếu cột\n",
    "        return report\n",
    "\n",
    "    if X.empty:\n",
    "        report[\"issues\"].append({\"type\": \"no_exog_now\", \"detail\": \"Không tạo được X từ tin tức hiện có.\"})\n",
    "        report[\"ok\"] = False\n",
    "        return report\n",
    "\n",
    "    built_cols = list(X.columns)\n",
    "    meta_cols  = list(feat_cols)\n",
    "\n",
    "    missing_cols = [c for c in meta_cols  if c not in built_cols]\n",
    "    extra_cols   = [c for c in built_cols if c not in meta_cols]\n",
    "    if missing_cols:\n",
    "        report[\"issues\"].append({\"type\": \"missing_cols\", \"detail\": missing_cols})\n",
    "    if extra_cols:\n",
    "        report[\"issues\"].append({\"type\": \"extra_cols\", \"detail\": extra_cols})\n",
    "    if not missing_cols and not extra_cols and built_cols != meta_cols:\n",
    "        report[\"issues\"].append({\"type\": \"column_order_mismatch\", \"detail\": {\"built\": built_cols, \"meta\": meta_cols}})\n",
    "\n",
    "    if X.shape[0] != len(y):\n",
    "        report[\"issues\"].append({\"type\": \"row_mismatch\", \"detail\": (X.shape[0], len(y))})\n",
    "\n",
    "    report[\"ok\"] = (len(report[\"issues\"]) == 0)\n",
    "    return report\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Backtest: exog vs no-exog\n",
    "# -----------------------------\n",
    "def backtest_arima_exog(\n",
    "    symbol: str,\n",
    "    lookback_days: int = 365,\n",
    "    test_ratio: float = 0.2,\n",
    "    add_index: Optional[List[str]] = None,\n",
    "    d: int = 0,\n",
    "    max_p: int = 3,\n",
    "    max_q: int = 3,\n",
    "    trends: Tuple[str, ...] = (\"n\", \"c\"),\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Backtest (time split) cho 2 mô hình:\n",
    "      - SARIMA (no exog)\n",
    "      - SARIMAX (with exog từ Qdrant)\n",
    "    Trả về MAE, RMSE, Directional Accuracy trên tập test.\n",
    "    \"\"\"\n",
    "    sym = symbol.upper()\n",
    "\n",
    "    # 1) Endog = log-return\n",
    "    close = get_close_series(sym, days=lookback_days)\n",
    "    if close is None or len(close) < 60:\n",
    "        raise ValueError(\"Không đủ dữ liệu giá để backtest.\")\n",
    "    y = _to_returns(close)\n",
    "    if len(y) < 30:\n",
    "        raise ValueError(\"Không đủ số điểm returns.\")\n",
    "\n",
    "    # 2) Exog aligned + shift(1)\n",
    "    X = _align_exog_to_y(sym, y, add_index=add_index or [], shift=1)\n",
    "\n",
    "    # 3) Split theo thời gian\n",
    "    n = len(y)\n",
    "    n_test = max(10, int(n * test_ratio))\n",
    "    n_train = n - n_test\n",
    "    y_tr, y_te = y.iloc[:n_train], y.iloc[n_train:]\n",
    "    X_tr = X.iloc[:n_train] if not X.empty else pd.DataFrame(index=y_tr.index)\n",
    "    X_te = X.iloc[n_train:] if not X.empty else pd.DataFrame(index=y_te.index)\n",
    "\n",
    "    # 4) Fit 2 mô hình\n",
    "    fit_no_exog, order0, trend0 = arima_select_fit(\n",
    "        y_tr, d=d, max_p=max_p, max_q=max_q, trends=trends, exog=None\n",
    "    )\n",
    "    if not X_tr.empty:\n",
    "        fit_exog, order1, trend1 = arima_select_fit(\n",
    "            y_tr, d=d, max_p=max_p, max_q=max_q, trends=trends, exog=X_tr\n",
    "        )\n",
    "    else:\n",
    "        fit_exog, order1, trend1 = None, None, None\n",
    "\n",
    "    # 5) Forecast (one-shot trên cửa sổ test)\n",
    "    fc_no = fit_no_exog.get_forecast(steps=len(y_te))\n",
    "    yhat_no = np.asarray(fc_no.predicted_mean, dtype=float)\n",
    "\n",
    "    if fit_exog is not None and not X_te.empty:\n",
    "        fc_ex = fit_exog.get_forecast(steps=len(y_te), exog=X_te)\n",
    "        yhat_ex = np.asarray(fc_ex.predicted_mean, dtype=float)\n",
    "    else:\n",
    "        yhat_ex = None\n",
    "\n",
    "    # 6) Metrics\n",
    "    def _metrics(y_true, y_pred) -> Dict[str, float]:\n",
    "        y_true = np.asarray(y_true, dtype=float)\n",
    "        y_pred = np.asarray(y_pred, dtype=float)\n",
    "        mae  = float(np.mean(np.abs(y_true - y_pred)))\n",
    "        rmse = float(np.sqrt(np.mean((y_true - y_pred) ** 2)))\n",
    "        da   = _directional_accuracy(y_true, y_pred)\n",
    "        return {\"MAE\": mae, \"RMSE\": rmse, \"DA\": da}\n",
    "\n",
    "    m_no = _metrics(y_te.values, yhat_no)\n",
    "    m_ex = _metrics(y_te.values, yhat_ex) if yhat_ex is not None else None\n",
    "\n",
    "    return {\n",
    "        \"symbol\": sym,\n",
    "        \"n_total\": n,\n",
    "        \"n_train\": n_train,\n",
    "        \"n_test\": n_test,\n",
    "        \"order_no_exog\": order0,\n",
    "        \"trend_no_exog\": trend0,\n",
    "        \"order_exog\": order1,\n",
    "        \"trend_exog\": trend1,\n",
    "        \"metrics_no_exog\": m_no,\n",
    "        \"metrics_exog\": m_ex,\n",
    "        \"has_exog\": bool(fit_exog is not None and yhat_ex is not None),\n",
    "        \"test_start\": str(y_te.index[0].date()) if len(y_te) else None,\n",
    "        \"test_end\": str(y_te.index[-1].date()) if len(y_te) else None,\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_models_report(symbol: str, **kwargs) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Wrapper backtest và tóm tắt so sánh exog vs no-exog.\n",
    "    \"\"\"\n",
    "    res = backtest_arima_exog(symbol, **kwargs)\n",
    "    note = (\n",
    "        \"Exog giúp cải thiện\"\n",
    "        if (res.get(\"metrics_exog\") and res[\"metrics_exog\"][\"MAE\"] < res[\"metrics_no_exog\"][\"MAE\"])\n",
    "        else \"Exog chưa cải thiện (hoặc chưa dùng)\"\n",
    "    )\n",
    "    return {\n",
    "        \"symbol\": res[\"symbol\"],\n",
    "        \"window\": f\"{res['n_train']} train / {res['n_test']} test\",\n",
    "        \"order_no_exog\": res[\"order_no_exog\"],\n",
    "        \"order_exog\": res[\"order_exog\"],\n",
    "        \"metrics_no_exog\": res[\"metrics_no_exog\"],\n",
    "        \"metrics_exog\": res[\"metrics_exog\"],\n",
    "        \"has_exog\": res[\"has_exog\"],\n",
    "        \"period_test\": (res[\"test_start\"], res[\"test_end\"]),\n",
    "        \"note\": note,\n",
    "    }\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Console helper\n",
    "# -----------------------------\n",
    "def print_diagnostics(symbol: str, add_index: Optional[List[str]] = None, recent_days: int = 90):\n",
    "    print(\"=== [Coverage] ===\")\n",
    "    cov = recent_news_coverage(symbol, days=recent_days, add_index=add_index or [])\n",
    "    print(f\"Symbol: {cov['symbol']} | window: {cov['days_window']}d | rows: {cov['rows']}\")\n",
    "    print(\"nonzero_days(news_count>0):\", cov[\"nonzero_days\"])\n",
    "    print(\"nonzero_cols:\", cov[\"nonzero_cols\"])\n",
    "    print(cov[\"sample_tail\"])\n",
    "\n",
    "    print(\"\\n=== [Alignment] ===\")\n",
    "    align = check_exog_alignment(symbol, add_index=add_index or [])\n",
    "    print(\"use_exog_meta:\", align.get(\"use_exog_meta\"))\n",
    "    print(\"built_X_shape:\", align.get(\"built_X_shape\"))\n",
    "    print(\"meta_feature_cols:\", align.get(\"meta_feature_cols\"))\n",
    "    print(\"built_cols:\", align.get(\"built_cols\"))\n",
    "    print(\"issues:\", align.get(\"issues\"))\n",
    "    print(\"OK:\", align.get(\"ok\"))\n",
    "\n",
    "    print(\"\\n=== [Backtest] ===\")\n",
    "    rep = compare_models_report(symbol, lookback_days=365, test_ratio=0.25, add_index=add_index or [])\n",
    "    print(\"period_test:\", rep[\"period_test\"])\n",
    "    print(\"order_no_exog:\", rep[\"order_no_exog\"], \"| order_exog:\", rep[\"order_exog\"])\n",
    "    print(\"metrics_no_exog:\", rep[\"metrics_no_exog\"])\n",
    "    print(\"metrics_exog:\", rep[\"metrics_exog\"])\n",
    "    print(\"has_exog:\", rep[\"has_exog\"])\n",
    "    print(\"note:\", rep[\"note\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(recent_news_coverage(\"VCB\", days=90, add_index=[\"VNINDEX\",\"VN30\"]))\n",
    "print(check_exog_alignment(\"VCB\", add_index=[\"VNINDEX\",\"VN30\"]))\n",
    "print(compare_models_report(\"VCB\", lookback_days=400, test_ratio=0.25, add_index=[\"VNINDEX\",\"VN30\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd80c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import train_gap_model, predict_tomorrow_full_exog, predict_direction_tomorrow\n",
    "\n",
    "print(train_gap_model(\"VCB\", lookback_days=365, add_index=[\"VNINDEX\",\"VN30\"]))\n",
    "print(predict_tomorrow_full_exog(\"VCB\"))\n",
    "print(predict_direction_tomorrow(\"VCB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb4283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ML.pipeline import smart_predict, train_gap_model, forecast_gap\n",
    "print(smart_predict(\"VCB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed078097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "W1024 15:01:06.511000 27848 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection `cafef_articles` đã tồn tại.\n",
      "EmbedderServices device: cuda\n",
      "RerankerServices device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "`return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mode': 'next_session', 'symbol': 'FPT', 'timestamp': '24-10-2025 15:01:26', 'next_session': 'AM', 'target_day': datetime.date(2025, 10, 27), 'open_band': {'px_mean': 97.7733318119878, 'px_lo': 95.3892856840437, 'px_hi': 100.21696194771023}, 'gap': {'symbol': 'FPT', 'gap_ret_mean': 0.0007502999488289655, 'gap_ret_ci': [-0.02393529629324368, 0.025435896190901613], 'last_close': 97.7, 'use_exog': True}, 'open_direction': 'tăng', 'open_gap_pct': 0.075, 'open_confidence': 'uncertain', 'note': 'AM dùng band OPEN (ước lượng khoảng mở cửa).'}\n"
     ]
    }
   ],
   "source": [
    "from modules.ML.pipeline import smart_predict\n",
    "\n",
    "# Tự động chọn chế độ: trong phiên → bước tiếp theo; ngoài giờ → phiên kế tiếp\n",
    "res = smart_predict(\"FPT\")\n",
    "print(res)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82fa5cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     open  high   low  close   volume\n",
      "time                                                 \n",
      "2025-10-24 14:45:00  97.7  97.7  97.7   97.7  90500.0\n"
     ]
    }
   ],
   "source": [
    "from modules.api.stock_api import get_intraday_df\n",
    "\n",
    "df = get_intraday_df(\"FPT\", interval=\"1m\", days=1, debug=True)\n",
    "print(df.tail(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c39fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [TEST] smart_predict() ===\n",
      "{'error': None,\n",
      " 'last_px': 59.7,\n",
      " 'mode': 'in_session',\n",
      " 'next_step_dir': 'giảm',\n",
      " 'path_pred': t+step\n",
      "1    59.680020\n",
      "2    59.660047\n",
      "3    59.640080\n",
      "dtype: float64,\n",
      " 'ret_mean': -0.00033472811160588297,\n",
      " 'ret_std': 0.001831466880738437,\n",
      " 'session': 'AM',\n",
      " 'source_used': 'intraday',\n",
      " 'step_confidence': 'low',\n",
      " 'symbol': 'VCB',\n",
      " 'timestamp': '27-10-2025 09:23:12'}\n",
      "\n",
      "Mode dự báo: in_session\n",
      "- Đang ở phiên AM\n",
      "- next_step_dir (đi tiếp trong vài bước tới): giảm\n",
      "- step_confidence: low\n",
      "- last_px: 59.7\n",
      "- path_pred (giá ước lượng các bước kế tiếp):\n",
      "t+step\n",
      "1    59.680020\n",
      "2    59.660047\n",
      "3    59.640080\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "=== [TEST] predict_next_session() ===\n",
      "{'base_from': 'AM_close',\n",
      " 'mode': 'next_session',\n",
      " 'next_session': 'PM',\n",
      " 'note': 'PM dựa trên giá kết thúc buổi sáng và band PM mặc định.',\n",
      " 'pm_band': {'px_hi': 59.99924749530624,\n",
      "             'px_lo': 59.40224500780314,\n",
      "             'px_mean': 59.7},\n",
      " 'pm_confidence': 'uncertain',\n",
      " 'pm_direction': 'không thay đổi',\n",
      " 'pm_gap_pct': 0.0,\n",
      " 'target_day': datetime.date(2025, 10, 27),\n",
      " 'timestamp': '27-10-2025 09:23:13'}\n",
      "\n",
      "Phiên kế tiếp: PM\n",
      "→ Dự báo khung giá buổi chiều (PM_band): {'px_mean': 59.7, 'px_lo': 59.40224500780314, 'px_hi': 59.99924749530624}\n",
      "→ Hướng: không thay đổi\n",
      "→ Độ tự tin: uncertain\n",
      "→ Dựa trên: AM_close\n",
      "\n",
      "\n",
      "=== [TEST] Snapshot thị trường chung ===\n",
      "[VNStock] Lỗi chỉ số HNX: Không lấy được lịch sử cho HNX từ VCI/TCBS/MSN\n",
      "[VNStock] Lỗi chỉ số UPCOM: Không lấy được lịch sử cho UPCOM từ VCI/TCBS/MSN\n",
      "📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n",
      "📈 **VNINDEX**: 1,690.23 điểm (+7.05, +0.42%)  \n",
      "📈 **VN30**: 1,949.41 điểm (+4.81, +0.25%)  \n",
      "\n",
      "🚀 Top tăng mạnh:\n",
      "- BTH: 70.0 (+172247.81%), GTGD~1\n",
      "- TCO: 10.55 (+11900.59%), GTGD~1\n",
      "- VNI: nan (+8736.93%), GTGD~0  \n",
      "\n",
      "⚠️ Top giảm mạnh:\n",
      "- PTC: nan (-99.96%), GTGD~0\n",
      "- TOP: nan (-99.67%), GTGD~0\n",
      "- HTP: nan (-98.51%), GTGD~0  \n",
      "🕒 Cập nhật: 27-10-2025 09:23:35\n",
      "\n",
      "--- Giá hiện tại mã VCB ---\n",
      "{'change': 200.0,\n",
      " 'fallback': False,\n",
      " 'high': 63600.0,\n",
      " 'low': 55400.0,\n",
      " 'market_date': '27-10-2025',\n",
      " 'open': 59500.0,\n",
      " 'percent_change': 0.34,\n",
      " 'price': 59700.0,\n",
      " 'source': 'VNStock.Trading',\n",
      " 'symbol': 'VCB',\n",
      " 'timestamp': '27-10-2025 09:23:36',\n",
      " 'volume': 114600}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tests/test_forecast_next_session.py\n",
    "import pprint\n",
    "from modules.ML.pipeline import smart_predict, predict_next_session\n",
    "from modules.api.stock_api import get_stock_quote\n",
    "from modules.api.stock_api import format_market_summary\n",
    "\n",
    "TEST_SYMBOL = \"VCB\"\n",
    "\n",
    "def test_smart_predict():\n",
    "    print(\"=== [TEST] smart_predict() ===\")\n",
    "    pack = smart_predict(TEST_SYMBOL)\n",
    "    pprint.pprint(pack)\n",
    "\n",
    "    # Gợi ý cách đọc kết quả\n",
    "    mode = pack.get(\"mode\")\n",
    "    print(f\"\\nMode dự báo: {mode}\")\n",
    "    if mode == \"in_session\":\n",
    "        print(f\"- Đang ở phiên {pack.get('session')}\")\n",
    "        print(f\"- next_step_dir (đi tiếp trong vài bước tới): {pack.get('next_step_dir')}\")\n",
    "        print(f\"- step_confidence: {pack.get('step_confidence')}\")\n",
    "        print(f\"- last_px: {pack.get('last_px')}\")\n",
    "        print(f\"- path_pred (giá ước lượng các bước kế tiếp):\\n{pack.get('path_pred')}\")\n",
    "    else:\n",
    "        # out_of_session / next_session mode\n",
    "        print(f\"- next_session: {pack.get('next_session')}\")\n",
    "        if pack.get('open_direction'):\n",
    "            print(f\"  open_direction: {pack['open_direction']}\")\n",
    "            print(f\"  open_gap_pct: {pack['open_gap_pct']}%\")\n",
    "            print(f\"  open_confidence: {pack['open_confidence']}\")\n",
    "            print(f\"  OPEN_am band: {pack.get('bands',{}).get('OPEN_am')}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "def test_predict_next_session():\n",
    "    print(\"=== [TEST] predict_next_session() ===\")\n",
    "    pack = predict_next_session(TEST_SYMBOL)\n",
    "    pprint.pprint(pack)\n",
    "\n",
    "    print(f\"\\nPhiên kế tiếp: {pack.get('next_session')}\")\n",
    "    if \"open_band\" in pack:\n",
    "        # AM scenario\n",
    "        print(\"→ Dự báo khoảng giá mở cửa (OPEN_am):\", pack[\"open_band\"])\n",
    "        print(\"→ Hướng:\", pack.get(\"open_direction\"))\n",
    "        print(\"→ Độ tự tin:\", pack.get(\"open_confidence\"))\n",
    "        print(\"→ Gap % so với đóng cửa phiên trước:\", pack.get(\"open_gap_pct\"), \"%\")\n",
    "    elif \"pm_band\" in pack:\n",
    "        # PM scenario\n",
    "        print(\"→ Dự báo khung giá buổi chiều (PM_band):\", pack[\"pm_band\"])\n",
    "        print(\"→ Hướng:\", pack.get(\"pm_direction\"))\n",
    "        print(\"→ Độ tự tin:\", pack.get(\"pm_confidence\"))\n",
    "        print(\"→ Dựa trên:\", pack.get(\"base_from\"))\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "def test_market_snapshot():\n",
    "    print(\"=== [TEST] Snapshot thị trường chung ===\")\n",
    "    # Kiểm tra nhanh để đảm bảo API index / tổng quan thị trường không chết\n",
    "    print(format_market_summary())\n",
    "\n",
    "    # Kiểm tra realtime 1 mã để đối chiếu với dự báo\n",
    "    print(\"\\n--- Giá hiện tại mã\", TEST_SYMBOL, \"---\")\n",
    "    data = get_stock_quote(TEST_SYMBOL)\n",
    "    pprint.pprint(data)\n",
    "    print(\"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_smart_predict()\n",
    "    test_predict_next_session()\n",
    "    test_market_snapshot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7c9b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== [TEST] SARIMAX train & đánh giá nội bộ ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Model saved: models\\VCB_gap.pkl\n",
      "- Meta saved : models\\VCB_gap.json\n",
      "\n",
      "--- META ---\n",
      "symbol: VCB\n",
      "order: [1, 0, 0]\n",
      "trend: n\n",
      "use_exog: True\n",
      "feature_cols: ['news_count', 'pos_count', 'neg_count', 'neu_count', 'mean_sent', 'sum_sent', 'ret_lag1', 'ret_lag2', 'ret_lag5']\n",
      "scaler: {'news_count': {'mu': 0.0, 'sd': 1.0}, 'pos_count': {'mu': 0.0, 'sd': 1.0}, 'neg_count': {'mu': 0.0, 'sd': 1.0}, 'neu_count': {'mu': 0.0, 'sd': 1.0}, 'mean_sent': {'mu': 0.0, 'sd': 1.0}, 'sum_sent': {'mu': 0.0, 'sd': 1.0}, 'ret_lag1': {'mu': -5.007558725072949e-05, 'sd': 0.012279129799331172}, 'ret_lag2': {'mu': -0.00010303191597674378, 'sd': 0.017594109387141794}, 'ret_lag5': {'mu': -0.0002205868864140254, 'sd': 0.024495925614274057}}\n",
      "train_len: 364\n",
      "timestamp: 25-10-2025 14:26:08\n",
      "target: gap_ret\n",
      "add_index: ['VNINDEX', 'VN30']\n",
      "\n",
      "--- Hiệu suất in-sample ---\n",
      "RMSE (trên log-return): 0.012487\n",
      "MAPE (trên log-return): 49920.896584\n",
      "AIC  : -2155.4299817259543\n",
      "\n",
      "Close series tail:\n",
      "_dt\n",
      "2025-10-20    59.4\n",
      "2025-10-21    59.3\n",
      "2025-10-22    59.6\n",
      "2025-10-23    59.8\n",
      "2025-10-24    59.5\n",
      "Freq: D, Name: close, dtype: float64\n",
      "\n",
      "Last close: 59.500  → Dự báo next(px): 59.325 (ret_hat=-0.00294)\n"
     ]
    }
   ],
   "source": [
    "# tests/test_sarimax_train_eval.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from modules.ML.pipeline import train_gap_model\n",
    "from modules.ML.registry import load_model_meta\n",
    "from modules.ML.metrics import rmse, mape\n",
    "from modules.api.stock_api import get_close_series\n",
    "\n",
    "TEST_SYMBOL = \"VCB\"\n",
    "\n",
    "def test_train_and_evaluate(lookback_days=365):\n",
    "    print(\"=== [TEST] SARIMAX train & đánh giá nội bộ ===\")\n",
    "\n",
    "    # 1. Train và lưu model/meta\n",
    "    model_path, meta_path = train_gap_model(TEST_SYMBOL, lookback_days=lookback_days)\n",
    "    print(f\"- Model saved: {model_path}\")\n",
    "    print(f\"- Meta saved : {meta_path}\")\n",
    "\n",
    "    # 2. Load lại để chắc chắn có thể đọc\n",
    "    model, meta = load_model_meta(TEST_SYMBOL, \"gap\")\n",
    "    if model is None or meta is None:\n",
    "        print(\"Không load được model sau khi train.\")\n",
    "        return\n",
    "    \n",
    "    print(\"\\n--- META ---\")\n",
    "    for k,v in meta.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "    # Lấy endog gốc (log-returns) từ model\n",
    "    # statsmodels SARIMAXResults lưu data trong model.model\n",
    "    try:\n",
    "        endog = model.model.endog  # numpy array, log-return y_t\n",
    "    except Exception as e:\n",
    "        print(\"Không đọc được endog từ model:\", e)\n",
    "        return\n",
    "\n",
    "    fitted = model.fittedvalues  # giá trị dự báo nội bộ in-sample\n",
    "    if hasattr(fitted, \"values\"):\n",
    "        fitted = fitted.values\n",
    "\n",
    "    # align độ dài\n",
    "    n = min(len(endog), len(fitted))\n",
    "    y_true = np.array(endog[-n:], dtype=\"float64\")\n",
    "    y_pred = np.array(fitted[-n:], dtype=\"float64\")\n",
    "\n",
    "    err_rmse = rmse(y_true, y_pred)\n",
    "    err_mape = mape(y_true, y_pred)\n",
    "\n",
    "    print(\"\\n--- Hiệu suất in-sample ---\")\n",
    "    print(f\"RMSE (trên log-return): {err_rmse:.6f}\")\n",
    "    print(f\"MAPE (trên log-return): {err_mape:.6f}\")\n",
    "    print(\"AIC  :\", getattr(model, \"aic\", None))\n",
    "\n",
    "    # 3. Diễn giải: quy đổi log-return dự báo vs giá thật\n",
    "    closes = get_close_series(TEST_SYMBOL, days=lookback_days)\n",
    "    closes = closes.dropna()\n",
    "    print(\"\\nClose series tail:\")\n",
    "    print(closes.tail())\n",
    "\n",
    "    # Tính thử ví dụ: dùng last_close và dự báo one-step ahead\n",
    "    if len(closes) > 0:\n",
    "        last_close = float(closes.iloc[-1])\n",
    "        if len(y_pred) > 0:\n",
    "            ret_hat = y_pred[-1]\n",
    "            px_hat  = last_close * np.exp(ret_hat)\n",
    "            print(f\"\\nLast close: {last_close:.3f}  → Dự báo next(px): {px_hat:.3f} (ret_hat={ret_hat:.5f})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11b02a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "W1027 09:21:02.560000 21436 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection `cafef_articles` đã tồn tại.\n",
      "EmbedderServices device: cuda\n",
      "RerankerServices device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "`return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "Maximum Likelihood optimization failed to converge. Check mle_retvals\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Model saved: models\\VCB_gap.pkl\n",
      "- Meta saved : models\\VCB_gap.json\n",
      "\n",
      "--- META ---\n",
      "symbol: VCB\n",
      "order: [1, 0, 0]\n",
      "trend: n\n",
      "use_exog: True\n",
      "feature_cols: ['news_count', 'pos_count', 'neg_count', 'neu_count', 'mean_sent', 'sum_sent', 'idx_VNINDEX_news_count', 'idx_VNINDEX_pos_count', 'idx_VNINDEX_neg_count', 'idx_VNINDEX_neu_count', 'idx_VNINDEX_mean_sent', 'idx_VNINDEX_sum_sent', 'idx_VN30_news_count', 'idx_VN30_pos_count', 'idx_VN30_neg_count', 'idx_VN30_neu_count', 'idx_VN30_mean_sent', 'idx_VN30_sum_sent', 'ret_lag1', 'ret_lag2', 'ret_lag5']\n",
      "scaler: {'news_count': {'mu': 0.008241758241758242, 'sd': 0.09053369044416568}, 'pos_count': {'mu': 0.0027472527472527475, 'sd': 0.052414241836095915}, 'neg_count': {'mu': 0.0, 'sd': 1.0}, 'neu_count': {'mu': 0.005494505494505495, 'sd': 0.0740227607951281}, 'mean_sent': {'mu': 0.0027386276972490354, 'sd': 0.035715182961767074}, 'sum_sent': {'mu': 0.0027386276972490354, 'sd': 0.035715182961767074}, 'idx_VNINDEX_news_count': {'mu': 0.008241758241758242, 'sd': 0.09053369044416568}, 'idx_VNINDEX_pos_count': {'mu': 0.0027472527472527475, 'sd': 0.052414241836095915}, 'idx_VNINDEX_neg_count': {'mu': 0.0, 'sd': 1.0}, 'idx_VNINDEX_neu_count': {'mu': 0.005494505494505495, 'sd': 0.0740227607951281}, 'idx_VNINDEX_mean_sent': {'mu': 0.002575468476657029, 'sd': 0.031880668755000376}, 'idx_VNINDEX_sum_sent': {'mu': 0.002575468476657029, 'sd': 0.031880668755000376}, 'idx_VN30_news_count': {'mu': 0.005494505494505495, 'sd': 0.0740227607951281}, 'idx_VN30_pos_count': {'mu': 0.0, 'sd': 1.0}, 'idx_VN30_neg_count': {'mu': 0.0, 'sd': 1.0}, 'idx_VN30_neu_count': {'mu': 0.005494505494505495, 'sd': 0.0740227607951281}, 'idx_VN30_mean_sent': {'mu': 0.0006989550336704149, 'sd': 0.009673252600768583}, 'idx_VN30_sum_sent': {'mu': 0.0006989550336704149, 'sd': 0.009673252600768583}, 'ret_lag1': {'mu': -6.65977989747447e-05, 'sd': 0.012281779416720684}, 'ret_lag2': {'mu': -0.0001331955979494924, 'sd': 0.01759518593759268}, 'ret_lag5': {'mu': -0.0003028253129009673, 'sd': 0.02457989695334142}}\n",
      "train_len: 364\n",
      "timestamp: 27-10-2025 09:21:54\n",
      "target: gap_ret\n",
      "add_index: ['VNINDEX', 'VN30']\n",
      "aic: -2129.7149668499505\n",
      "rmse_in_sample: 0.012068382163758237\n",
      "mae_in_sample: 0.006544079091570114\n",
      "last_close: 59.8\n",
      "ret_hat_next: 7.859905196408807e-05\n",
      "next_price_est: 59.804700408028836\n",
      "\n",
      "--- Hiệu suất in-sample ---\n",
      "RMSE (log-return): 0.012068\n",
      "MAE  (log-return): 0.006544\n",
      "AIC              : -2129.7149668499505\n",
      "\n",
      "Close series tail:\n",
      "_dt\n",
      "2025-10-23    59.8\n",
      "2025-10-24    59.5\n",
      "2025-10-25    59.5\n",
      "2025-10-26    59.5\n",
      "2025-10-27    59.8\n",
      "Freq: D, Name: close, dtype: float64\n",
      "\n",
      "Last close: 59.800  → Dự báo next(px): 59.805 (ret_hat=+0.00008)\n",
      ">>> eval_report = {'rmse': 0.012068382163758237, 'mae': 0.006544079091570114, 'aic': -2129.7149668499505, 'last_close': 59.8, 'ret_hat_next': 7.859905196408807e-05, 'next_price_est': 59.804700408028836}\n",
      "\n",
      ">>> smart_predict\n",
      "{'mode': 'in_session', 'session': 'AM', 'symbol': 'VCB', 'timestamp': '27-10-2025 09:21:55', 'error': None, 'next_step_dir': 'tăng', 'ret_mean': 0.0006688969445694389, 'ret_std': 0.0009159253965682712, 'step_confidence': 'medium', 'last_px': 59.9, 'path_pred': t+step\n",
      "1    59.940080\n",
      "2    59.980187\n",
      "3    60.020321\n",
      "dtype: float64, 'source_used': 'intraday'}\n",
      "\n",
      ">>> forecast_gap\n",
      "{'symbol': 'VCB', 'gap_ret_mean': 7.859905196408807e-05, 'gap_ret_ci': [-0.01979944033622664, 0.019956638440154814], 'last_close': 59.9, 'use_exog': True}\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from modules.ML import pipeline\n",
    "reload(pipeline)\n",
    "\n",
    "fit, meta, eval_report = pipeline.train_gap_model(\"VCB\")\n",
    "print(\">>> eval_report =\", eval_report)\n",
    "\n",
    "print(\"\\n>>> smart_predict\")\n",
    "print(pipeline.smart_predict(\"VCB\"))\n",
    "\n",
    "print(\"\\n>>> forecast_gap\")\n",
    "print(pipeline.forecast_gap(\"VCB\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c9068c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📅 Phiên sáng (AM) sắp tới của VCB (2025-10-27):\n",
      "- Giá mở cửa dự kiến khoảng 59.43 VNĐ (dải 58.26 ~ 60.62).\n",
      "- Dự kiến giảm khoảng -0.12%.\n",
      "- Mức độ tự tin mô hình: uncertain.\n",
      "⚠️ Đây chỉ là ước lượng dựa trên tin tức & hành vi giá gần nhất, không phải khuyến nghị đầu tư.\n"
     ]
    }
   ],
   "source": [
    "from modules.api.stock_api import format_forecast_text\n",
    "from modules.ML.pipeline import smart_predict\n",
    "\n",
    "pack = smart_predict(\"VCB\")\n",
    "print(format_forecast_text(\"VCB\", pack))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
