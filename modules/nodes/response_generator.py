from modules.core.state import GlobalState
from modules.utils.debug import add_debug_info
from modules.utils.services import llm_services
from datetime import datetime
import re

def response_node(state: GlobalState, max_history: int = 50) -> GlobalState:
    """
    Node cu·ªëi c√πng sinh ph·∫£n h·ªìi cho ng∆∞·ªùi d√πng.
    Quy t·∫Øc:
    - N·∫øu route_to = API ‚Üí tr·∫£ ngay api_response
    - N·∫øu greeting ‚Üí tr·∫£ l·ªùi ch√†o th√¢n thi·ªán
    - N·∫øu RAG / Hybrid ‚Üí g·ªçi LLM sinh n·ªôi dung t·ª´ prompt
    """
    route = getattr(state, "route_to", "")
    intent = getattr(state, "intent", "rag")

    if route not in ["rag", "hybrid"]:
        result = state.api_response or "Kh√¥ng c√≥ ph·∫£n h·ªìi API"
        state.mark_api_response(
            api_type=state.api_type or "api",
            result=result,
            text=result
        )
        if state.user_query:
            state.conversation_history.append({"role": "user", "content": state.user_query})
        state.conversation_history.append({"role": "assistant", "content": result})
        state.final_answer = result
        state.response = result
        return state

    if getattr(state, "is_greeting", False) or intent == "greeting":
        msg = "üëã Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p g√¨ cho b·∫°n?"
        state.set_final_answer(msg, route="Greeting")
        return state

    if not state.prompt:
        msg = "Kh√¥ng th·ªÉ t·∫°o prompt ‚Äî thi·∫øu d·ªØ li·ªáu RAG."
        state.set_final_answer(msg, route="RAG")
        return state

    try:
        if not hasattr(llm_services, "model"):
            msg = "LLM ch∆∞a ƒë∆∞·ª£c kh·ªüi t·∫°o."
            state.set_final_answer(msg, route="RAG")
            add_debug_info(state, "llm_status", "model_not_initialized")
            return state

        outputs = llm_services.model.invoke(
            [
                {"role": "user", "content": state.prompt},
                {"role": "assistant", "content": ""}
            ],
            temperature=0.7,
            max_tokens=2048
        )

        # Chu·∫©n h√≥a k·∫øt qu·∫£ tr·∫£ v·ªÅ
        if isinstance(outputs, str):
            text = outputs.strip()
        elif isinstance(outputs, list):
            if len(outputs) > 0 and isinstance(outputs[0], dict):
                text = outputs[0].get("content") or outputs[0].get("text") or str(outputs[0])
            else:
                text = " ".join(map(str, outputs))
        elif hasattr(outputs, "content"):
            text = outputs.content.strip()
        else:
            text = str(outputs)

        # L√†m s·∫°ch markdown, code block, URL, t·ª´ kh√≥a kh√¥ng c·∫ßn thi·∫øt
        assistant_msg = re.sub(r"```[\s\S]*?```", "", text)
        assistant_msg = re.sub(r"http\S+", "(link)", assistant_msg)
        assistant_msg = re.sub(r"^(Assistant:|User:|Tr·ª£ l√Ω:|Ng∆∞·ªùi d√πng:)\s*", "", assistant_msg, flags=re.I).strip()

        # N·∫øu LLM tr·∫£ v·ªÅ qu√° ng·∫Øn ho·∫∑c tr·ªëng, fallback t·ª± t√≥m t·∫Øt context
        if len(assistant_msg.split()) < 10:
            if state.intent == "market" and getattr(state, "api_response", None):
                assistant_msg = f"üìä D·ªØ li·ªáu th·ªã tr∆∞·ªùng:\n{state.api_response}\n(Tin t·ª©c g·∫ßn ƒë√¢y ch∆∞a kh·∫£ d·ª•ng ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt.)"
            else:
                assistant_msg = "Hi·ªán ch∆∞a c√≥ ƒë·ªß d·ªØ li·ªáu ƒë·ªÉ ph√¢n t√≠ch chi ti·∫øt."
        # C·∫≠p nh·∫≠t h·ªôi tho·∫°i
        if state.user_query:
            state.conversation_history.append({"role": "user", "content": state.user_query})
        entry = {"role": "assistant", "content": assistant_msg}

        # N·∫øu c√≥ ngu·ªìn, th√™m metadata
        if getattr(state, "retrieved_docs", None):
            entry["sources"] = [
                {
                    "title": d.get("title", ""),
                    "url": d.get("url", ""),
                    "time": d.get("time", ""),
                    "score": float(d.get("score", 0.0)) if d.get("score") else None,
                }
                for d in state.retrieved_docs
            ]

        state.conversation_history.append(entry)
        state.conversation_history = state.conversation_history[-max_history:]
        state.final_answer = assistant_msg
        state.response = assistant_msg
        add_debug_info(state, "llm_status", "response_generated")
        add_debug_info(state, "route", route)
        add_debug_info(state, "intent", intent)
        add_debug_info(state, "timestamp", datetime.now().isoformat())

    except Exception as e:
        add_debug_info(state, "llm_error", str(e))
        err_msg = "ƒê√£ x·∫£y ra l·ªói khi g·ªçi LLM, vui l√≤ng th·ª≠ l·∫°i sau."
        state.set_final_answer(err_msg, route="RAG")
        state.response = err_msg
        return state

    return state
