2025-10-14 07:54:09,940 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 07:54:09,965 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002197E857CD0>
2025-10-14 07:54:09,966 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 07:54:09,967 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 07:54:09,967 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 07:54:09,968 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 07:54:09,968 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 00:54:09 GMT')])
2025-10-14 07:54:09,998 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 07:54:09,999 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 07:54:09,999 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 07:54:09,999 [DEBUG] httpcore.connection: close.started
2025-10-14 07:54:09,999 [DEBUG] httpcore.connection: close.complete
2025-10-14 07:55:40,454 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:55:42,353 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 07:55:42,390 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:55:42,900 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 07:55:42,923 [INFO] RAGPipeline: router: API
2025-10-14 07:55:42,923 [INFO] RAGPipeline: intent: stock
2025-10-14 07:59:53,808 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:59:54,380 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 07:59:54,394 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:59:54,966 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 07:59:54,976 [INFO] RAGPipeline: router: API
2025-10-14 07:59:54,977 [INFO] RAGPipeline: intent: stock
2025-10-14 08:07:36,113 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:07:38,708 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 08:07:38,727 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:07:39,260 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 08:07:39,272 [INFO] RAGPipeline: router: API
2025-10-14 08:07:39,272 [INFO] RAGPipeline: intent: stock
2025-10-14 08:11:52,094 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:11:52,097 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020069873C90>
2025-10-14 08:11:52,097 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:11:52,098 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:11:52,111 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:11:51 GMT')])
2025-10-14 08:11:52,112 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:11:52,113 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:11:52,113 [DEBUG] httpcore.connection: close.started
2025-10-14 08:11:52,113 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:18:56,012 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:18:56,015 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023A0E7E5550>
2025-10-14 08:18:56,017 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:18:56,019 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:18:56,020 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:18:56,022 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:18:56,024 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:18:56,038 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:18:55 GMT')])
2025-10-14 08:18:56,039 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:18:56,040 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:18:56,042 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:18:56,043 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:18:56,044 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:18:56,046 [DEBUG] httpcore.connection: close.started
2025-10-14 08:18:56,046 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:19,564 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:20:21,489 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:20:21,942 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:20:22,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:20:22,585 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:20:23,295 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:23,307 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000183EFA2F1D0>
2025-10-14 08:20:23,308 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:20:22 GMT')])
2025-10-14 08:20:23,315 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 08:20:23,316 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,317 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:23,318 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:23,319 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:23,320 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:23,321 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:23,323 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:23,338 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000183EFA3B710>
2025-10-14 08:20:23,338 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,339 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:23,341 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,343 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:23,343 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,344 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:20:22 GMT')])
2025-10-14 08:20:23,345 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 08:20:23,346 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:23,350 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:23,351 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:23,894 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 08:20:24,543 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 08:20:25,970 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 08:20:26,281 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 08:20:26,587 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:26,937 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:28,739 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:28,764 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:29,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:29,391 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:29,416 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 08:20:29,519 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:29,521 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018475FA72D0>
2025-10-14 08:20:29,521 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:20:29,524 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:29,524 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:20:29,525 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:29,526 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:20:29,544 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:20:29 GMT')])
2025-10-14 08:20:29,545 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 08:20:29,545 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:20:29,562 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:29,563 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:29,563 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:29,564 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:29,565 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:29,964 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 08:20:30,609 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,922 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:31,220 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 08:20:31,505 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:31,828 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:20:32,122 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:20:32,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 08:20:32,539 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 08:20:32,838 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 08:20:33,729 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:20:34,092 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:20:34,100 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:20:34,462 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:20:34,484 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:20:35,032 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 08:20:35,275 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:20:35,738 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 08:20:35,802 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 08:20:35,810 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 08:20:35,841 [DEBUG] matplotlib: interactive is False
2025-10-14 08:20:35,842 [DEBUG] matplotlib: platform is win32
2025-10-14 08:20:35,892 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 08:20:35,898 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 08:20:36,555 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:20:37,106 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 08:20:38,355 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:38,355 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001847941BA90>
2025-10-14 08:20:38,355 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:20:38,362 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:38,364 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:20:38,364 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:38,365 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:20:38,368 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:20:37 GMT')])
2025-10-14 08:20:38,372 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:20:38,372 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:38,376 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:38,377 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:32:39,712 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:32:42,446 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:32:44,413 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:32:45,140 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:32:45,150 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:32:46,228 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:32:50,265 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-14 08:32:50,266 [DEBUG] root: Unable to get server version: [WinError 10061] No connection could be made because the target machine actively refused it, server version defaults to None
2025-10-14 08:32:50,268 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:32:54,292 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-14 08:34:12,613 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:34:14,920 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:34:15,637 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:34:16,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:34:16,414 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:34:17,439 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:17,442 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2368CF6D0>
2025-10-14 08:34:17,442 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,445 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:17,445 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,447 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:17,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,449 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:17 GMT')])
2025-10-14 08:34:17,452 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 08:34:17,454 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,456 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:17,457 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:17,458 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:17,460 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:17,461 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:17,461 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:17,467 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2368D3C90>
2025-10-14 08:34:17,469 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,470 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:17,473 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,474 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:17,475 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,478 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:17 GMT')])
2025-10-14 08:34:17,480 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 08:34:17,485 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,486 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:17,487 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:17,488 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:17,488 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:17,490 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:18,267 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 08:34:19,063 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 08:34:22,325 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 08:34:22,608 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 08:34:22,913 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:23,275 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:25,495 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:25,527 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:25,826 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:26,445 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:26,476 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 08:34:26,797 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:26,812 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2DC396890>
2025-10-14 08:34:26,812 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:34:26,815 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:26,815 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:34:26,817 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:26,817 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:34:26,838 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:26 GMT')])
2025-10-14 08:34:26,839 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 08:34:26,840 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:34:26,856 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:26,857 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:26,858 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:26,859 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:26,859 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:27,259 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:27,534 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:27,560 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 08:34:28,162 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:28,424 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:28,447 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:28,726 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 08:34:29,008 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:29,326 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:34:29,599 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:34:29,628 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 08:34:30,154 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 08:34:30,442 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 08:34:31,484 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:34:32,229 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:34:32,232 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:34:32,918 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:34:32,996 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:34:33,549 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 08:34:33,635 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:34:34,828 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 08:34:35,112 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 08:34:35,127 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 08:34:35,155 [DEBUG] matplotlib: interactive is False
2025-10-14 08:34:35,157 [DEBUG] matplotlib: platform is win32
2025-10-14 08:34:35,279 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 08:34:35,291 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 08:34:38,095 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:34:45,462 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 08:34:46,586 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:46,611 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2DF8CC450>
2025-10-14 08:34:46,612 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:34:46,616 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:46,616 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:34:46,619 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:46,619 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:34:46,637 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:34:46 GMT')])
2025-10-14 08:34:46,638 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:34:46,639 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:34:46,640 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:46,641 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:46,641 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:46,641 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:46,644 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:37:21,141 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:37:21,142 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001785EB70690>
2025-10-14 08:37:21,142 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:37:21,145 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:37:21,150 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:37:20 GMT')])
2025-10-14 08:37:21,152 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:37:21,153 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:37:21,153 [DEBUG] httpcore.connection: close.started
2025-10-14 08:37:21,153 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:37:53,815 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:37:53,817 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001785EB1EA90>
2025-10-14 08:37:53,817 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:37:53,818 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:37:53,818 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:37:53,819 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:37:53,819 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:37:53,825 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:37:53 GMT')])
2025-10-14 08:37:53,825 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:37:53,825 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:37:53,826 [DEBUG] httpcore.connection: close.started
2025-10-14 08:37:53,827 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:38:47,837 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:38:47,839 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000178FD8E4150>
2025-10-14 08:38:47,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:38:47,840 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:38:47,841 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:38:47,842 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:38:47,842 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:38:47,847 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:38:47 GMT')])
2025-10-14 08:38:47,848 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:38:47,848 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:38:47,849 [DEBUG] httpcore.connection: close.started
2025-10-14 08:38:47,849 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:47,310 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:41:49,322 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:41:49,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:41:50,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:41:50,437 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:41:51,164 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:51,185 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025B86AFF4D0>
2025-10-14 09:41:51,187 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,189 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:51,190 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,191 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:51,192 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,195 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:41:51 GMT')])
2025-10-14 09:41:51,196 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:41:51,196 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:51,198 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:51,202 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:51,203 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:51,204 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025B86B0B690>
2025-10-14 09:41:51,206 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,206 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:51,208 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,210 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:51,210 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,212 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:41:51 GMT')])
2025-10-14 09:41:51,213 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:41:51,215 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,217 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:51,217 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:51,218 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:51,218 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:51,219 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:51,943 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:41:52,605 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:41:54,009 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:41:54,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:41:54,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:54,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:56,556 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:56,586 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:56,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:57,174 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:57,198 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:41:57,301 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:57,303 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025C86297950>
2025-10-14 09:41:57,304 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:41:57,305 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:57,306 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:41:57,307 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:57,308 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:41:57,364 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:41:57 GMT')])
2025-10-14 09:41:57,364 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:41:57,366 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:41:57,387 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:57,388 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:57,388 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:57,389 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:57,390 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:57,773 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,049 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,074 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:41:58,381 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,695 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,723 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:58,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:41:59,286 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:59,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:41:59,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:41:59,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:42:00,483 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:42:00,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:42:01,597 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:42:01,959 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:42:01,964 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:42:02,343 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:42:02,362 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:42:02,792 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:42:02,880 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:42:03,341 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:42:03,406 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:42:03,409 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:42:03,440 [DEBUG] matplotlib: interactive is False
2025-10-14 09:42:03,441 [DEBUG] matplotlib: platform is win32
2025-10-14 09:42:03,491 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:42:03,493 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:42:04,141 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:42:05,387 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:42:06,507 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:42:06,521 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025C89E44850>
2025-10-14 09:42:06,521 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:42:06,526 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:42:06,526 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:42:06,528 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:42:06,528 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:42:06,547 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:42:06 GMT')])
2025-10-14 09:42:06,549 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:42:06,550 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:42:06,551 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:42:06,551 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:42:06,552 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:42:06,552 [DEBUG] httpcore.connection: close.started
2025-10-14 09:42:06,553 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:23,058 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:43:24,927 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:43:25,388 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:43:26,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:43:26,024 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:43:26,813 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:26,828 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268677FF7D0>
2025-10-14 09:43:26,828 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,828 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:26,831 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,832 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:26,832 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,833 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:43:26 GMT')])
2025-10-14 09:43:26,835 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:26,836 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:26,836 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:26,841 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:26,843 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026867803C90>
2025-10-14 09:43:26,844 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,846 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:26,846 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,847 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:26,849 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,850 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:43:26 GMT')])
2025-10-14 09:43:26,850 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:43:26,853 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,854 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:26,855 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:26,855 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:26,856 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:26,857 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:27,151 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:43:27,842 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:43:29,550 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:43:29,841 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:43:30,152 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:30,558 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:32,553 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:32,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:32,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:33,192 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:33,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:43:33,356 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:33,358 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268ED79C990>
2025-10-14 09:43:33,358 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:43:33,361 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:33,362 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:43:33,362 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:33,364 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:43:33,396 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:43:33 GMT')])
2025-10-14 09:43:33,397 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:43:33,397 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:43:33,417 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:33,418 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:33,418 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:33,420 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:33,420 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:33,862 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,146 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,182 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:43:34,529 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,821 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,852 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:35,140 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:43:35,444 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:35,765 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:43:36,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:43:36,071 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:43:36,502 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:43:36,791 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:43:37,689 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:43:38,215 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:43:38,219 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:43:38,705 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:43:38,731 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:43:39,308 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:43:39,412 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:43:39,972 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:43:40,060 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:43:40,066 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:43:40,099 [DEBUG] matplotlib: interactive is False
2025-10-14 09:43:40,100 [DEBUG] matplotlib: platform is win32
2025-10-14 09:43:40,171 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:43:40,175 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:43:40,948 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:43:41,827 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:43:42,500 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:42,503 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268EE40F8D0>
2025-10-14 09:43:42,503 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:43:42,509 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:43:42,523 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:43:42 GMT')])
2025-10-14 09:43:42,523 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:43:42,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:43:42,526 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:42,528 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:42,529 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:42,530 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:42,530 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:20,177 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:46:22,060 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:46:22,515 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:46:23,640 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:46:23,648 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:46:24,371 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:24,371 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176992FF750>
2025-10-14 09:46:24,371 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,371 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,381 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:46:23 GMT')])
2025-10-14 09:46:24,381 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:46:24,381 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:24,383 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:24,383 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:24,387 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:24,389 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017699303E10>
2025-10-14 09:46:24,389 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,391 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:24,392 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,392 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:24,394 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,394 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:23 GMT')])
2025-10-14 09:46:24,396 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:46:24,400 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,400 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:24,401 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:24,401 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:24,403 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:24,404 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:24,690 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:46:25,373 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:46:26,931 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:46:27,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:46:27,522 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:27,853 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:29,501 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:29,530 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:29,818 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:30,160 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:30,195 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:46:30,300 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:30,315 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017699466C50>
2025-10-14 09:46:30,316 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:46:30,316 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:30,318 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:46:30,318 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:30,319 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:46:30,345 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:30 GMT')])
2025-10-14 09:46:30,347 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:46:30,348 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:46:30,364 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:30,365 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:30,366 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:30,366 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:30,368 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:30,786 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,084 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:46:31,462 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,785 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:32,074 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:46:32,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:32,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:46:33,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:46:33,042 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:46:33,692 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:46:33,993 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:46:34,835 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:46:35,180 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:46:35,184 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:46:35,541 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:46:35,556 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:46:35,994 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:46:36,988 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:46:39,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:46:39,190 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:46:39,190 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:46:39,224 [DEBUG] matplotlib: interactive is False
2025-10-14 09:46:39,225 [DEBUG] matplotlib: platform is win32
2025-10-14 09:46:39,274 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:46:39,274 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:46:39,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:46:40,753 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:46:41,167 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:41,169 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001775FFE0DD0>
2025-10-14 09:46:41,170 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:46:41,171 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:41,174 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:46:41,176 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:41,176 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:46:41,187 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:41 GMT')])
2025-10-14 09:46:41,190 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:46:41,190 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:46:41,192 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:41,193 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:41,193 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:41,193 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:41,195 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:38,854 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:47:40,774 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:47:41,235 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:47:41,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:47:41,885 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:47:42,606 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:42,608 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BEADE666D0>
2025-10-14 09:47:42,610 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,612 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:42,612 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,613 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:42,613 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:42 GMT')])
2025-10-14 09:47:42,615 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:42,618 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:42,619 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:42,619 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:42,620 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:42,622 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BEAE4AAF90>
2025-10-14 09:47:42,623 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,625 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:42,627 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,628 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:42,629 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,629 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:47:42 GMT')])
2025-10-14 09:47:42,629 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:47:42,633 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,634 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:42,634 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:42,635 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:42,635 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:42,635 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:42,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:47:43,615 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:47:45,108 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:47:45,398 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:47:45,689 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:46,113 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:47,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:47,890 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:48,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:48,503 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:48,532 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:47:48,648 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:48,651 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BED81C3790>
2025-10-14 09:47:48,652 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:47:48,653 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:48,654 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:47:48,655 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:48,657 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:47:48,676 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:48 GMT')])
2025-10-14 09:47:48,676 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:47:48,680 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:47:48,698 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:48,699 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:48,699 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:48,701 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:48,701 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:49,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:49,438 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:49,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:47:50,003 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:50,305 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:50,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:50,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:47:50,966 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:51,301 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:47:51,605 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:47:51,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:47:52,163 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:47:52,469 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:47:53,289 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:47:53,649 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:47:53,652 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:47:54,017 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:47:54,038 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:47:54,501 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:47:55,651 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:47:56,078 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:47:56,148 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:47:56,155 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:47:56,182 [DEBUG] matplotlib: interactive is False
2025-10-14 09:47:56,183 [DEBUG] matplotlib: platform is win32
2025-10-14 09:47:56,232 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:47:56,232 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:47:56,951 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:47:57,720 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:47:58,310 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:58,331 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF5CE2F350>
2025-10-14 09:47:58,331 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:47:58,337 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:58,339 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:47:58,340 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:58,340 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:47:58,352 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:58 GMT')])
2025-10-14 09:47:58,354 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:47:58,354 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:47:58,355 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:58,356 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:58,356 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:58,356 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:58,358 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:47,355 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:16:49,299 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:16:49,780 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:16:50,428 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:16:50,434 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:16:51,146 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:51,150 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020C81BFE890>
2025-10-14 10:16:51,150 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,150 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:51,155 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,156 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:51,156 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,157 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:50 GMT')])
2025-10-14 10:16:51,157 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:16:51,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,159 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:51,161 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:51,161 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:51,162 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:51,163 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:51,164 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:51,166 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020C827D3850>
2025-10-14 10:16:51,168 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:51,171 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,172 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:50 GMT')])
2025-10-14 10:16:51,173 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:51,175 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:51,175 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:51,511 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:16:52,166 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:16:53,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:16:53,934 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:16:54,243 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:54,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:56,582 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:56,623 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:56,917 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:57,243 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:57,267 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:16:57,415 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:57,417 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D861E3E90>
2025-10-14 10:16:57,417 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:16:57,420 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:57,422 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:16:57,423 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:57,423 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:16:57,448 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:57 GMT')])
2025-10-14 10:16:57,451 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:16:57,452 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:16:57,470 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:57,470 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:57,472 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:57,473 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:57,474 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:57,980 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,276 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,304 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:16:58,641 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,953 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:59,244 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:16:59,542 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:59,861 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:17:00,158 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:17:00,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:17:00,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:17:00,878 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:17:01,773 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:17:02,289 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:17:02,294 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:17:02,743 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:17:02,770 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:17:03,355 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:17:03,461 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:17:04,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:17:04,170 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:17:04,177 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:17:04,216 [DEBUG] matplotlib: interactive is False
2025-10-14 10:17:04,217 [DEBUG] matplotlib: platform is win32
2025-10-14 10:17:04,283 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:17:04,286 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:17:05,163 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:17:06,042 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:17:06,588 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:17:06,590 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D86EC0110>
2025-10-14 10:17:06,590 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:17:06,593 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:17:06,613 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:17:06 GMT')])
2025-10-14 10:17:06,613 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:17:06,613 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:17:06,617 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:17:06,618 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:17:06,619 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:17:06,620 [DEBUG] httpcore.connection: close.started
2025-10-14 10:17:06,621 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:32:31,626 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:32:31,628 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029604AF90D0>
2025-10-14 10:32:31,628 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:32:31,630 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:32:31,644 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:32:31 GMT')])
2025-10-14 10:32:31,645 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:32:31,645 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:32:31,647 [DEBUG] httpcore.connection: close.started
2025-10-14 10:32:31,648 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:34:01,113 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:34:01,115 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029604880690>
2025-10-14 10:34:01,115 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:34:01,118 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:34:01,132 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:34:00 GMT')])
2025-10-14 10:34:01,132 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:34:01,134 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:34:01,134 [DEBUG] httpcore.connection: close.started
2025-10-14 10:34:01,135 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:34:20,724 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:34:20,744 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029623B489D0>
2025-10-14 10:34:20,744 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:34:20,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:34:20,760 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:34:20 GMT')])
2025-10-14 10:34:20,760 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:34:20,760 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:34:20,761 [DEBUG] httpcore.connection: close.started
2025-10-14 10:34:20,762 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:35:03,973 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:35:03,995 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029615700690>
2025-10-14 10:35:03,995 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:35:03,998 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:35:04,010 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:35:03 GMT')])
2025-10-14 10:35:04,011 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:35:04,011 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:35:04,012 [DEBUG] httpcore.connection: close.started
2025-10-14 10:35:04,013 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:36:02,576 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:36:02,578 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029557C06B90>
2025-10-14 10:36:02,578 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:36:02,579 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:36:02,579 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:36:02,580 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:36:02,580 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:36:02 GMT')])
2025-10-14 10:36:02,594 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:36:02,596 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:36:02,596 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:36:02,596 [DEBUG] httpcore.connection: close.started
2025-10-14 10:36:02,596 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:38:18,800 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:38:18,802 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACDB3E8050>
2025-10-14 10:38:18,802 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:38:18,804 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:38:18,804 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:38:18,805 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:38:18,805 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:38:18,817 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:38:18 GMT')])
2025-10-14 10:38:18,818 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:38:18,819 [DEBUG] httpcore.connection: close.started
2025-10-14 10:38:18,819 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:22,327 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:40:23,174 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:40:23,637 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:40:24,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:40:24,286 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:40:25,057 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:25,077 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000224078CF610>
2025-10-14 10:40:25,077 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,080 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:25,081 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,081 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:25,082 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,083 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:24 GMT')])
2025-10-14 10:40:25,084 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:25,088 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:25,088 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:25,088 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:25,090 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:25,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000224078D3910>
2025-10-14 10:40:25,093 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:25,097 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,098 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:40:24 GMT')])
2025-10-14 10:40:25,098 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:25,104 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:25,105 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:25,512 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:40:25,643 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:40:27,268 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:40:27,557 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:40:27,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:28,134 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:29,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:29,911 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:30,194 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:30,488 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:30,518 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:40:30,643 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:30,647 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002248000A190>
2025-10-14 10:40:30,648 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:40:30,650 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:30,650 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:40:30,651 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:30,652 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:40:30,682 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:30 GMT')])
2025-10-14 10:40:30,683 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:40:30,683 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:40:30,691 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:30,702 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:30,703 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:30,703 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:30,704 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:31,104 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:31,831 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:31,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:40:32,162 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:32,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:32,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:32,733 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:40:32,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:33,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:40:33,548 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:40:33,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:40:34,055 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:40:34,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:40:35,236 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:40:35,620 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:40:35,624 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:40:36,872 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:40:36,893 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:40:39,105 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:40:39,586 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:40:40,035 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:40:40,102 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:40:40,105 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:40:40,138 [DEBUG] matplotlib: interactive is False
2025-10-14 10:40:40,139 [DEBUG] matplotlib: platform is win32
2025-10-14 10:40:40,190 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:40:40,192 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:40:40,889 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:40:41,469 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:40:41,914 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:41,918 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022506AEF4D0>
2025-10-14 10:40:41,918 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:41,923 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:40:41,929 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:41 GMT')])
2025-10-14 10:40:41,929 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:40:41,932 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:40:41,932 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:41,934 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:41,934 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:41,935 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:41,935 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:15,824 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:42:16,675 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:42:17,142 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:42:17,784 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:42:17,785 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:42:18,493 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:18,506 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A2753F990>
2025-10-14 10:42:18,508 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,510 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:18,511 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,511 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:18,513 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,513 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:42:18 GMT')])
2025-10-14 10:42:18,514 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:42:18,516 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:18,517 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:18,517 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:18,521 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:18,522 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A27542BD0>
2025-10-14 10:42:18,523 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,525 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:18,525 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,526 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:18,527 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,527 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:42:18 GMT')])
2025-10-14 10:42:18,528 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:42:18,531 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,533 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:18,533 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:18,534 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:18,534 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:18,535 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:18,854 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:42:19,002 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:42:20,446 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:42:20,740 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:42:21,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:21,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:22,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:23,023 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:23,330 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:23,910 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:23,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:42:24,040 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:24,055 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020ADC677510>
2025-10-14 10:42:24,056 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:42:24,058 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:24,058 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:42:24,059 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:24,060 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:42:24,081 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:42:23 GMT')])
2025-10-14 10:42:24,083 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:42:24,083 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:42:24,101 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:24,102 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:24,103 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:24,103 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:24,104 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:24,777 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:25,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,242 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:42:26,562 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,883 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:27,178 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:42:27,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:28,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:42:28,293 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:42:28,323 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:42:28,739 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:42:29,021 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:42:29,847 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:42:30,195 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:42:30,196 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:42:30,546 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:42:30,564 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:42:30,972 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:42:31,043 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:42:31,493 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:42:31,556 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:42:31,562 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:42:31,592 [DEBUG] matplotlib: interactive is False
2025-10-14 10:42:31,593 [DEBUG] matplotlib: platform is win32
2025-10-14 10:42:31,641 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:42:31,646 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:42:32,283 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:42:32,773 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:42:33,169 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:33,180 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020ADD1474D0>
2025-10-14 10:42:33,181 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:42:33,183 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:33,183 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:42:33,185 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:33,185 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:42:33,192 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:42:32 GMT')])
2025-10-14 10:42:33,194 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:42:33,194 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:42:33,196 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:33,197 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:33,197 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:33,197 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:33,197 [DEBUG] httpcore.connection: close.complete
2025-10-14 15:46:29,887 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:46:50,938 [INFO] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:47:32,977 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:47:33,343 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:47:33,346 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:47:33,706 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:47:33,733 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:47:34,185 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:47:34,273 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:47:34,725 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:47:34,842 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:47:34,848 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:47:34,880 [DEBUG] matplotlib: interactive is False
2025-10-14 15:47:34,880 [DEBUG] matplotlib: platform is win32
2025-10-14 15:47:34,952 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:47:34,956 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:47:35,904 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:47:36,435 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:47:36,808 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:47:57,851 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:51:37,544 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:51:37,875 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:51:37,879 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:51:38,214 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:51:38,232 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:51:38,635 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:51:38,705 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:51:39,138 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:51:39,201 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:51:39,207 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:51:39,235 [DEBUG] matplotlib: interactive is False
2025-10-14 15:51:39,236 [DEBUG] matplotlib: platform is win32
2025-10-14 15:51:39,285 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:51:39,288 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:51:39,965 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:51:40,523 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:51:40,850 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:52:01,882 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:58:48,547 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:58:48,891 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:58:48,894 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:58:49,247 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:58:49,265 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:58:49,699 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:58:49,787 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:58:50,214 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:58:50,279 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:58:50,286 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:58:50,316 [DEBUG] matplotlib: interactive is False
2025-10-14 15:58:50,317 [DEBUG] matplotlib: platform is win32
2025-10-14 15:58:50,370 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:58:50,374 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:58:51,019 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:58:51,478 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:58:51,767 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:59:12,791 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-15 08:38:37,074 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:38:40,079 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:40:07,068 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:40:07,783 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:40:07,787 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:40:09,503 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:09,509 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E0FB42D0>
2025-10-15 08:40:09,510 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,513 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:09,513 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,515 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:09,515 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,522 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:40:09 GMT')])
2025-10-15 08:40:09,523 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:40:09,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,527 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:09,528 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:09,528 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:09,529 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:09,530 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:09,531 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:09,546 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E0FB6850>
2025-10-15 08:40:09,547 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,549 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:09,549 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,550 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:09,550 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,551 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:40:09 GMT')])
2025-10-15 08:40:09,552 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:40:09,555 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,555 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:09,556 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:09,556 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:09,557 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:09,558 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:14,504 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:14,537 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:40:14,867 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:40:15,232 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:15,265 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:40:16,587 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:16,604 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E2BB5910>
2025-10-15 08:40:16,604 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:40:16,607 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:16,608 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:40:16,608 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:16,610 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:40:16,673 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:40:16 GMT')])
2025-10-15 08:40:16,673 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:40:16,677 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:40:16,711 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:16,712 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:16,712 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:16,713 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:16,713 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:17,220 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:17,506 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:17,538 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:40:17,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:18,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:18,683 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:40:18,979 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:40:19,272 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:40:19,596 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:40:19,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:40:19,920 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:40:20,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:40:20,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:40:21,638 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:40:22,045 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:40:22,049 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:40:22,389 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:40:22,469 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:40:22,891 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:40:22,976 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:40:23,407 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:40:23,637 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:40:23,646 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:40:23,691 [DEBUG] matplotlib: interactive is False
2025-10-15 08:40:23,691 [DEBUG] matplotlib: platform is win32
2025-10-15 08:40:23,812 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:40:23,823 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:40:26,458 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:40:26,914 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:40:28,443 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:28,461 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C28747E850>
2025-10-15 08:40:28,462 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:40:28,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:28,465 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:40:28,466 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:28,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:40:28,522 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 01:40:28 GMT')])
2025-10-15 08:40:28,524 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:40:28,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:40:28,525 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:28,527 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:28,527 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:28,527 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:28,530 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:28,867 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-15 08:47:13,764 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:47:14,476 [DEBUG] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:47:14,993 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:47:15,667 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:47:15,672 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:47:16,484 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:16,486 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE48E454D0>
2025-10-15 08:47:16,486 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:16 GMT')])
2025-10-15 08:47:16,487 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,491 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:16,492 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:16,492 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:16,492 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:16,492 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:16,493 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:16,494 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE48E46690>
2025-10-15 08:47:16,494 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,495 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:16,495 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,496 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:16,496 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,498 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:16 GMT')])
2025-10-15 08:47:16,498 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:47:16,499 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,499 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:16,500 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:16,500 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:16,500 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:16,501 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:18,745 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:18,779 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:47:19,157 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:47:19,476 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:19,510 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:47:19,694 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:19,709 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE4AD211D0>
2025-10-15 08:47:19,709 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:47:19,753 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:19 GMT')])
2025-10-15 08:47:19,753 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:47:19,753 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:19,767 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:19,767 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:20,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:20,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:20,576 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:47:20,885 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:21,193 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:21,489 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:47:21,772 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:47:22,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:47:22,868 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:47:23,151 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:47:23,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:47:23,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:47:23,860 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:49:01,781 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:49:03,687 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:49:04,212 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:49:04,831 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:49:04,833 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:49:05,540 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:05,545 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB49118290>
2025-10-15 08:49:05,546 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,547 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:05,547 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,549 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:05,550 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,551 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:05 GMT')])
2025-10-15 08:49:05,551 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:49:05,552 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:05,554 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:05,555 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:05,557 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:05,573 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB4911B7D0>
2025-10-15 08:49:05,573 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,575 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:05,576 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,576 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:05,578 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,579 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:49:05 GMT')])
2025-10-15 08:49:05,580 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:49:05,580 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:05,581 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:05,581 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:07,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:07,550 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:49:07,857 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:49:08,173 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:08,208 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:49:08,957 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:08,959 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB4AD0FCD0>
2025-10-15 08:49:08,960 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:08,965 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:49:09,007 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:08 GMT')])
2025-10-15 08:49:09,009 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:49:09,010 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:49:09,034 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:09,035 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:09,036 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:09,036 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:09,038 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:09,527 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:09,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:09,873 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:49:10,200 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:10,504 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:10,552 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:49:10,864 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:49:11,186 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:49:11,506 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:49:11,796 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:49:11,823 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:49:12,190 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:49:12,484 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:49:13,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:49:13,659 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:49:13,662 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:49:14,076 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:49:14,093 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:49:14,512 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:49:14,590 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:49:15,020 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:49:15,082 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:49:15,089 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:49:15,116 [DEBUG] matplotlib: interactive is False
2025-10-15 08:49:15,117 [DEBUG] matplotlib: platform is win32
2025-10-15 08:49:15,165 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:49:15,170 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:49:15,676 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:49:16,330 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:49:17,097 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:17,100 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB55AEB790>
2025-10-15 08:49:17,101 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:49:17,103 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:49:17,113 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:17 GMT')])
2025-10-15 08:49:17,115 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:49:17,116 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:17,117 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:17,120 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:17,296 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:49:17,296 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:49:17,300 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:49:38,334 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:49:38,335 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:49:38,365 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:49:38,366 [INFO] openai._base_client: Retrying request to /chat/completions in 0.402170 seconds
2025-10-15 08:49:38,769 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:49:38,769 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:49:38,769 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:49:59,809 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:49:59,809 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:49:59,811 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:49:59,811 [INFO] openai._base_client: Retrying request to /chat/completions in 0.998753 seconds
2025-10-15 08:50:00,813 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:50:00,813 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:50:00,814 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:50:21,845 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:50:21,846 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:50:21,849 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 08:50:21,850 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 08:50:21,851 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 08:52:34,899 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:52:34,902 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BA0D0DC090>
2025-10-15 08:52:34,903 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:52:34,905 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:52:34,906 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:52:34,908 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:52:34,909 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:52:34,921 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:52:34 GMT')])
2025-10-15 08:52:34,922 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:52:34,922 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:52:34,923 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:52:34,924 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:52:34,925 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:52:34,926 [DEBUG] httpcore.connection: close.started
2025-10-15 08:52:34,927 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:52:35,199 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:52:35,199 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:52:35,202 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:52:56,238 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:52:56,239 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:52:56,241 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:52:56,241 [INFO] openai._base_client: Retrying request to /chat/completions in 0.410208 seconds
2025-10-15 08:52:56,655 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:52:56,656 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:52:56,657 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:53:17,686 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:53:17,688 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:53:17,688 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:53:17,691 [INFO] openai._base_client: Retrying request to /chat/completions in 0.808713 seconds
2025-10-15 08:53:18,500 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:53:18,500 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:53:18,503 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:53:39,531 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:53:39,532 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:53:39,536 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 08:53:39,536 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 08:53:39,538 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 08:58:52,263 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:58:54,165 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:58:54,674 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:58:55,325 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:58:55,329 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:58:56,075 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:56,080 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9D3F8290>
2025-10-15 08:58:56,080 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,082 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:56,084 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,084 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:56,085 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,086 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:58:55 GMT')])
2025-10-15 08:58:56,088 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:58:56,088 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,089 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:56,090 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:56,090 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:56,091 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:56,093 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:58:56,094 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:56,096 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9D3FAE50>
2025-10-15 08:58:56,098 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,100 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:56,101 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,101 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:56,102 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,103 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:58:56 GMT')])
2025-10-15 08:58:56,103 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:58:56,103 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,107 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:56,108 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:56,108 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:56,109 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:56,109 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:58:58,152 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:58:58,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:58:58,485 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:58:58,806 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:58:58,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:58:59,624 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:59,627 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9EFE97D0>
2025-10-15 08:58:59,627 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:58:59,629 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:59,630 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:58:59,631 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:59,632 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:58:59,666 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 01:58:59 GMT')])
2025-10-15 08:58:59,668 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:58:59,668 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:58:59,695 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:59,696 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:59,696 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:59,697 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:59,698 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:59:00,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:59:00,470 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:59:00,501 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:59:00,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:59:01,120 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:59:01,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:59:01,446 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:59:01,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:59:02,060 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:59:02,351 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:59:02,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:59:02,716 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:59:03,035 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:59:03,851 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:59:04,231 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:59:04,234 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:59:04,604 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:59:04,624 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:59:05,063 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:59:05,142 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:59:05,586 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:59:05,650 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:59:05,656 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:59:05,686 [DEBUG] matplotlib: interactive is False
2025-10-15 08:59:05,687 [DEBUG] matplotlib: platform is win32
2025-10-15 08:59:05,738 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:59:05,743 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:59:06,175 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:59:06,753 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:59:07,515 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:59:07,518 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BA93670D0>
2025-10-15 08:59:07,519 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:59:07,521 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:59:07,521 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:59:07,523 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:59:07,525 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:59:07,539 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:59:07 GMT')])
2025-10-15 08:59:07,539 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:59:07,539 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:59:07,542 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:59:07,544 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:59:07,544 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:59:07,545 [DEBUG] httpcore.connection: close.started
2025-10-15 08:59:07,546 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:59:07,744 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:07,745 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:07,746 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:59:28,766 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:59:28,768 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:59:28,772 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:59:28,773 [INFO] openai._base_client: Retrying request to /chat/completions in 0.438809 seconds
2025-10-15 08:59:29,213 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:29,213 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:29,213 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:59:50,240 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:59:50,241 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:59:50,242 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:59:50,242 [INFO] openai._base_client: Retrying request to /chat/completions in 0.769119 seconds
2025-10-15 08:59:51,015 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00 | score=0.750]\nKháng cự 3 (1.813-1.820). Kịch bản kém tích cực:Giá vận động trong mô hình đi ngang 1.600-1.700 điểm với thanh khoản suy giảm, nhà đầu tư tổ chức tiếp tục duy trì bán ròng mạnh mẽ như 2 tháng trước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ tr\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00 | score=0.625]\nTrong bối cảnh VN-Index "quay đầu" điều chỉnh về cuối phiên 14/10, cổ phiếuCRV của CTCP Tập đoàn Bất động sản CRVvẫn gây chú ý với nhà đầu tư. Doanh nghiệp này mới chào sàn HoSE từ ngày 10/10, và sau 3 phiên giao dịch, cổ phiếu này đã thiết lập chuỗi tăng trần liên tiếp. Đóng cửa, thị giá CRV tăng k ngày 6/11/1955 tại Thủy Nguyên, Hải Phòng. Vị doanh nhân đến từ "đất cảng" này hiện đang sở hữu khối tài sản trị giá hàng nghìn tỷ đồng khi trực tiếp nắm giữ hơn 262 triệu cổ phiếu TCH. Về kế hoạch k...\n\n[Cập nhật số liệu CTCK ngày 15/10: Chứng khoán VPS lãi gần 1.400 tỷ trong quý 3, nhiều công ty báo lãi tăng mạnh | 15-10-2025 00:03:00 | score=0.562]\nTính đến sáng 15/10, đã có 9 CTCK công bố BCTC quý 3/2025. Chứng khoán VPSđã công bố BCTC quý 3 với doanh thu hoạt động trong kỳ đạt 2.708 tỷ đồng, tăng 65% so với cùng kỳ năm trước. Trong đó, doanh thu môi giới đóng góp 1.523 tỷ, tăng 113%, lãi cho vay và phải thu cũng tăng 1,5 lần lên 706 tỷ. Sau\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:51,015 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:51,016 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 09:00:12,037 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 09:00:12,038 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 09:00:12,039 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 09:00:12,039 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 09:00:12,039 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 09:35:06,192 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 09:35:08,310 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 09:35:08,876 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 09:35:09,511 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 09:35:09,516 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 09:35:10,427 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:10,442 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DACEBE90>
2025-10-15 09:35:10,442 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,444 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:10,445 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,446 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:10,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,450 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 02:35:10 GMT')])
2025-10-15 09:35:10,450 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 09:35:10,450 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,454 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:10,455 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:10,456 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:10,457 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:10,458 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:10,459 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:10,463 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DACFAE50>
2025-10-15 09:35:10,464 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:10,466 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,468 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:10,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,470 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:35:10 GMT')])
2025-10-15 09:35:10,470 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 09:35:10,473 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,474 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:10,475 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:10,476 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:10,476 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:10,476 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:10,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:10,772 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:35:11,044 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:35:11,357 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:11,384 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 09:35:12,206 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:12,218 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DA6D9750>
2025-10-15 09:35:12,219 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:35:12,221 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:12,221 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:35:12,223 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:12,224 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:35:12,316 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:35:11 GMT')])
2025-10-15 09:35:12,317 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 09:35:12,318 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:12,362 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:12,362 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:12,829 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:13,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:13,145 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 09:35:13,917 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:14,193 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:14,221 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:35:14,497 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 09:35:14,773 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:35:15,093 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:35:15,369 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:35:15,395 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 09:35:15,729 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 09:35:16,018 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 09:36:56,948 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 09:36:59,012 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 09:36:59,602 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 09:37:00,388 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 09:37:00,397 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 09:37:01,225 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:01,226 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025582628350>
2025-10-15 09:37:01,228 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,230 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:01,230 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,231 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:01,232 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,232 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:00 GMT')])
2025-10-15 09:37:01,235 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 09:37:01,235 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,236 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:01,238 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:01,239 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:01,240 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:01,242 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:01,243 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:01,245 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025582629B10>
2025-10-15 09:37:01,246 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,248 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,253 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:00 GMT')])
2025-10-15 09:37:01,254 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 09:37:01,255 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:01,259 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:01,260 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:01,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-15 09:37:02,323 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-15 09:37:05,908 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-15 09:37:06,214 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-15 09:37:06,503 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:06,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:09,400 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:09,430 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:09,738 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:10,067 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:10,092 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 09:37:10,292 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:10,296 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002560009CA50>
2025-10-15 09:37:10,297 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:37:10,298 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:10,300 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:37:10,301 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:10,302 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:37:10,355 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 02:37:09 GMT')])
2025-10-15 09:37:10,357 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 09:37:10,359 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:37:10,389 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:10,390 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:10,392 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:10,392 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:10,393 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:10,972 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,256 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,283 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 09:37:11,648 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,954 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,982 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:12,271 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 09:37:12,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:12,898 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:37:13,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:37:13,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 09:37:13,641 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 09:37:13,940 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 09:37:14,926 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 09:37:15,391 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 09:37:15,395 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 09:37:15,885 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 09:37:15,908 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 09:37:16,458 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 09:37:16,573 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 09:37:17,136 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 09:37:17,225 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 09:37:17,232 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 09:37:17,266 [DEBUG] matplotlib: interactive is False
2025-10-15 09:37:17,267 [DEBUG] matplotlib: platform is win32
2025-10-15 09:37:17,338 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 09:37:17,345 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 09:37:18,177 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 09:37:18,893 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 09:37:19,439 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:19,456 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002568CB35C50>
2025-10-15 09:37:19,456 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:37:19,458 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:19,461 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:37:19,462 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:19,463 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:37:19,490 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:19 GMT')])
2025-10-15 09:37:19,490 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 09:37:19,490 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:37:19,495 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:19,495 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:19,496 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:19,497 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:19,497 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:17,327 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:15:19,545 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:15:20,201 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:15:20,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:15:20,944 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:15:21,908 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:21,908 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018064EF8290>
2025-10-15 14:15:21,912 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,913 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:21,913 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,916 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:21,916 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,918 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:15:21 GMT')])
2025-10-15 14:15:21,919 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:15:21,920 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,921 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:21,922 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:21,922 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:21,924 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:21,926 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:21,927 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:21,940 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018064EFAC10>
2025-10-15 14:15:21,941 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:21,946 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,947 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:15:21 GMT')])
2025-10-15 14:15:21,948 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:21,950 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:21,954 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:24,634 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:24,674 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:15:24,975 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:15:25,317 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:25,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:15:26,144 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:26,164 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018066ACDDD0>
2025-10-15 14:15:26,164 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:26,167 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:26,168 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:26,169 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:26,170 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:26,177 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:15:25 GMT')])
2025-10-15 14:15:26,178 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:15:26,179 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:26,181 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:26,182 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:26,183 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:26,183 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:26,184 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:26,514 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:26,799 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:26,827 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:15:27,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:27,434 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:27,461 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:15:27,752 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:15:28,031 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:15:28,351 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:15:28,646 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:15:28,675 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:15:29,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:15:29,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:15:30,396 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:15:30,837 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:15:30,841 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:15:31,443 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:15:31,465 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:15:31,995 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:15:32,109 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:15:32,689 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:15:32,780 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:15:32,786 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:15:32,827 [DEBUG] matplotlib: interactive is False
2025-10-15 14:15:32,827 [DEBUG] matplotlib: platform is win32
2025-10-15 14:15:32,893 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:15:32,902 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:15:33,563 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:15:34,551 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:15:35,108 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:35,115 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000180066FF750>
2025-10-15 14:15:35,117 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,119 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:35,119 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,121 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:35,122 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,128 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:15:34 GMT')])
2025-10-15 14:15:35,130 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:15:35,131 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,132 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:35,133 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:35,134 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:35,135 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:35,137 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:35,444 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-620186c7-4611-42e2-922e-52bd95d1a981', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6875, rerank=-6.2736)\nđộng, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế Công ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã\n(Source: )\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:15:35,446 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:15:35,447 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:15:35,546 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800CFA7C10>
2025-10-15 14:15:35,547 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001806555E600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:15:35,621 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800CDBFAD0>
2025-10-15 14:15:35,623 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,624 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:35,624 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,625 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:35,626 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:38,928 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2719'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:15:35 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:15:38,929 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:15:38,930 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:38,931 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:38,932 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:38,932 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:38,933 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2719', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:15:35 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:15:38,934 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:16:27,800 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:16:29,865 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:16:30,440 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:16:31,136 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:16:31,140 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:16:32,012 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:32,017 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9D93F8910>
2025-10-15 14:16:32,019 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,021 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:32,022 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,022 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:32,023 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,024 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:16:31 GMT')])
2025-10-15 14:16:32,025 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:16:32,027 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,028 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:32,029 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:32,029 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:32,030 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:32,032 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:32,034 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:32,036 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9D9564690>
2025-10-15 14:16:32,036 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,038 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:32,039 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,039 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:32,041 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,041 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:16:31 GMT')])
2025-10-15 14:16:32,042 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:16:32,044 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,045 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:32,045 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:32,046 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:32,047 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:32,047 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:34,271 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:34,302 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:16:34,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:16:35,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:35,597 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:16:36,355 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:36,366 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9DB10BB50>
2025-10-15 14:16:36,367 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:36,369 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:36,371 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:36,372 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:36,374 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:36,380 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:16:36 GMT')])
2025-10-15 14:16:36,381 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:16:36,382 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:36,384 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:36,385 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:36,386 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:36,387 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:36,388 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:36,691 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:36,991 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,021 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:16:37,348 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,657 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,687 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:16:37,996 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:16:38,292 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:16:38,610 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:16:38,902 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:16:38,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:16:39,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:16:39,568 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:16:40,545 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:16:40,992 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:16:40,997 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:16:41,433 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:16:41,450 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:16:41,935 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:16:42,032 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:16:42,460 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:16:42,530 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:16:42,537 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:16:42,567 [DEBUG] matplotlib: interactive is False
2025-10-15 14:16:42,572 [DEBUG] matplotlib: platform is win32
2025-10-15 14:16:42,626 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:16:42,629 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:16:43,149 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:16:44,049 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:16:44,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:16:44,950 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:16:45,118 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:45,143 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F2379B50>
2025-10-15 14:16:45,143 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,146 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:45,146 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,147 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:45,149 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,153 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:16:44 GMT')])
2025-10-15 14:16:45,155 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:16:45,155 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,157 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:45,158 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:45,159 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:45,159 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:45,161 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:45,455 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-12fc42d8-9cc2-4bd2-97cc-b18a43034d35', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n\n## Dữ liệu giá/ thị trường: \n📊 **VCB** — Giá hiện tại: 63,000.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -100.00 (-0.16%)  \n• Khối lượng: 4,362,400  \n🕒 Cập nhật: 15-10-2025 14:16:44\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã động, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức để nhận định xu hướng.\n\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:16:45,460 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:16:45,461 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:16:45,576 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F7BCDE10>
2025-10-15 14:16:45,576 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D9D9BBE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:16:45,653 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F0F2D3D0>
2025-10-15 14:16:45,653 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,655 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:45,655 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,658 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:45,658 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:48,959 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2697'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:16:45 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:16:48,960 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:16:48,961 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:48,962 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:48,963 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:48,965 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:48,965 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2697', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:16:45 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:16:48,966 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:19:02,354 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:19:02,355 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2E9B35910>
2025-10-15 14:19:02,356 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:19:02,359 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,366 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:19:02 GMT')])
2025-10-15 14:19:02,367 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:19:02,367 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:19:02,368 [DEBUG] httpcore.connection: close.started
2025-10-15 14:19:02,368 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:19:02,588 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-8ace584e-30a1-4a02-8c55-fd9aef97ad7c', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. Nếu chỉ có giá cổ phiếu, hãy mô tả tình hình giá hiện tại.\n4. Nếu chỉ có tin tức, hãy tóm tắt xu hướng thị trường.\n5. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - KHÔNG dùng ngôn ngữ lập trình, không code, không markdown, không in ra cấu trúc JSON.\n- KHÔNG thêm tiền tố như `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHÔNG nói "Tôi không phải chuyên gia tài chính" hoặc thêm lời mở đầu/ngoài lề.\n- Trả lời ngắn gọn, tự nhiên, ưu tiên tiếng Việt, có thể giữ nguyên thuật ngữ (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n(Luôn sử dụng thông tin trên khi người dùng hỏi về ngày, giờ, hôm qua, mai, tuần trước/sau.)\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Tóm tắt ngắn gọn tin tức liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nđộng, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n[Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntrị tài sản tăng mạnh. Cụ thể, với hơn 170,6 triệu cổ phiếu VIC nắm giữ trực tiếp, bà Phạm Thu Hương hiện sở hữu khối tài sản ước tính khoảng 37.500 tỷ đồng, tương đương với hơn 1,4 tỷ USD. Như vậy, tính đến nay, tỷ phú Phạm Nhật Vượng và bà Phạm Thu Hương cũng là cặp vợ chồng doanh nhân duy nhất tạ đề khác thuộc thẩm quyền. Theo thông báo này, ngày chốt danh sách cổ đông để lấy ý kiến là 30/10 và thời gian lấy ý kiến cổ đông dự kiến là trong tháng 11. Tỷ phú Phạm Nhật Vượng cũng vừa hoàn tất việc dùng hơn 60 triệu cổ phiếu VIC (tương đương 1,55% vốn điều lệ của Vingroup) để góp vốn vào CTCP Nă VRE, vốn hóa Tập đoàn Vingroup lần đầu tiên vượt ngưỡng 800.000 tỷ đồng. Đây cũng là kỷ lục mới của thị trường chứng khoán Việt Nam. Đặc biệt, cùng ngày, theo dữ liệu cập nhật của Forbes, tài sản của tỷ phú Phạm Nhật Vượng, Chủ tịch Tập đoàn Vingroup đã đạt 20,3 tỷ USD trong, tức là tăng gấp 3 lần s Phiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị thay thế bằng cú đảo chiều bất ngờ trong buổi chiều. Cụ thể, khi lực cầu suy yếu dần, phe bán bắt đầu tận dụng cơ hội để chốt lời, nhất ở nhóm cổ phiếu đ\n(Source: )\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00] (score=0.6667, rerank=-7.0788)\ntục nâng lên doanh thu 5.000 tỷ và lợi nhuận sau thuế 2.000 tỷ đồng. Nếu hoàn thành, đây sẽ là giai đoạn tăng trưởng mạnh nhất trong lịch sử Bất động sản CRV. Trước khi niêm yết, vào tháng 7/2025, Đại hội đồng cổ đông CRV đã thông qua phương án phát hành thêm 16,81 triệu cổ phiếu cho cổ đông hiện hữ\n(Source: )\n\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00] (score=0.6, rerank=-6.283)\ntrước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ trợ sâu hơn ở hỗ trợ quanh 1.500 /- điểm. Khi thị trường xác nhận đóng cửa dưới trung bình trượt ngắn hạn, cổ phiếu trong tài khoản gãy qua đường trung bình trượt… là tín hiệu kỹ thuật xác nhận Báo cáo chiến lược thị trường mới đây củaChứng khoán An Bình (ABS)nhận định hiện tại đang là giai đoạn thị trường tăng giá trở lại sau nhịp điều chỉnh ngắn hạn 5 tuần vừa qua. Về mặt định giá, P/E của VN-Index cho 4 quý gần nhất đã tăng từ mức 14,7x ngày 8/9 lên mức 15,4x ngày 8/10/2025, gần đạt tới\n(Source: )\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** Hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:19:02,590 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:19:02,590 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:19:02,693 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2EE6DE450>
2025-10-15 14:19:02,693 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E2CFD0C0E0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:19:02,767 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2EA4A2850>
2025-10-15 14:19:02,767 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:19:06,159 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2373'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:19:02 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:19:06,159 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:19:06,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:19:06,160 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2373', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:19:02 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:19:06,161 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:28:18,625 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:28:18,643 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023788294A90>
2025-10-15 14:28:18,643 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:28:18,645 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:28:18,652 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 07:28:18 GMT')])
2025-10-15 14:28:18,653 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:28:18,653 [DEBUG] httpcore.connection: close.started
2025-10-15 14:28:18,655 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:28:18,878 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a2867fb5-b4bc-4cfb-b5ae-183b497bab6b', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n\n\n## Bối cảnh thời gian: \n Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Trả về thông tin liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nđộng, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n[Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntrị tài sản tăng mạnh. Cụ thể, với hơn 170,6 triệu cổ phiếu VIC nắm giữ trực tiếp, bà Phạm Thu Hương hiện sở hữu khối tài sản ước tính khoảng 37.500 tỷ đồng, tương đương với hơn 1,4 tỷ USD. Như vậy, tính đến nay, tỷ phú Phạm Nhật Vượng và bà Phạm Thu Hương cũng là cặp vợ chồng doanh nhân duy nhất tạ đề khác thuộc thẩm quyền. Theo thông báo này, ngày chốt danh sách cổ đông để lấy ý kiến là 30/10 và thời gian lấy ý kiến cổ đông dự kiến là trong tháng 11. Tỷ phú Phạm Nhật Vượng cũng vừa hoàn tất việc dùng hơn 60 triệu cổ phiếu VIC (tương đương 1,55% vốn điều lệ của Vingroup) để góp vốn vào CTCP Nă VRE, vốn hóa Tập đoàn Vingroup lần đầu tiên vượt ngưỡng 800.000 tỷ đồng. Đây cũng là kỷ lục mới của thị trường chứng khoán Việt Nam. Đặc biệt, cùng ngày, theo dữ liệu cập nhật của Forbes, tài sản của tỷ phú Phạm Nhật Vượng, Chủ tịch Tập đoàn Vingroup đã đạt 20,3 tỷ USD trong, tức là tăng gấp 3 lần s Phiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị thay thế bằng cú đảo chiều bất ngờ trong buổi chiều. Cụ thể, khi lực cầu suy yếu dần, phe bán bắt đầu tận dụng cơ hội để chốt lời, nhất ở nhóm cổ phiếu đ\n(Source: )\n\n[Một cổ phiếu bất động sản “bốc đầu” kịch trần 3 phiên liên tiếp | 15-10-2025 00:16:00] (score=0.6667, rerank=-7.0788)\ntục nâng lên doanh thu 5.000 tỷ và lợi nhuận sau thuế 2.000 tỷ đồng. Nếu hoàn thành, đây sẽ là giai đoạn tăng trưởng mạnh nhất trong lịch sử Bất động sản CRV. Trước khi niêm yết, vào tháng 7/2025, Đại hội đồng cổ đông CRV đã thông qua phương án phát hành thêm 16,81 triệu cổ phiếu cho cổ đông hiện hữ\n(Source: )\n\n[ABS: VN-Index bước vào nhịp tăng mới, mục tiêu 1.820 điểm | 15-10-2025 00:06:00] (score=0.6, rerank=-6.283)\ntrước đó khiến cho động lượng giảm, giá giảm qua hỗ trợ 1.586-1.600 điểm. Thị trường có thể tìm về mức hỗ trợ sâu hơn ở hỗ trợ quanh 1.500 /- điểm. Khi thị trường xác nhận đóng cửa dưới trung bình trượt ngắn hạn, cổ phiếu trong tài khoản gãy qua đường trung bình trượt… là tín hiệu kỹ thuật xác nhận Báo cáo chiến lược thị trường mới đây củaChứng khoán An Bình (ABS)nhận định hiện tại đang là giai đoạn thị trường tăng giá trở lại sau nhịp điều chỉnh ngắn hạn 5 tuần vừa qua. Về mặt định giá, P/E của VN-Index cho 4 quý gần nhất đã tăng từ mức 14,7x ngày 8/9 lên mức 15,4x ngày 8/10/2025, gần đạt tới\n(Source: )\n\n## Task Type:\nIntent: rag\nMô tả: Phân tích câu hỏi tổng quát dựa trên ngữ cảnh có sẵn.\n\n\n## Task Input:\n**User:** hôm nay có tin tức gì mới?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:28:18,880 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:28:18,880 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:28:19,006 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000237EAA5A0D0>
2025-10-15 14:28:19,006 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000237E3FEFE30> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:28:19,072 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000237EABD5710>
2025-10-15 14:28:19,072 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:28:19,074 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:28:22,401 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2291'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:28:19 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:28:22,401 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:28:22,403 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2291', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:28:19 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:28:22,403 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:30:42,965 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:30:44,952 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:30:45,537 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:30:46,270 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:30:46,274 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:30:47,027 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:47,048 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B431BA8110>
2025-10-15 14:30:47,049 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,051 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:47,051 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,052 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:47,054 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,055 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:30:46 GMT')])
2025-10-15 14:30:47,056 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:30:47,057 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,058 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:47,059 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:47,059 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:47,060 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:47,061 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:47,062 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:47,079 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B431BAB110>
2025-10-15 14:30:47,081 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,082 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:47,084 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,085 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:47,086 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,087 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:30:46 GMT')])
2025-10-15 14:30:47,088 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:30:47,088 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,093 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:47,093 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:47,094 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:47,096 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:47,097 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:49,261 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:49,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:30:49,588 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:30:49,905 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:49,930 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:30:50,686 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:50,688 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B433A4FF50>
2025-10-15 14:30:50,689 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:50,691 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:50,692 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:50,693 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:50,694 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:30:50,696 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:30:50 GMT')])
2025-10-15 14:30:50,697 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:30:50,698 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:30:50,700 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:50,701 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:50,702 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:50,703 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:50,704 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:51,029 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:51,324 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:51,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:30:51,670 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:52,434 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:52,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:30:52,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:30:53,039 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:30:53,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:30:53,670 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:30:53,696 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:30:54,046 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:30:54,339 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:30:55,239 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:30:55,630 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:30:55,633 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:30:55,990 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:30:56,015 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:30:56,430 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:30:56,542 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:30:57,008 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:30:57,075 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:30:57,080 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:30:57,110 [DEBUG] matplotlib: interactive is False
2025-10-15 14:30:57,112 [DEBUG] matplotlib: platform is win32
2025-10-15 14:30:57,178 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:30:57,181 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:30:57,647 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:30:58,313 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:30:58,747 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:30:59,267 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:30:59,487 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:59,489 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B44AAEF3D0>
2025-10-15 14:30:59,492 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,495 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:59,496 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,497 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:59,499 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,502 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:30:59 GMT')])
2025-10-15 14:30:59,503 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:30:59,505 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,507 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:59,508 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:59,509 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:59,511 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:59,512 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:59,809 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-6c91dfd5-ffd6-4e57-b1c3-f05606a41f21', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n\n\n## Bối cảnh thời gian: \n Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Trả về thông tin liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n\n## Dữ liệu giá/ thị trường: \n📊 **VCB** — Giá hiện tại: 62,900.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -200.00 (-0.32%)  \n• Khối lượng: 4,676,100  \n🕒 Cập nhật: 15-10-2025 14:30:59\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã động, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức để nhận định xu hướng.\n\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:30:59,810 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:30:59,811 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:30:59,921 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B45032DA10>
2025-10-15 14:30:59,923 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B43220E600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:30:59,989 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B44AA9D450>
2025-10-15 14:30:59,990 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,991 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:59,992 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,993 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:59,994 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:31:03,288 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2732'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:30:59 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:31:03,288 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:31:03,289 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:31:03,290 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:31:03,291 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:31:03,291 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:31:03,292 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2732', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:30:59 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:31:03,294 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:47:57,019 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:47:59,052 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:47:59,626 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:48:00,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:48:00,283 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:48:01,136 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:01,156 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA15E985D0>
2025-10-15 14:48:01,156 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,158 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:01,158 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,160 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:01,160 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,161 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:48:00 GMT')])
2025-10-15 14:48:01,162 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:48:01,163 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,165 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:01,165 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:01,166 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:01,167 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:01,167 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:01,168 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:01,171 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA15EA8990>
2025-10-15 14:48:01,173 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,175 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:01,176 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,177 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:01,177 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,180 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:48:00 GMT')])
2025-10-15 14:48:01,181 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:48:01,183 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,184 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:01,185 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:01,186 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:01,186 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:01,187 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:03,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:03,420 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:48:03,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:48:04,052 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:04,080 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:48:04,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:04,859 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA17AEF850>
2025-10-15 14:48:04,860 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:04,861 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:04,863 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:04,865 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:04,866 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:04,868 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:48:04 GMT')])
2025-10-15 14:48:04,869 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:48:04,869 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:04,872 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:04,873 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:04,874 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:04,875 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:04,875 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:05,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:05,949 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:05,975 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:48:06,295 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:06,578 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:06,604 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:48:06,896 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:48:07,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:48:08,496 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:48:08,779 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:48:08,806 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:48:09,166 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:48:09,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:48:10,492 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:48:10,933 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:48:10,937 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:48:11,304 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:48:11,323 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:48:11,765 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:48:11,852 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:48:12,273 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:48:12,345 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:48:12,352 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:48:12,382 [DEBUG] matplotlib: interactive is False
2025-10-15 14:48:12,384 [DEBUG] matplotlib: platform is win32
2025-10-15 14:48:12,433 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:48:12,437 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:48:12,924 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:48:13,721 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:48:14,110 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:48:14,629 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:48:14,795 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:14,797 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA2DD0A310>
2025-10-15 14:48:14,798 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:14,800 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:14,801 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:14,802 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:14,802 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:14,808 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:48:14 GMT')])
2025-10-15 14:48:14,810 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:48:14,810 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:14,811 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:14,812 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:14,813 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:14,814 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:14,815 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:15,075 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1b81a76c-d088-43bc-9977-ee19dced0fd4', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n\n\n## Bối cảnh thời gian: \n Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Trả về thông tin liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n\n## Dữ liệu giá/ thị trường: \n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 14:48:14\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã động, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức để nhận định xu hướng.\n\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:48:15,075 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:48:15,076 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:48:15,161 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA345143D0>
2025-10-15 14:48:15,162 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CA164FE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:48:15,221 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA3451D090>
2025-10-15 14:48:15,222 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:15,223 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:15,224 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:15,225 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:15,225 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:18,494 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2737'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:48:14 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:48:18,495 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:48:18,496 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:18,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:18,497 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:18,498 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:18,498 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2737', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:48:14 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:48:18,500 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:49:43,552 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:49:44,168 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:49:44,197 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:49:44,213 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA2D9EFFD0>
2025-10-15 14:49:44,214 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,215 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:49:44,217 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,218 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:49:44,219 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,224 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:49:43 GMT')])
2025-10-15 14:49:44,225 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:49:44,226 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,228 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:49:44,229 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:49:44,230 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:49:44,231 [DEBUG] httpcore.connection: close.started
2025-10-15 14:49:44,232 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:49:44,443 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a408af3c-11b2-446a-ac10-c31b5c65303a', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n\n\n## Bối cảnh thời gian: \n Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Trả về thông tin liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n\n## Dữ liệu giá/ thị trường: \n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 14:49:44\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã động, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức để nhận định xu hướng.\n\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:49:44,445 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:49:44,446 [DEBUG] httpcore.connection: close.started
2025-10-15 14:49:44,447 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:49:44,447 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:49:44,550 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA322F6C50>
2025-10-15 14:49:44,551 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CA164FE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:49:44,615 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA322D3610>
2025-10-15 14:49:44,617 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,617 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:49:44,619 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,620 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:49:44,621 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:49:47,966 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2674'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:49:44 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:49:47,967 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:49:47,968 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:49:47,969 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:49:47,970 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:49:47,971 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:49:47,971 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2674', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:49:44 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:49:47,972 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:10:45,828 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:10:46,423 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:10:46,451 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:10:46,453 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DA8E550>
2025-10-15 15:10:46,455 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,458 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:10:46,459 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,461 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:10:46,461 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,467 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:10:46 GMT')])
2025-10-15 15:10:46,470 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:10:46,471 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,472 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:10:46,473 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:10:46,473 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:10:46,474 [DEBUG] httpcore.connection: close.started
2025-10-15 15:10:46,475 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:10:46,714 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-b52c442d-bc1b-40b9-bb69-13bf511aac02', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên dạng gốc\n\n## Instruction:\n Bạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n\n\n## Constraints:\n - Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n\n\n## Bối cảnh thời gian: \n Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Examples (chỉ minh họa định dạng hội thoại, KHÔNG lặp lại nội dung ví dụ, chỉ dùng để tham khảo cấu trúc):\n\n    **- Example 1:**\n    **User:** Hãy cho tôi thông tin về một mã cổ phiếu.  \n    **Assistant:** Trả về thông tin liên quan đến mã cổ phiếu đó.\n\n    **- Example 2:**\n    **User:** Thị trường chứng khoán Việt Nam có xu hướng gì nổi bật?  \n    **Assistant:** Phân tích xu hướng dựa trên tin tức và dữ liệu, ngắn gọn, súc tích.\n\n\n## Dữ liệu giá/ thị trường: \n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 15:10:46\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã động, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức để nhận định xu hướng.\n\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:10:46,716 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:10:46,717 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:10:46,845 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DAFBC50>
2025-10-15 15:10:46,846 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B2462180E0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:10:46,904 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DC70650>
2025-10-15 15:10:46,905 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,907 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:10:46,908 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,909 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:10:46,909 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:10:50,168 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2541'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:10:46 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:10:50,169 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:10:50,170 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:10:50,171 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:10:50,171 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:10:50,172 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:10:50,172 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2541', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:10:46 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:10:50,173 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:22:06,461 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:22:08,447 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:22:09,037 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:22:09,694 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:22:09,697 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:22:10,511 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:10,513 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C351A88C10>
2025-10-15 15:22:10,513 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,516 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:10,516 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,517 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:10,518 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,519 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:22:10 GMT')])
2025-10-15 15:22:10,520 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:22:10,520 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,521 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:10,521 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:10,522 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:10,522 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:10,523 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:10,524 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:10,526 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C351478E10>
2025-10-15 15:22:10,527 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,529 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:10,530 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,530 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:10,531 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,531 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:22:10 GMT')])
2025-10-15 15:22:10,533 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:22:10,536 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,537 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:10,537 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:10,538 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:10,539 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:10,540 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:12,803 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:12,832 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:22:13,141 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:22:13,469 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:13,497 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:22:14,279 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:14,282 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35390B7D0>
2025-10-15 15:22:14,284 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:14,287 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:14,288 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:14,289 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:14,290 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:14,294 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:22:14 GMT')])
2025-10-15 15:22:14,296 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:22:14,297 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:14,299 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:14,300 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:14,301 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:14,302 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:14,302 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:14,608 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:14,897 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:14,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:22:15,260 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:15,549 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:15,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:22:15,875 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:22:16,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:22:16,466 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:22:16,973 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:22:17,001 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:22:17,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:22:17,650 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:22:18,573 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:22:18,966 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:22:18,970 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:22:19,363 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:22:19,389 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:22:19,912 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:22:20,018 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:22:20,593 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:22:20,691 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:22:20,698 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:22:20,733 [DEBUG] matplotlib: interactive is False
2025-10-15 15:22:20,735 [DEBUG] matplotlib: platform is win32
2025-10-15 15:22:20,793 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:22:20,796 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:22:21,344 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:22:21,924 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:22:22,333 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:22:22,784 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:22:23,017 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:23,020 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35E972690>
2025-10-15 15:22:23,022 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,024 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:23,026 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,028 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:23,029 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,031 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:22:22 GMT')])
2025-10-15 15:22:23,033 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:22:23,034 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,036 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:23,037 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:23,038 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:23,038 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:23,040 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:23,299 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-4823973f-a194-4c46-8fe1-73eafb49ee3c', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh biến động giá với tình hình chung thị trường.\n        - Nêu nguyên nhân, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n        - KHÔNG liệt kê tiêu đề tin tức.\n        \n## Dữ liệu API / Thị trường:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 15:22:22\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:22:23,301 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:22:23,302 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:22:23,433 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C370100550>
2025-10-15 15:22:23,434 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C3520EA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:22:23,502 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35E9779D0>
2025-10-15 15:22:23,504 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,506 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:23,506 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,508 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:23,509 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:26,793 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2839'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:22:23 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:22:26,794 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:22:26,795 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:26,795 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:26,796 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:26,797 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:26,798 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2839', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:22:23 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:22:26,798 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:36:17,822 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:36:19,970 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:36:20,905 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:36:21,658 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:36:21,663 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:36:22,402 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:36:26,440 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-15 15:36:26,440 [DEBUG] root: Unable to get server version: [WinError 10061] No connection could be made because the target machine actively refused it, server version defaults to None
2025-10-15 15:36:26,443 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:36:30,478 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-15 15:38:31,611 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:38:31,617 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:38:32,313 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:32,313 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC1C3A6C50>
2025-10-15 15:38:32,317 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,318 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:32,320 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,321 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:32,321 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,330 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:38:32 GMT')])
2025-10-15 15:38:32,331 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:38:32,332 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,333 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:32,335 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:32,335 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:32,335 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:32,337 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:32,338 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:32,340 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC1C38BD10>
2025-10-15 15:38:32,341 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,343 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:32,344 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,345 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:32,346 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,347 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:38:32 GMT')])
2025-10-15 15:38:32,348 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:38:32,348 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,351 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:32,352 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:32,353 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:32,354 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:32,356 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:35,200 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:35,232 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:38:35,546 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:38:35,867 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:35,898 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:38:37,272 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:37,279 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC6F479B50>
2025-10-15 15:38:37,281 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:37,283 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:37,284 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:37,286 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:37,286 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:37,314 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:38:37 GMT')])
2025-10-15 15:38:37,316 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:38:37,317 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:37,318 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:37,319 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:37,320 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:37,322 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:37,322 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:37,637 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:37,913 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:37,945 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:38:38,274 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:38,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:38,573 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:38:38,846 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:38:39,119 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:38:39,422 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:38:39,676 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:38:39,708 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:38:40,192 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:38:40,471 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:38:41,435 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:38:41,876 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:38:41,882 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:38:42,262 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:38:42,297 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:38:42,833 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:38:42,932 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:38:43,411 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:38:43,548 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:38:43,555 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:38:43,589 [DEBUG] matplotlib: interactive is False
2025-10-15 15:38:43,591 [DEBUG] matplotlib: platform is win32
2025-10-15 15:38:43,667 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:38:43,675 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:38:44,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:38:45,432 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:38:46,281 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:46,281 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0A604D90>
2025-10-15 15:38:46,281 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,289 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:46,291 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,292 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:46,293 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,309 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:38:46 GMT')])
2025-10-15 15:38:46,310 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:38:46,311 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,313 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:46,313 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:46,314 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:46,315 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:46,315 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:46,583 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-cc03452e-c5d6-419c-b8b2-3b23c81fd685', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Trả lời ngắn gọn, chính xác theo thông tin có trong Context hoặc API.\n        - Nếu không có thông tin, nói rõ "Hiện tôi chưa có dữ liệu phù hợp".\n        \n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: general\nMô tả: Trả lời chung các câu hỏi không xác định rõ intent.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:38:46,583 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:38:46,588 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:38:46,721 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BBED850>
2025-10-15 15:38:46,722 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EC6ED37140> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:38:46,791 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BBED910>
2025-10-15 15:38:46,791 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,793 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:46,794 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,796 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:46,797 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:50,058 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2697'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:38:47 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:38:50,060 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:50,060 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2697', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:38:47 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:38:50,060 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:40:56,856 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:40:57,344 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:40:57,360 [DEBUG] RAGPipeline: router: API
2025-10-15 15:40:57,360 [DEBUG] RAGPipeline: intent: stock
2025-10-15 15:45:22,277 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:45:22,280 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC6E849950>
2025-10-15 15:45:22,280 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,284 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:45:22,285 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,286 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:45:22,288 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,291 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:45:22 GMT')])
2025-10-15 15:45:22,293 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:45:22,294 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,295 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:45:22,296 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:45:22,297 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:45:22,298 [DEBUG] httpcore.connection: close.started
2025-10-15 15:45:22,300 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:45:22,461 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-03239c57-c5be-44be-a108-9019dd13587a', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Trả lời ngắn gọn, chính xác theo thông tin có trong Context hoặc API.\n        - Nếu không có thông tin, nói rõ "Hiện tôi chưa có dữ liệu phù hợp".\n        \n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: general\nMô tả: Trả lời chung các câu hỏi không xác định rõ intent.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:45:22,462 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:45:22,463 [DEBUG] httpcore.connection: close.started
2025-10-15 15:45:22,464 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:45:22,464 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:45:22,601 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BC6F790>
2025-10-15 15:45:22,601 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EC6ED37140> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:45:22,666 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0F9E43D0>
2025-10-15 15:45:22,667 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,668 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:45:22,669 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:45:22,672 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:45:25,897 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2738'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:45:23 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:45:25,899 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:45:25,900 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:45:25,901 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:45:25,902 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:45:25,902 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:45:25,902 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2738', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:45:23 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:45:25,904 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:58:36,357 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:58:38,273 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:58:38,856 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:58:39,965 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:58:39,970 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:58:40,816 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:40,818 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4D898950>
2025-10-15 15:58:40,820 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,821 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:40,823 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,824 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:40,824 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,825 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:58:40 GMT')])
2025-10-15 15:58:40,826 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:58:40,826 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,828 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:40,829 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:40,829 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:40,829 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:40,830 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:40,833 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:40,834 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4D580C50>
2025-10-15 15:58:40,836 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:40,840 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,841 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:58:40 GMT')])
2025-10-15 15:58:40,842 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:58:40,843 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,844 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:40,845 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:40,847 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:40,848 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:40,848 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:43,027 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:43,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:58:43,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:58:43,663 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:43,691 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:58:44,434 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:44,439 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4F47FED0>
2025-10-15 15:58:44,439 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:44,442 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:44,444 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:44,445 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:44,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:44,450 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:58:44 GMT')])
2025-10-15 15:58:44,450 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:58:44,450 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:44,454 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:44,456 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:44,456 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:44,456 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:44,456 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:44,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,066 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,094 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:58:45,413 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,693 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:58:45,992 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:58:46,264 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:58:46,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:58:46,843 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:58:46,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:58:47,222 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:58:47,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:58:48,511 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:58:48,967 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:58:48,970 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:58:49,439 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:58:49,459 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:58:49,933 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:58:50,011 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:58:50,523 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:58:50,597 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:58:50,603 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:58:50,640 [DEBUG] matplotlib: interactive is False
2025-10-15 15:58:50,641 [DEBUG] matplotlib: platform is win32
2025-10-15 15:58:50,690 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:58:50,698 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:58:51,165 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:58:51,899 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:58:52,291 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:58:52,864 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:58:53,030 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:53,033 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C6BF28750>
2025-10-15 15:58:53,033 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,035 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:53,036 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,037 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:53,038 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,041 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:58:52 GMT')])
2025-10-15 15:58:53,042 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:58:53,043 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,044 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:53,046 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:53,046 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:53,047 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:53,048 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:53,301 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-21ff0da9-6299-4824-9ad0-d75e1d7434b7', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh biến động giá với tình hình chung thị trường.\n        - Nêu nguyên nhân, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n        - KHÔNG liệt kê tiêu đề tin tức.\n        \n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 15:58:52\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:58:53,302 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:58:53,304 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:58:53,439 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C654B90D0>
2025-10-15 15:58:53,440 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000012C4DEFA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:58:53,517 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C64F80850>
2025-10-15 15:58:53,518 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:56,811 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2690'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:58:54 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:58:56,812 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:58:56,813 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:56,815 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:56,816 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:56,817 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:56,819 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2690', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:58:54 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:58:56,819 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:03:35,004 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:03:36,982 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:03:37,518 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:03:38,620 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:03:38,629 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:03:39,457 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:39,465 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EC7B8890>
2025-10-15 16:03:39,466 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:03:39 GMT')])
2025-10-15 16:03:39,468 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:39,475 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:39,476 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:39,476 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:39,480 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EC7B9810>
2025-10-15 16:03:39,481 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,483 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:39,484 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,484 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:39,486 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,488 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:03:39 GMT')])
2025-10-15 16:03:39,491 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:03:39,494 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:39,498 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:39,501 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:39,502 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:39,503 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:41,961 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:41,992 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:03:42,275 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:03:42,587 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:42,615 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:03:43,404 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:43,407 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EE37BB50>
2025-10-15 16:03:43,408 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:43,411 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:43,412 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:43,414 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:43,414 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:43,419 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:03:43 GMT')])
2025-10-15 16:03:43,419 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:03:43,419 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:43,424 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:43,424 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:43,425 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:43,425 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:43,427 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:43,751 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:44,020 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:44,048 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:03:44,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:45,054 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:45,085 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:03:45,398 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:03:45,693 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:03:45,983 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:03:46,261 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:03:46,290 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:03:46,618 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:03:46,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:03:47,874 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:03:48,284 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:03:48,288 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:03:48,644 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:03:48,664 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:03:49,111 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:03:49,198 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:03:49,647 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:03:49,727 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:03:49,734 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:03:49,764 [DEBUG] matplotlib: interactive is False
2025-10-15 16:03:49,765 [DEBUG] matplotlib: platform is win32
2025-10-15 16:03:49,816 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:03:49,817 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:03:50,281 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:03:50,966 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:03:51,270 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:03:51,867 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:03:52,045 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:52,047 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001758BA082D0>
2025-10-15 16:03:52,048 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,049 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:52,051 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,052 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:52,053 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,055 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:03:51 GMT')])
2025-10-15 16:03:52,056 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:03:52,057 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,059 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:52,060 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:52,060 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:52,061 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:52,061 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:52,303 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-c0602ee4-b2ea-46ff-84a0-e04361bea2e0', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh **mức tăng/giảm giá cổ phiếu** với xu hướng thị trường (VNINDEX, VN30...) được mô tả trong tin tức.\n        - Chỉ tóm tắt nội dung tin tức có **ảnh hưởng đến cổ phiếu đó** (ví dụ: nhóm ngân hàng, chứng khoán, thị trường chung).\n        - Nêu rõ nguyên nhân chính khiến giá biến động (nếu có).\n        - Kết luận xu hướng ngắn hạn: “tăng nhẹ / giảm nhẹ / trung lập”.\n        - KHÔNG liệt kê tiêu đề tin tức, KHÔNG lặp nguyên văn nội dung.\n        - Viết theo giọng **phân tích tài chính ngắn gọn, tự nhiên, rõ ràng**.\n        - Ví dụ mong đợi:\n        > Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng chiều với xu hướng điều chỉnh của VN-Index khi xuất hiện tín hiệu tạo đỉnh ngắn hạn. Tin tiêu cực từ nhóm chứng khoán khiến dòng tiền thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 16:03:51\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:03:52,307 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:03:52,307 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:03:52,445 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001758BA2AE90>
2025-10-15 16:03:52,446 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000175ECE1A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:03:52,522 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001759012AF50>
2025-10-15 16:03:52,523 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,523 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:52,525 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,526 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:52,527 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:55,827 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2732'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:03:53 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:03:55,828 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:03:55,829 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:55,830 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2732', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:03:53 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:03:55,834 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:03:55,843 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:03:55,844 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:03:55,845 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:03:55,845 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:03:55,847 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:03:55.847240
2025-10-15 16:10:14,841 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:10:16,827 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:10:17,426 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:10:18,265 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:10:18,273 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:10:19,154 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:19,156 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD9248A90>
2025-10-15 16:10:19,157 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,160 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:19,161 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,161 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:19,163 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,164 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:10:19 GMT')])
2025-10-15 16:10:19,165 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:10:19,166 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,167 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:19,168 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:19,169 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:19,170 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:19,171 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:19,172 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:19,174 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD924AE90>
2025-10-15 16:10:19,176 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,176 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:19,178 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,179 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:19,180 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,182 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:19 GMT')])
2025-10-15 16:10:19,182 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:10:19,184 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,185 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:19,187 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:19,187 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:19,188 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:19,189 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:21,441 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:21,473 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:10:21,765 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:10:22,090 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:22,122 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:10:22,883 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:22,886 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD990ED90>
2025-10-15 16:10:22,887 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:22,889 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:22,890 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:22,891 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:22,892 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:22,894 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:22 GMT')])
2025-10-15 16:10:22,895 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:10:22,896 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:22,898 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:22,900 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:22,901 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:22,902 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:22,903 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:23,212 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:23,509 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:23,541 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:10:23,856 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:24,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:24,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:10:24,474 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:10:24,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:10:25,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:10:25,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:10:25,383 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:10:25,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:10:26,128 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:10:27,003 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:10:27,414 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:10:27,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:10:27,834 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:10:27,854 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:10:28,335 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:10:28,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:10:28,883 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:10:28,954 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:10:28,960 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:10:28,993 [DEBUG] matplotlib: interactive is False
2025-10-15 16:10:28,994 [DEBUG] matplotlib: platform is win32
2025-10-15 16:10:29,047 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:10:29,052 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:10:29,543 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:10:30,256 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:10:30,629 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:10:31,165 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:10:31,340 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:31,342 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AF18A8FD0>
2025-10-15 16:10:31,342 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,346 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:31,347 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,349 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:31,350 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,351 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:31 GMT')])
2025-10-15 16:10:31,354 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:10:31,355 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,356 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:31,356 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:31,358 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:31,358 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:31,358 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:31,611 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-3408844a-2984-47a6-b9ee-bd1ed570bef5', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, luôn trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Trả lời bằng TIẾNG VIỆT, tự nhiên, ngắn gọn, rõ ràng.\n- KHÔNG dùng mã code hoặc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên ký hiệu như VNINDEX, VN30, VCB,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n### Hướng dẫn phản hồi:\n- Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n- So sánh **mức tăng/giảm cổ phiếu** với xu hướng thị trường (VNINDEX, VN30...).\n- Chỉ chọn tin tức **liên quan nhóm ngành** hoặc **thị trường chung**.\n- Giải thích nguyên nhân biến động, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n- KHÔNG liệt kê tiêu đề tin, KHÔNG lặp nguyên văn nội dung.\n- Giọng văn: phân tích tài chính ngắn gọn, tự nhiên.\n- Ví dụ:\n> Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng chiều với xu hướng điều chỉnh của VN-Index khi xuất hiện tín hiệu tạo đỉnh ngắn hạn. Dòng tiền có dấu hiệu thận trọng, thanh khoản giảm nhẹ. Xu hướng ngắn hạn: giảm nhẹ.\n\n\n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 16:10:31\n\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n### Trả lời rõ ràng, 3–5 câu, theo hướng phân tích tài chính ngắn hạn.\n\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:10:31,617 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:10:31,618 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:10:31,734 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AE624DAD0>
2025-10-15 16:10:31,735 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000026AD98AA960> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:10:31,831 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AF18AB450>
2025-10-15 16:10:31,833 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,835 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:31,835 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,836 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:31,837 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:35,138 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2760'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:10:32 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:10:35,139 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:10:35,140 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:35,144 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2760', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:10:32 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:10:35,144 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:10:35,154 [DEBUG] RAGPipeline: fallback_trigger: LLM output too short
2025-10-15 16:10:35,154 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:10:35,156 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:10:35,157 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:10:35,157 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:10:35,159 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:10:35.159338
2025-10-15 16:14:07,194 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:14:09,157 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:14:09,786 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:14:10,473 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:14:10,477 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:14:11,214 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:11,216 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254307B8B90>
2025-10-15 16:14:11,217 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:11,221 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,221 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:14:11 GMT')])
2025-10-15 16:14:11,222 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:14:11,223 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,223 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:11,224 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:11,224 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:11,224 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:11,225 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:11,227 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:11,229 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254307BAE90>
2025-10-15 16:14:11,230 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,232 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:11,233 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,233 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:11,235 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,236 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:14:11 GMT')])
2025-10-15 16:14:11,237 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:14:11,237 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,239 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:11,239 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:11,241 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:11,241 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:11,241 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:13,386 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:13,418 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:14:13,730 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:14:14,188 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:14,216 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:14:14,970 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:14,972 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002543265C6D0>
2025-10-15 16:14:14,973 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:14,976 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:14,976 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:14,977 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:14,978 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:14,980 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:14:14 GMT')])
2025-10-15 16:14:14,981 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:14:14,982 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:14,984 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:14,985 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:14,986 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:14,986 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:14,987 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:15,280 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:15,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:15,607 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:14:15,932 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:16,224 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:16,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:14:16,553 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:14:16,849 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:14:17,169 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:14:17,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:14:17,486 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:14:17,832 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:14:18,142 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:14:19,047 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:14:19,450 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:14:19,457 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:14:19,841 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:14:19,860 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:14:20,321 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:14:20,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:14:20,904 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:14:20,993 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:14:21,000 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:14:21,030 [DEBUG] matplotlib: interactive is False
2025-10-15 16:14:21,031 [DEBUG] matplotlib: platform is win32
2025-10-15 16:14:21,088 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:14:21,091 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:14:21,587 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:14:22,180 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:14:22,504 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:14:22,961 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:14:23,121 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:23,146 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002544EE40190>
2025-10-15 16:14:23,147 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,148 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:23,150 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,151 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:23,151 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,157 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:14:22 GMT')])
2025-10-15 16:14:23,158 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:14:23,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,160 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:23,161 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:23,162 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:23,162 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:23,163 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:23,418 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a97f4b67-0dbb-4ea2-b4e1-0dc88a761853', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh biến động giá với tình hình chung thị trường.\n        - Nêu nguyên nhân, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n        - KHÔNG liệt kê tiêu đề tin tức.\n        \n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 16:14:22\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so \n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:14:23,420 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:14:23,421 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:14:23,536 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002543D76AE90>
2025-10-15 16:14:23,536 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025430E1A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:14:23,615 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002544EC6FD10>
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,621 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:23,622 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:26,885 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2703'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:14:24 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:14:26,886 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:14:26,887 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:26,888 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:26,888 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:26,889 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:26,890 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2703', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:14:24 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:14:26,890 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:14:26,898 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:14:26,898 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:14:26,901 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:14:26,902 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:14:26,903 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:14:26.903181
2025-10-15 19:17:13,733 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:17:14,828 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:17:15,837 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:17:15,839 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C719D96B50>
2025-10-15 19:17:15,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:17:15,844 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:17:15,844 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:17:15,846 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:17:15,847 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:17:15,871 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:17:15 GMT')])
2025-10-15 19:17:15,871 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:17:15,871 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:17:15,878 [DEBUG] httpcore.connection: close.started
2025-10-15 19:17:15,878 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:17:16,241 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a9e7dd50-7546-481d-9d74-f5af37adfc3c', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh biến động giá với tình hình chung thị trường.\n        - Nêu nguyên nhân, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n        - KHÔNG liệt kê tiêu đề tin tức.\n        \n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 19:17:14\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=2.9442)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay xảy ra, nhất là sau chuỗi tăng điểm mạnh nhất lịch sử, nhưng điều này được xem là nhịp kiểm tra lại (re-test) cần thiết. Rủi ro xu hướng chỉ thực sự xuất hiện khi vùng hỗ trợ bị xuyên thủng đi kèm thanh khoản bán tăng mạnh. Trong kịch bản tích cực, các nhịp điều chỉnh là cơ hội để tái cơ cấu danh mụ\n(Source: )\n\n[Doanh nghiệp thép đầu tiên công bố BCTC quý 3/2025: Lợi nhuận "bốc hơi" 90% so với cùng kỳ | 15-10-2025 11:29:00] (score=0.6667, rerank=-2.0305)\ntrường thép quý 3/2025 trải qua giai đoạn đầy thách thức và chịu tác động mạnh của việc Mỹ siết chặt thuế quan cũng như phòng vệ thương mại từ các quốc gia khiến tình hình căng thẳng thương mại leo thang. Điều này dẫn đến sản lượng sản xuất giảm 57% và tiêu thụ giảm 57% khiến doanh thu bán hàng giảm\n(Source: )\n\n[Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày | 15-10-2025 09:45:00] (score=0.75, rerank=2.694)\nPhiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị thay thế bằng cú đảo chiều bất ngờ trong buổi chiều. Cụ thể, khi lực cầu suy yếu dần, phe bán bắt đầu tận dụng cơ hội để chốt lời, nhất ở nhóm cổ phiếu đ\n(Source: )\n\n[Ngân hàng MB đăng ký mua 45,76 triệu cổ phiếu chào bán của MBS | 15-10-2025 09:38:00] (score=0.6667, rerank=3.8618)\nđể bổ sung vốn cho vay margin. Nếu tiếp tục hoàn tất đợt chào bán này, MBS sẽ nâng vốn điều lệ lên mức 6.587,1 tỷ đồng. Sau khi hoàn tất chào bán cổ phiếu cho cổ đông hiện hữu, MBS sẽ tiếp tục phát hành 8,59 triệu cổ phiếu theo chương trình lựa chọn người lao động (ESOP) với giá 10.000 đồng/cổ phiếu Ngân hàng TMCP Quân đội (MB, mã: MBB, sàn HoSE) vừa đăng ký thực hiện quyền mua cổ phiếu chào bán thêm của CTCP Chứng khoán MB (MBS). Theo đó, MB đăng ký thực hiện 381,37 triệu quyền mua tương đươn\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Cổ phiếu VCB hôm nay biến động như nào?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:17:16,248 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:17:16,250 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:17:16,338 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83FE50>
2025-10-15 19:17:16,340 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:17:16,450 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA15A90>
2025-10-15 19:17:16,450 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:17:16,452 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:17:16,452 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:17:16,454 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:17:16,454 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:17:19,886 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2883'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:17:16 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:17:19,886 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:17:19,892 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2883', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:17:16 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:17:19,892 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:17:19,917 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:17:19,917 [INFO] RAGPipeline: route: hybrid
2025-10-15 19:17:19,917 [INFO] RAGPipeline: intent: stock_news
2025-10-15 19:17:19,919 [INFO] RAGPipeline: llm_response_len: 1289
2025-10-15 19:17:19,919 [INFO] RAGPipeline: timestamp: 2025-10-15T19:17:19.919516
2025-10-15 19:18:27,735 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:18:33,490 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:18:34,535 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:18:34,537 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83F750>
2025-10-15 19:18:34,539 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,541 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:18:34,542 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,544 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:18:34,544 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,554 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:18:34 GMT')])
2025-10-15 19:18:34,555 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:18:34,555 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,556 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:18:34,556 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:18:34,558 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:18:34,558 [DEBUG] httpcore.connection: close.started
2025-10-15 19:18:34,558 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:18:34,610 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-ce49cf66-9093-42ab-a233-3317e430655b', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Viết 3–5 câu, kết hợp dữ liệu giá (API) và tin tức (Context).\n        - So sánh biến động giá với tình hình chung thị trường.\n        - Nêu nguyên nhân, kết luận xu hướng ngắn hạn (tăng / giảm / trung lập).\n        - KHÔNG liệt kê tiêu đề tin tức.\n        \n## Dữ liệu giá cổ phiếu:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 19:18:33\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay Thị trường chứng khoán Việt Nam đang ở giai đoạn thăng hoa hiếm thấy. VN-Index liên tục bứt phá để tiến lên mốc 1.765 điểm, mức đỉnh cao nhất trong lịch sử hoạt động. Tuy nhiên, khi chỉ số chung đã đi khá xa so với vùng đáy và không ít cổ phiếu đã ghi nhận mức tăng "bằng lần", nhiều nhà đầu tư e ngạ\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.5833, rerank=-1.478)\nCông ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. Phần lớn doanh thu của CVS đến từ lãi từ khoản đầu tư nắm giữ đến ngày đáo hạn (HTM) với gần 4 tỷ đồng. Điểm tích cực là lãi từ cho vay và phải thu đã\n(Source: )\n\n[Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày | 15-10-2025 09:45:00] (score=0.75, rerank=0.2283)\nPhiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị thay thế bằng cú đảo chiều bất ngờ trong buổi chiều. Cụ thể, khi lực cầu suy yếu dần, phe bán bắt đầu tận dụng cơ hội để chốt lời, nhất ở nhóm cổ phiếu đ\n(Source: )\n\n[Ngân hàng MB đăng ký mua 45,76 triệu cổ phiếu chào bán của MBS | 15-10-2025 09:38:00] (score=0.6, rerank=3.3085)\nđể bổ sung vốn cho vay margin. Nếu tiếp tục hoàn tất đợt chào bán này, MBS sẽ nâng vốn điều lệ lên mức 6.587,1 tỷ đồng. Sau khi hoàn tất chào bán cổ phiếu cho cổ đông hiện hữu, MBS sẽ tiếp tục phát hành 8,59 triệu cổ phiếu theo chương trình lựa chọn người lao động (ESOP) với giá 10.000 đồng/cổ phiếu Ngân hàng TMCP Quân đội (MB, mã: MBB, sàn HoSE) vừa đăng ký thực hiện quyền mua cổ phiếu chào bán thêm của CTCP Chứng khoán MB (MBS). Theo đó, MB đăng ký thực hiện 381,37 triệu quyền mua tương đương 45,76 triệu cổ phiếu do MBS phá\n## Task Type:\nIntent: stock_news\nMô tả: Kết hợp dữ liệu giá cổ phiếu (API) với tin tức (Context) để phân tích xu hướng ngắn hạn.\n\n## Task Input:\n**User:** Phân tích cổ phiểu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:18:34,617 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:18:34,619 [DEBUG] httpcore.connection: close.started
2025-10-15 19:18:34,619 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:18:34,621 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:18:34,704 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA50610>
2025-10-15 19:18:34,704 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:18:34,775 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA525D0>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:18:38,220 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2754'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:18:34 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:18:38,225 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:18:38,228 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2754', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:18:34 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:18:38,228 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:18:38,230 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:18:38,230 [INFO] RAGPipeline: route: hybrid
2025-10-15 19:18:38,232 [INFO] RAGPipeline: intent: stock_news
2025-10-15 19:18:38,232 [INFO] RAGPipeline: llm_response_len: 1247
2025-10-15 19:18:38,232 [INFO] RAGPipeline: timestamp: 2025-10-15T19:18:38.232435
2025-10-15 19:19:09,122 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:19:09,126 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83FBD0>
2025-10-15 19:19:09,128 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,130 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:19:09,130 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,132 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:19:09,135 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,148 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 12:19:08 GMT')])
2025-10-15 19:19:09,150 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:19:09,152 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,154 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:19:09,155 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:19:09,156 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:19:09,156 [DEBUG] httpcore.connection: close.started
2025-10-15 19:19:09,156 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:19:09,220 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1ba8402a-1801-4b0b-ac46-bfeb9c955483', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': '- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI chuyên về tài chính Việt Nam**, có nhiệm vụ:\n1. Phân tích xu hướng thị trường và cổ phiếu Việt Nam dựa trên dữ liệu (API) và tin tức (Context).\n2. Khi có cả dữ liệu giá cổ phiếu (API) và tin tức (Context), hãy kết hợp cả hai:\n   - So sánh giá tăng/giảm với tin tức cùng ngày.\n   - Nêu ngắn gọn nguyên nhân hoặc diễn biến chính.\n3. KHÔNG đưa ra khuyến nghị đầu tư tuyệt đối, chỉ mô tả và nhận định.\n\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n        ### Hướng dẫn phản hồi:\n        - Trả lời ngắn gọn, chính xác theo thông tin có trong Context hoặc API.\n        - Nếu không có thông tin, nói rõ "Hiện tôi chưa có dữ liệu phù hợp".\n        \n## Conversation History:\n**User:** Phân tích cổ phiểu VCB hôm nay?\n**Assistant:** Tóm tắt nhanh tin tức liên quan:\n- Tín hiệu tạo đỉnh ngắn hạn của VN-Index (15-10-2025 13:36:00): cổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động ...\n- Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 (15-10-2025 10:49:00): Công ty Cổ phần Chứng khoán CV (CVS)đã công bố BCTC quý 3/2025, ghi nhận doanh thu hoạt động đạt gần 8 tỷ, tăng trưởng 72% so với cùng kỳ năm trước. P...\n- Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày (15-10-2025 09:45:00): Phiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị tha...\n- Ngân hàng MB đăng ký mua 45,76 triệu cổ phiếu chào bán của MBS (15-10-2025 09:38:00): để bổ sung vốn cho vay margin. Nếu tiếp tục hoàn tất đợt chào bán này, MBS sẽ nâng vốn điều lệ lên mức 6.587,1 tỷ đồng. Sau khi hoàn tất chào bán cổ p...\n- Lịch sự kiện và tin vắn chứng khoán ngày 15/10/2025 (15-10-2025 05:00:00): Tin doanh nghiệp VFR -Công ty Cổ phần Vận tải và Thuê tàu:Ngày 22/10/2025 là ngày đăng ký cuối cùng để chốt danh sách cổ đông nhận cổ tức năm 2024 bằn...\n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n[Tín hiệu tạo đỉnh ngắn hạn của VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\ncổ phiếu trụ, trong khi phần còn lại của thị trường suy yếu – đây là dấu hiệu cảnh báo sớm về sự phân phối. Thứ hai,về mặt kỹ thuật, các chỉ báo động lượng như RSI có thể đi vào vùng quá mua (trên 70), nhưng trong giai đoạn xu hướng tăng mạnh, đây không phải là dấu hiệu đảo chiều đáng tin cậy. Thay\n(Source: )\n\n[Lộ diện công ty chứng khoán đầu tiên báo lỗ trong quý 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nđộng, tăng trưởng mạnh 157% so với cùng kỳ năm trước. Tuy vậy, công ty chứng khoán này lỗ trước thuế hơn 18 tỷ đồng, tích cực hơn khoản lỗ 24 tỷ trong cùng kỳ năm 2024. Năm 2025, CVS đặt kế hoạch doanh thu gần 55 tỷ đồng, gấp gần 5 lần thực hiện năm trước. Tuy nhiên, công ty đặt kế hoạch lỗ sau thuế\n(Source: )\n\n[Vingroup lập kỷ lục chưa từng có trong lịch sử VN, tỷ phú Phạm Nhật Vượng tạo kỳ tích trong cùng 1 ngày | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntrị tài sản tăng mạnh. Cụ thể, với hơn 170,6 triệu cổ phiếu VIC nắm giữ trực tiếp, bà Phạm Thu Hương hiện sở hữu khối tài sản ước tính khoảng 37.500 tỷ đồng, tương đương với hơn 1,4 tỷ USD. Như vậy, tính đến nay, tỷ phú Phạm Nhật Vượng và bà Phạm Thu Hương cũng là cặp vợ chồng doanh nhân duy nhất tạ đề khác thuộc thẩm quyền. Theo thông báo này, ngày chốt danh sách cổ đông để lấy ý kiến là 30/10 và thời gian lấy ý kiến cổ đông dự kiến là trong tháng 11. Tỷ phú Phạm Nhật Vượng cũng vừa hoàn tất việc dùng hơn 60 triệu cổ phiếu VIC (tương đương 1,55% vốn điều lệ của Vingroup) để góp vốn vào CTCP Nă VRE, vốn hóa Tập đoàn Vingroup lần đầu tiên vượt ngưỡng 800.000 tỷ đồng. Đây cũng là kỷ lục mới của thị trường chứng khoán Việt Nam. Đặc biệt, cùng ngày, theo dữ liệu cập nhật của Forbes, tài sản của tỷ phú Phạm Nhật Vượng, Chủ tịch Tập đoàn Vingroup đã đạt 20,3 tỷ USD trong, tức là tăng gấp 3 lần s Phiên giao dịch ngày 14/10 của thị trường chứng khoán Việt Nam diễn ra đầy kịch tính. Thị trường kỳ vọng về một nhịp bứt phá mạnh mẽ, nhưng lại bị thay thế bằng cú đảo chiều bất ngờ trong buổi chiều. Cụ thể, khi lực cầu suy yếu dần, phe bán bắt đầu tận dụng cơ hội để chốt lời, nhất ở nhóm cổ phiếu đ\n(Source: )\n\n[Một cổ phiếu bất động sản “bốc đầu” kị\n## Task Type:\nIntent: news\nMô tả: Tóm tắt tin tức chứng khoán nổi bật.\n\n## Task Input:\n**User:** hôm nay có tin tức gì mới?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:19:09,228 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:19:09,229 [DEBUG] httpcore.connection: close.started
2025-10-15 19:19:09,231 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:19:09,233 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:19:09,292 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83D350>
2025-10-15 19:19:09,292 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:19:09,363 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83E810>
2025-10-15 19:19:09,363 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:19:09,368 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:19:12,736 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2577'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:19:09 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:19:12,736 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:19:12,738 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:19:12,739 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:19:12,739 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:19:12,740 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:19:12,740 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2577', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:19:09 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:19:12,740 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:19:12,742 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:19:12,742 [INFO] RAGPipeline: route: rag
2025-10-15 19:19:12,742 [INFO] RAGPipeline: intent: news
2025-10-15 19:19:12,743 [INFO] RAGPipeline: llm_response_len: 1254
2025-10-15 19:19:12,743 [INFO] RAGPipeline: timestamp: 2025-10-15T19:19:12.743934
2025-10-15 19:55:07,311 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 19:55:11,217 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 19:55:13,352 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 19:55:15,061 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 19:55:15,073 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 19:55:17,544 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:17,547 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA8E718D10>
2025-10-15 19:55:17,547 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,554 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:17,556 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,556 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:17,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,564 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:55:17 GMT')])
2025-10-15 19:55:17,568 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 19:55:17,568 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,570 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:17,573 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:17,575 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:17,576 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:17,579 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:17,581 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:17,589 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA8ED2AE10>
2025-10-15 19:55:17,591 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,594 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:17,597 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,600 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:17,603 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,606 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:55:17 GMT')])
2025-10-15 19:55:17,609 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 19:55:17,613 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,616 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:17,618 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:17,620 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:17,620 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:17,624 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:23,565 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:23,638 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:55:24,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:55:24,585 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:24,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 19:55:26,389 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:26,396 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA90BCBB50>
2025-10-15 19:55:26,397 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:26,400 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:26,404 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:26,404 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:26,408 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:26,430 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:55:26 GMT')])
2025-10-15 19:55:26,433 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 19:55:26,434 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:26,440 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:26,440 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:26,444 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:26,444 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:26,447 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:26,810 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:27,146 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:27,215 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 19:55:27,657 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:28,066 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:28,136 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:55:28,986 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 19:55:29,396 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:55:29,911 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:55:30,318 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:55:30,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 19:55:30,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 19:55:31,242 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 19:55:33,597 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:55:34,873 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:55:34,883 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:55:35,857 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:55:35,922 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:55:37,033 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 19:55:37,221 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:55:41,395 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 19:55:41,662 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 19:55:41,680 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 19:55:41,772 [DEBUG] matplotlib: interactive is False
2025-10-15 19:55:41,775 [DEBUG] matplotlib: platform is win32
2025-10-15 19:55:41,961 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 19:55:41,970 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 19:55:43,699 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:55:44,862 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 19:55:45,671 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:55:46,803 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:55:48,681 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:48,687 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA6549190>
2025-10-15 19:55:48,687 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:48,694 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:48,694 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:48,700 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:48,702 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:48,718 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:55:48 GMT')])
2025-10-15 19:55:48,721 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:55:48,721 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:48,727 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:48,729 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:48,730 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:48,745 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:48,748 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:49,114 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1d0c1a19-36f1-4c14-948a-832afa5f1fb3', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **VCB** — Giá hiện tại: 62,500.0 VNĐ  \n• Mở cửa: 63,100.0 | Cao nhất: 67,500.0 | Thấp nhất: 58,700.0  \n• Thay đổi: -600.00 (-0.95%)  \n• Khối lượng: 5,218,800  \n🕒 Cập nhật: 15-10-2025 19:55:46\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Phân tích cổ phiếu VCB hôm nay?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:55:49,119 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:55:49,124 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:55:49,277 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA6859310>
2025-10-15 19:55:49,279 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EA8F38A720> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:55:49,337 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA7A5A790>
2025-10-15 19:55:49,337 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:52,745 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2576'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:55:49 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:55:52,747 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:52,750 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:52,755 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:52,755 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:52,757 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:52,757 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2576', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:55:49 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:55:52,761 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:55:52,790 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 19:55:52,790 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 19:55:52,793 [DEBUG] RAGPipeline: intent: market
2025-10-15 19:55:52,794 [DEBUG] RAGPipeline: timestamp: 2025-10-15T19:55:52.794082
2025-10-15 19:57:33,807 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 19:57:37,058 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 19:57:38,287 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 19:57:46,824 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 19:57:46,836 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 19:57:48,784 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:48,808 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA716FF50>
2025-10-15 19:57:48,811 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,814 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:48,816 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,816 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:48,819 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,820 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:57:48 GMT')])
2025-10-15 19:57:48,823 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 19:57:48,825 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,827 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:48,828 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:48,830 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:48,831 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:48,833 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:48,836 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:48,842 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA71776D0>
2025-10-15 19:57:48,844 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,846 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:48,849 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,852 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:48,854 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,857 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:57:48 GMT')])
2025-10-15 19:57:48,857 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 19:57:48,861 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,864 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:48,867 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:48,868 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:48,868 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:48,871 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:53,684 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:53,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:57:54,124 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:57:55,011 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:55,092 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 19:57:56,733 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:56,737 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA8D42E10>
2025-10-15 19:57:56,739 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:57:56,743 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:56,745 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:57:56,748 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:56,750 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:57:56,757 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:57:56 GMT')])
2025-10-15 19:57:56,759 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 19:57:56,761 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:57:56,768 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:56,770 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:56,773 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:56,775 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:56,775 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:57,165 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:57,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:57,649 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 19:57:58,086 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:58,494 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:58,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:57:58,893 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 19:57:59,211 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:57:59,623 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:57:59,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:58:00,008 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 19:58:00,544 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 19:58:00,954 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 19:58:03,099 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:58:04,032 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:58:04,039 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:58:04,948 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:58:04,997 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:58:06,078 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 19:58:06,280 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:58:07,288 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 19:58:07,447 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 19:58:07,461 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 19:58:07,536 [DEBUG] matplotlib: interactive is False
2025-10-15 19:58:07,540 [DEBUG] matplotlib: platform is win32
2025-10-15 19:58:07,676 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 19:58:07,685 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 19:58:08,888 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:10,171 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 19:58:10,862 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:11,998 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:12,039 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:13,273 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:13,300 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:14,389 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:16,400 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:17,445 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:19,454 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:20,613 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:20,629 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 19:58:23,995 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 19:58:25,190 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 19:58:29,217 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 19:58:31,203 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:58:31,206 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEBFFE15D0>
2025-10-15 19:58:31,210 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,215 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:58:31,217 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,220 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:58:31,223 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,229 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:58:31 GMT')])
2025-10-15 19:58:31,231 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:58:31,233 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,234 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:58:31,237 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:58:31,239 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:58:31,241 [DEBUG] httpcore.connection: close.started
2025-10-15 19:58:31,241 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:58:31,503 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-44cf9865-4a49-4d41-b314-699ba0341ca4', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 15-10-2025 19:58:30\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n## Retrieved Context:\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm nay có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:58:31,508 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:58:31,510 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:58:31,618 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEC3649A90>
2025-10-15 19:58:31,620 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CEA77D67B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:58:31,697 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEBFD9CC10>
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,706 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:58:31,708 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:58:34,981 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2710'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:58:31 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:58:34,983 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:58:34,986 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:58:34,988 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:58:34,992 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:58:34,994 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:58:34,997 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2710', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:58:31 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:58:34,998 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:58:35,033 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 19:58:35,037 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 19:58:35,039 [DEBUG] RAGPipeline: intent: market
2025-10-15 19:58:35,042 [DEBUG] RAGPipeline: timestamp: 2025-10-15T19:58:35.042144
2025-10-15 20:10:44,282 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 20:10:47,695 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 20:10:49,070 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 20:10:50,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 20:10:50,412 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 20:10:52,731 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:10:52,737 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E0861FE10>
2025-10-15 20:10:52,739 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,744 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:10:52,745 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,746 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:10:52,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,750 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 13:10:52 GMT')])
2025-10-15 20:10:52,752 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 20:10:52,752 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,752 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:10:52,756 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:10:52,758 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:10:52,759 [DEBUG] httpcore.connection: close.started
2025-10-15 20:10:52,761 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:10:52,763 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:10:52,769 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E08627710>
2025-10-15 20:10:52,771 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,775 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:10:52,777 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,780 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:10:52,786 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,790 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 13:10:52 GMT')])
2025-10-15 20:10:52,794 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 20:10:52,798 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,803 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:10:52,805 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:10:52,808 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:10:52,810 [DEBUG] httpcore.connection: close.started
2025-10-15 20:10:52,812 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:10:58,807 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:10:59,319 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 20:11:00,115 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 20:11:00,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:00,850 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 20:11:02,563 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:11:02,568 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E0A208250>
2025-10-15 20:11:02,568 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:02,570 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:02,570 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:02,578 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:02,581 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:02,598 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 13:11:02 GMT')])
2025-10-15 20:11:02,601 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 20:11:02,603 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:02,609 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:02,611 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:02,613 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:02,615 [DEBUG] httpcore.connection: close.started
2025-10-15 20:11:02,617 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:11:03,099 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:03,515 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:04,125 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 20:11:10,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:11:10,471 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:11:18,057 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 20:11:19,487 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 20:11:19,999 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 20:11:20,515 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 20:11:21,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 20:11:21,638 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 20:11:23,584 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 20:11:23,995 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 20:11:26,123 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 20:11:27,069 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 20:11:27,076 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 20:11:27,980 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 20:11:28,032 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 20:11:29,104 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 20:11:29,290 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 20:11:30,354 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 20:11:30,541 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 20:11:30,557 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 20:11:30,640 [DEBUG] matplotlib: interactive is False
2025-10-15 20:11:30,644 [DEBUG] matplotlib: platform is win32
2025-10-15 20:11:30,774 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 20:11:30,784 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 20:11:32,020 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:33,223 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 20:11:33,986 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:35,108 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:35,140 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:36,154 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:36,179 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:37,330 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:39,340 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:40,418 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:42,429 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:43,522 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:43,531 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 20:11:46,898 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 20:11:48,191 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 20:11:51,425 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 20:11:53,386 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:11:53,396 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E1F5D8C90>
2025-10-15 20:11:53,396 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,401 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,427 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 13:11:53 GMT')])
2025-10-15 20:11:53,427 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 20:11:53,431 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,435 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:53,438 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:53,441 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:53,441 [DEBUG] httpcore.connection: close.started
2025-10-15 20:11:53,445 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:11:53,718 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-002f83d7-c65c-4a8e-8888-6aa22e7fe133', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 15-10-2025 20:11:52\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Tư, Ngày 15 tháng 10 năm 2025.\nNgày hôm qua là Ngày 14 tháng 10 năm 2025.\nNgày mai là Ngày 16 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 22 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 08 tháng 10 năm 2025.]\n\n(Không tìm thấy nội dung tin tức phù hợp.)\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm nay có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 20:11:53,721 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 20:11:53,723 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 20:11:53,853 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E21266590>
2025-10-15 20:11:53,853 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028E08C827B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 20:11:53,933 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E24B9D790>
2025-10-15 20:11:53,935 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,941 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:53,944 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,947 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:53,949 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:57,273 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2827'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 13:11:53 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 20:11:57,273 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 20:11:57,278 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:57,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:57,280 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:57,284 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:57,285 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2827', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 13:11:53 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 20:11:57,287 [DEBUG] openai._base_client: request_id: None
2025-10-15 20:11:57,309 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 20:11:57,313 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 20:11:57,315 [DEBUG] RAGPipeline: intent: market
2025-10-15 20:11:57,315 [DEBUG] RAGPipeline: timestamp: 2025-10-15T20:11:57.315857
2025-10-16 08:15:48,041 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:15:50,972 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:15:52,369 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:15:53,678 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:15:53,689 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:15:55,799 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:15:55,805 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D108C1E350>
2025-10-16 08:15:55,806 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,809 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:15:55,810 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,810 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:15:55,814 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,814 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:15:55 GMT')])
2025-10-16 08:15:55,817 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:15:55,820 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,822 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:15:55,823 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:15:55,824 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:15:55,828 [DEBUG] httpcore.connection: close.started
2025-10-16 08:15:55,828 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:15:55,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:15:55,838 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D108C2BCD0>
2025-10-16 08:15:55,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,843 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:15:55,846 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,848 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:15:55,848 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,850 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:15:55 GMT')])
2025-10-16 08:15:55,853 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:15:55,856 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,858 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:15:55,860 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:15:55,860 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:15:55,863 [DEBUG] httpcore.connection: close.started
2025-10-16 08:15:55,864 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:00,336 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:00,368 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:16:00,743 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:16:01,154 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:01,189 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:16:01,641 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:16:01,650 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D10AACDC50>
2025-10-16 08:16:01,650 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:01,657 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:01,660 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:01,660 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:01,666 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:01,666 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:16:01 GMT')])
2025-10-16 08:16:01,672 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:16:01,675 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:01,679 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:01,682 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:01,684 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:01,685 [DEBUG] httpcore.connection: close.started
2025-10-16 08:16:01,686 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:02,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:02,388 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:02,418 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:16:02,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:03,307 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:03,335 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:16:03,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:16:04,333 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:16:04,685 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:16:05,082 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:16:05,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:16:05,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:16:06,375 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:16:08,659 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:16:09,494 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:16:09,504 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:16:10,308 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:16:10,464 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:16:11,356 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:16:11,537 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:16:12,311 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:16:12,861 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:16:12,890 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:16:12,968 [DEBUG] matplotlib: interactive is False
2025-10-16 08:16:12,972 [DEBUG] matplotlib: platform is win32
2025-10-16 08:16:13,217 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:16:13,239 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:16:18,728 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:19,909 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:16:21,210 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:22,052 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:22,111 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:22,945 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:22,974 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:23,865 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:25,875 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:26,837 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:28,847 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:29,761 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:29,774 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:16:32,897 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:16:34,268 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:16:37,531 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:16:39,558 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:16:39,563 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D127172E10>
2025-10-16 08:16:39,565 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:39,569 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:39,572 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:39,576 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:39,578 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:39,609 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:16:39 GMT')])
2025-10-16 08:16:39,612 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:16:39,615 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:39,619 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:39,621 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:39,621 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:39,625 [DEBUG] httpcore.connection: close.started
2025-10-16 08:16:39,626 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:40,093 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-14eda29d-bcee-4b1b-9b08-b1efba36ce5f', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:16:38\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán Vietcap bổ nhiệm Phó Chủ tịch HĐQT thường trực | 16-10-2025 06:02:00] (score=0.7381, rerank=5.3302)\nCông ty cổ phần Chứng khoán Vietcap (MCK: VCI, sàn HoSE) vừa công bố nghị quyết về việc bổ nhiệm Phó Chủ tịch HĐQT thường trực trong thời gian còn lại của nhiệm kỳ 2021-2026 đối với ông Đinh Quang Hoàn. Ông Đinh Quang Hoàn. Ảnh: VCI Theo giới thiệu, ông Đinh Quang Hoàn sinh năm 1976, có bằng Thạc sĩ Kinh tế chuyên ngành Tài chính và bằng Cử nhân chuyên ngành Kế toán - Kiểm toán của trường Đại học Kinh tế TP.HCM. Đồng thời, ông có chứng chỉ kiểm toán viên độc lập của Bộ Tài chính và là thành viên lâu năm của Hiệp hội Kế toán viên công chứng - Vương quốc Anh (ACCA). Ông có hơn 25 năm kinh nghiệm trong lĩnh vực tư vấn tài chính, kế toán và kiểm toán khi từng làm việc tại Công ty kiểm toán quốc tế KPMG với chức vụ Trưởng phòng Kiểm toán, phụ trách các dự án kiểm toán, soát xét tài chính cho các tập đoàn đa quốc gia cũng như cá...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm nay có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:16:40,100 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:16:40,104 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:16:40,214 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D11562CC90>
2025-10-16 08:16:40,214 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D17D766180> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:16:40,286 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D12715AD10>
2025-10-16 08:16:40,291 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:40,293 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:40,293 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:40,298 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:40,299 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:46,731 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4910'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:16:40 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:16:46,732 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:16:46,733 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:46,735 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:46,736 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:46,736 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:46,736 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4910', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:16:40 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:16:46,738 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:16:46,752 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:16:46.752113
2025-10-16 08:24:47,131 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:24:48,061 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:24:48,623 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:24:49,274 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:24:49,279 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:24:50,266 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:50,268 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E243FF90>
2025-10-16 08:24:50,268 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,268 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:50,272 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,273 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:50,273 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,276 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:24:49 GMT')])
2025-10-16 08:24:50,278 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:24:50,279 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:50,281 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:50,281 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:50,283 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:50,284 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:50,285 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:50,286 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E244AE90>
2025-10-16 08:24:50,286 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:24:49 GMT')])
2025-10-16 08:24:50,296 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:24:50,296 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,298 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:50,299 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:50,300 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:50,301 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:50,303 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:52,401 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:52,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:24:52,715 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:24:53,019 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,046 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:24:53,255 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:53,257 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E42CFB10>
2025-10-16 08:24:53,259 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:24:53,261 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:53,262 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:24:53,263 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:53,264 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:24:53,267 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:24:52 GMT')])
2025-10-16 08:24:53,268 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:24:53,269 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:24:53,270 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:53,272 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:53,272 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:53,273 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:53,274 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:53,551 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,820 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,846 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:24:54,156 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:54,413 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:54,449 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:24:54,720 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:24:54,993 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:24:55,344 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:24:55,616 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:24:55,950 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:24:56,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:24:56,555 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:24:57,449 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:24:57,848 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:24:57,852 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:24:58,229 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:24:58,251 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:24:58,694 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:24:58,770 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:24:59,232 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:24:59,333 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:24:59,344 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:24:59,378 [DEBUG] matplotlib: interactive is False
2025-10-16 08:24:59,379 [DEBUG] matplotlib: platform is win32
2025-10-16 08:24:59,435 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:24:59,438 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:24:59,994 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:00,618 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:25:00,924 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:01,508 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:01,522 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:02,250 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:02,261 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:02,845 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:04,848 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:05,388 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:07,391 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:07,919 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:07,923 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:25:10,584 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:25:11,623 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:25:14,272 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:25:14,977 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:25:14,977 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF063E10>
2025-10-16 08:25:14,987 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:25:14,987 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:25:14,990 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:25:14,992 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:25:14,992 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:25:14,994 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:25:14 GMT')])
2025-10-16 08:25:14,996 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:25:14,996 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:25:14,997 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:25:14,999 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:25:14,999 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:25:15,000 [DEBUG] httpcore.connection: close.started
2025-10-16 08:25:15,000 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:25:15,379 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-d18afc2c-9f40-47c9-8f8d-fa281fd7ced0', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:25:14\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-10 giảm, cho thấy trạng thái thăm dò giữa cung và cầu. VDSC đánh giá đây là diễn biến bình thường, vì thị trường cần thời gian để thu hút thêm dòng tiền. VDSC dự báo trong các phiên tới, VN- Index s...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:25:15,379 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:25:15,384 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:25:15,487 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF25EC50>
2025-10-16 08:25:15,492 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000236E2AAA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:25:15,554 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF25F850>
2025-10-16 08:25:15,554 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:25:15,554 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:25:15,556 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:25:15,558 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:25:15,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:25:21,976 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'3964'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:25:15 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:25:21,978 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:25:21,979 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:25:21,980 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:25:21,980 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:25:21,981 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:25:21,982 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '3964', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:25:15 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:25:21,982 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:25:21,992 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:25:21.993170
2025-10-16 08:32:13,765 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:32:14,861 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:32:15,665 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:32:16,475 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:32:16,480 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:32:17,621 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:17,635 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33A74EC90>
2025-10-16 08:32:17,636 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,638 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:17,639 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,640 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:17,641 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,643 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:32:17 GMT')])
2025-10-16 08:32:17,645 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:32:17,645 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,646 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:17,648 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:17,649 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:17,650 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:17,650 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:17,651 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:17,656 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33A758DD0>
2025-10-16 08:32:17,659 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,662 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:17,664 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,666 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:17,666 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,670 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:32:17 GMT')])
2025-10-16 08:32:17,672 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:32:17,675 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,676 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:17,676 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:17,677 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:17,678 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:17,680 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:20,853 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:20,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:32:21,195 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:32:21,542 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:21,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:32:21,891 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:21,911 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33C5FCC10>
2025-10-16 08:32:21,913 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:32:21,916 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:21,917 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:32:21,920 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:21,921 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:32:21,927 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:32:21 GMT')])
2025-10-16 08:32:21,929 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:32:21,931 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:32:21,934 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:21,935 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:21,937 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:21,938 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:21,940 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:22,254 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:22,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:22,569 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:32:22,934 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:23,218 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:23,246 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:32:23,555 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:32:23,838 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:32:24,167 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:32:24,485 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:32:24,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:32:24,907 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:32:25,188 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:32:26,481 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:32:26,970 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:32:26,973 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:32:27,506 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:32:27,532 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:32:28,127 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:32:28,247 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:32:28,832 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:32:28,935 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:32:28,945 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:32:28,986 [DEBUG] matplotlib: interactive is False
2025-10-16 08:32:28,987 [DEBUG] matplotlib: platform is win32
2025-10-16 08:32:29,072 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:32:29,077 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:32:29,711 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:30,474 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:32:30,912 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:31,547 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:31,562 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:32,168 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:32,182 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:32,904 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:34,909 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:35,465 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:37,470 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:38,083 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:38,092 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:32:41,710 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:32:42,719 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:32:46,250 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:32:47,019 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:47,022 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B346A91B50>
2025-10-16 08:32:47,023 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:32:47,025 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:47,026 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:32:47,027 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:47,029 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:32:47,033 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:32:46 GMT')])
2025-10-16 08:32:47,035 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:32:47,036 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:32:47,038 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:47,040 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:47,041 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:47,043 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:47,043 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:33:55,089 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:33:55,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B39129C350>
2025-10-16 08:33:55,093 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:33:55,095 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:33:55,096 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:33:55,097 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:33:55,098 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:33:55,101 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:33:54 GMT')])
2025-10-16 08:33:55,102 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:33:55,102 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:33:55,104 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:33:55,105 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:33:55,105 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:33:55,106 [DEBUG] httpcore.connection: close.started
2025-10-16 08:33:55,107 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:20,360 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:34:21,330 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:34:21,928 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:34:22,613 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:34:22,617 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:34:23,431 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:23,434 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952D1689D0>
2025-10-16 08:34:23,434 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,436 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:23,438 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,438 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:23,440 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,441 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:23 GMT')])
2025-10-16 08:34:23,442 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:34:23,443 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,444 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:23,445 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:23,445 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:23,447 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:23,448 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:23,449 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:23,461 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952D169050>
2025-10-16 08:34:23,462 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,468 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:23 GMT')])
2025-10-16 08:34:23,468 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:34:23,470 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:23,471 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:23,473 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:25,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:25,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:34:26,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:34:26,538 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:26,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:34:26,765 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:26,765 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952ED31F50>
2025-10-16 08:34:26,765 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:26,772 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:26,774 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:26,775 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:26,776 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:26,778 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:34:26 GMT')])
2025-10-16 08:34:26,779 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:34:26,781 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:26,784 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:26,785 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:26,786 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:26,787 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:26,788 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:27,101 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:27,394 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:27,427 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:34:27,747 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:28,037 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:28,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:34:28,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:34:28,642 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:34:28,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:34:29,257 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:34:29,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:34:29,649 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:34:29,968 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:34:30,893 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:34:31,266 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:34:31,274 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:34:31,670 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:34:31,688 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:34:32,153 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:34:32,247 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:34:32,730 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:34:32,799 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:34:32,805 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:34:32,841 [DEBUG] matplotlib: interactive is False
2025-10-16 08:34:32,841 [DEBUG] matplotlib: platform is win32
2025-10-16 08:34:32,906 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:34:32,910 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:34:33,411 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:34,023 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:34:34,359 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:34,758 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:34,774 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:35,227 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:35,239 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:35,652 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:37,656 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:38,068 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:40,078 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:40,624 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:40,630 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:34:44,087 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:34:45,201 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:34:48,747 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:34:49,432 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:49,433 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000295494FD850>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:49,440 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,442 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:49 GMT')])
2025-10-16 08:34:49,443 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:34:49,444 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,445 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:49,446 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:49,446 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:49,447 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:49,448 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:49,751 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-339a9dc7-2b84-466d-b2a7-703f61aae1d9', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:34:49\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-10 giảm, cho thấy trạng thái thăm dò giữa cung và cầu. VDSC đánh giá đây là diễn biến bình thường, vì thị trường cần thời gian để thu hút thêm dòng tiền. VDSC dự báo trong các phiên tới, VN- Index s...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:34:49,753 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:34:49,753 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:34:49,873 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029549501FD0>
2025-10-16 08:34:49,876 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002952D7CA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:34:49,944 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029544B2FE90>
2025-10-16 08:34:49,944 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,947 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:49,947 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,948 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:49,949 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:56,440 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4508'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:34:49 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:34:56,441 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:34:56,441 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:56,441 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:56,443 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:56,443 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:56,444 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4508', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:34:49 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:34:56,444 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:34:56,454 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:34:56.454468
2025-10-16 08:39:11,816 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:39:12,731 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:39:13,295 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:39:13,950 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:39:13,953 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:39:14,732 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:14,752 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A51EA8790>
2025-10-16 08:39:14,753 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,759 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:39:14 GMT')])
2025-10-16 08:39:14,759 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:39:14,760 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,762 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:14,763 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:14,763 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:14,765 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:14,765 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:14,767 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:14,769 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A51B18A50>
2025-10-16 08:39:14,769 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,772 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:14,773 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,774 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:14,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,775 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:39:14 GMT')])
2025-10-16 08:39:14,776 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:39:14,776 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,780 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:14,781 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:14,781 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:14,781 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:14,784 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:17,047 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:17,075 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:39:17,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:39:17,662 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:17,689 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:39:17,890 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:17,892 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A53A6BB50>
2025-10-16 08:39:17,893 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:17,896 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:17,896 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:17,897 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:17,899 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:17,909 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:39:17 GMT')])
2025-10-16 08:39:17,909 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:39:17,912 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:17,914 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:17,915 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:17,916 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:17,916 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:17,918 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:18,203 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:18,467 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:18,777 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:39:19,082 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:19,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:19,376 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:39:19,644 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:39:19,932 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:39:20,228 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:39:20,499 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:39:20,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:39:20,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:39:21,230 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:39:22,133 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:39:22,554 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:39:22,557 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:39:22,949 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:39:22,969 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:39:23,481 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:39:23,580 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:39:24,051 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:39:24,125 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:39:24,131 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:39:24,170 [DEBUG] matplotlib: interactive is False
2025-10-16 08:39:24,172 [DEBUG] matplotlib: platform is win32
2025-10-16 08:39:24,231 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:39:24,234 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:39:24,771 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:25,481 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:39:25,781 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:26,336 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:26,356 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:26,893 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:26,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:27,496 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:29,500 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:29,970 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:31,974 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:32,427 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:32,435 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:39:35,945 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:39:36,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:39:40,253 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:39:41,031 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:41,033 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A7016EE90>
2025-10-16 08:39:41,033 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,036 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:41,037 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,038 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:41,039 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,042 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:39:40 GMT')])
2025-10-16 08:39:41,043 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:39:41,044 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,045 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:41,046 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:41,047 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:41,047 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:41,047 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:41,393 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-e6cc0fd5-4a80-4d45-b7ce-cfd234d0e432', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:39:40\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-10 giảm, cho thấy trạng thái thăm dò giữa cung và cầu. VDSC đánh giá đây là diễn biến bình thường, vì thị trường cần thời gian để thu hút thêm dòng tiề...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 thá...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:39:41,394 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:39:41,395 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:39:41,517 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A7016D050>
2025-10-16 08:39:41,517 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028A5250A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:39:41,587 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A5E9E7C50>
2025-10-16 08:39:41,588 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,590 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:41,590 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,592 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:41,592 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:48,030 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4335'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:39:41 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:39:48,031 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:39:48,032 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:48,033 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:48,033 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:48,034 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:48,034 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4335', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:39:41 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:39:48,035 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:39:48,043 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:39:48,044 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:39:48,045 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:39:48,045 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:39:48.045392
2025-10-16 08:46:25,664 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:46:26,557 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:46:27,092 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:46:27,728 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:46:27,733 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:46:28,486 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:28,488 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8147E3790>
2025-10-16 08:46:28,489 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,491 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:28,491 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,492 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:28,493 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,494 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:46:28 GMT')])
2025-10-16 08:46:28,495 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:46:28,497 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:28,498 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:28,499 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:28,500 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:28,500 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:28,501 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:28,503 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8148E9B50>
2025-10-16 08:46:28,503 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,507 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:28,508 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,510 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:28,510 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,512 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:46:28 GMT')])
2025-10-16 08:46:28,512 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:46:28,513 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:28,516 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:28,517 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:30,659 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:30,688 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:46:30,988 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:46:31,317 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:31,342 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:46:31,537 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:31,550 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8164F5E90>
2025-10-16 08:46:31,551 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:31,552 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:31,554 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:31,557 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:31,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:46:31,560 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:46:31 GMT')])
2025-10-16 08:46:31,562 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:46:31,564 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:46:31,565 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:31,567 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:31,568 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:31,568 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:31,569 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:31,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,164 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,191 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:46:32,517 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,813 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,840 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:46:33,142 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:46:33,439 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:46:33,760 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:46:34,047 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:46:34,073 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:46:34,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:46:34,741 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:46:35,640 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:46:36,035 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:46:36,041 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:46:36,390 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:46:36,408 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:46:36,862 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:46:36,950 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:46:37,393 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:46:37,467 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:46:37,469 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:46:37,512 [DEBUG] matplotlib: interactive is False
2025-10-16 08:46:37,512 [DEBUG] matplotlib: platform is win32
2025-10-16 08:46:37,590 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:46:37,597 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:46:38,111 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:38,750 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:46:39,059 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:39,557 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:39,574 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:40,140 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:40,154 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:40,703 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:42,707 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:43,268 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:45,273 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:45,777 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:45,782 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:46:49,293 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:46:50,150 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:46:53,924 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:46:54,649 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:54,651 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82BF69850>
2025-10-16 08:46:54,651 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:54,653 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:54,654 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:54,655 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:54,656 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:46:54,660 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:46:54 GMT')])
2025-10-16 08:46:54,660 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:46:54,661 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:46:54,662 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:54,663 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:54,663 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:54,663 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:54,665 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:55,006 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-fed4eac3-267f-497c-9646-b3316354d85d', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:46:54\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-10 giảm, cho thấy trạng thái thăm dò giữa cung và cầu. VDSC đánh giá đây là diễn biến bình thường, vì thị trường cần thời gian để thu hút thêm dòng tiền. VDSC dự báo trong các phiên tới, VN- Index s...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:46:55,008 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:46:55,008 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:46:55,135 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82BE53850>
2025-10-16 08:46:55,136 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F814F4A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:46:55,210 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82C5C5010>
2025-10-16 08:46:55,212 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:55,213 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:55,213 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:55,214 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:55,215 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:47:01,638 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4610'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:46:54 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:47:01,640 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:47:01,640 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:47:01,641 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:47:01,642 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:47:01,643 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:47:01,643 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4610', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:46:54 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:47:01,645 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:47:01,662 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:47:01,662 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:47:01,664 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:47:01,664 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:47:01.664317
2025-10-16 08:49:42,380 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:49:43,327 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:49:43,996 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:49:44,743 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:49:44,747 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:49:45,524 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:45,529 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018670D48A10>
2025-10-16 08:49:45,530 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:45,534 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,535 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:49:45 GMT')])
2025-10-16 08:49:45,536 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:49:45,537 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,537 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:45,538 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:45,538 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:45,539 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:45,539 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:45,541 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:45,544 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018670D4BE10>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:45,548 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,550 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:49:45 GMT')])
2025-10-16 08:49:45,552 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:49:45,552 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,552 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:45,555 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:45,555 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:45,556 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:45,557 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:47,731 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:47,758 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:49:48,067 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:49:48,409 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:48,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:49:48,635 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:48,635 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000186729132D0>
2025-10-16 08:49:48,635 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:49:48,640 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:49:48,646 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:49:48 GMT')])
2025-10-16 08:49:48,646 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:49:48,646 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:49:48,650 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:48,650 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:48,652 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:48,653 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:48,653 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:48,949 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,234 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,266 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:49:49,639 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,964 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:49:50,264 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:49:50,576 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:49:50,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:49:51,190 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:49:51,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:49:51,620 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:49:51,916 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:49:52,822 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:49:53,228 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:49:53,231 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:49:53,648 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:49:53,669 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:49:54,131 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:49:54,222 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:49:54,663 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:49:54,734 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:49:54,741 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:49:54,772 [DEBUG] matplotlib: interactive is False
2025-10-16 08:49:54,773 [DEBUG] matplotlib: platform is win32
2025-10-16 08:49:54,825 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:49:54,829 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:49:55,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:55,795 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:49:56,114 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:56,536 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:56,550 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:56,936 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:56,947 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:57,409 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:59,412 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:59,812 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:50:01,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:50:02,288 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:50:02,298 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:50:05,767 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:50:06,686 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:50:10,227 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:50:11,137 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:50:11,139 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860DCFAE90>
2025-10-16 08:50:11,140 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,142 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:50:11,142 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,144 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:50:11,144 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,147 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:50:10 GMT')])
2025-10-16 08:50:11,148 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:50:11,150 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,151 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:50:11,152 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:50:11,153 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:50:11,154 [DEBUG] httpcore.connection: close.started
2025-10-16 08:50:11,155 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:50:11,570 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1a625da5-02fd-4fc0-afdd-d831339b3e32', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:50:11\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-1...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 tháng, hoàn thành 100,7% kế hoạch năm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nvà đối tác chiến lược. SHS đạt lợi nhuận trước thuế hơn 1...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:50:11,570 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:50:11,570 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:50:11,708 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860E2B0E90>
2025-10-16 08:50:11,709 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000186713AA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:50:11,768 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860E2B2310>
2025-10-16 08:50:11,770 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,771 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:50:11,772 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,774 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:50:11,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:50:18,136 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4265'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:50:12 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:50:18,137 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:50:18,138 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:50:18,140 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:50:18,141 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:50:18,141 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:50:18,142 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4265', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:50:12 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:50:18,143 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:50:18,156 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:50:18,157 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:50:18,157 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:50:18,158 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:50:18.158917
2025-10-16 08:52:38,845 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:52:39,823 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:52:40,379 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:52:41,025 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:52:41,029 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:52:41,805 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:41,808 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983A7DD2D0>
2025-10-16 08:52:41,808 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,808 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:41,811 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,812 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:41,812 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:52:41 GMT')])
2025-10-16 08:52:41,815 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:41,819 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:41,820 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:41,825 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983A7DF110>
2025-10-16 08:52:41,826 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,828 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:41,829 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,830 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:41,832 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,832 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:52:41 GMT')])
2025-10-16 08:52:41,833 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:52:41,833 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,836 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:41,837 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:41,837 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:41,837 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:41,837 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:43,875 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:43,906 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:52:44,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:52:44,534 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:44,558 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:52:44,757 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:44,759 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983C3A2B50>
2025-10-16 08:52:44,759 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:52:44,761 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:44,762 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:52:44,763 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:44,764 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:52:44,766 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:52:44 GMT')])
2025-10-16 08:52:44,766 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:52:44,766 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:52:44,771 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:44,771 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:44,772 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:44,772 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:44,775 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:45,090 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:45,389 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:45,417 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:52:45,738 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:46,028 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:46,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:52:46,353 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:52:46,648 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:52:46,971 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:52:47,256 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:52:47,283 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:52:47,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:52:47,946 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:52:48,854 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:52:49,247 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:52:49,251 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:52:49,615 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:52:49,640 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:52:50,132 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:52:50,224 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:52:50,693 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:52:50,774 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:52:50,785 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:52:50,842 [DEBUG] matplotlib: interactive is False
2025-10-16 08:52:50,843 [DEBUG] matplotlib: platform is win32
2025-10-16 08:52:50,921 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:52:50,924 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:52:51,420 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:51,860 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:52:52,174 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:52,603 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:52,615 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:53,054 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:53,064 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:53,513 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:55,516 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:55,896 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:57,901 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:58,292 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:58,299 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:53:01,736 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:53:03,425 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:53:06,834 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:53:07,576 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:53:07,589 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019846B29B50>
2025-10-16 08:53:07,590 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:53:07,592 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:53:07,592 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:53:07,594 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:53:07,595 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:53:07,597 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:53:07 GMT')])
2025-10-16 08:53:07,598 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:53:07,600 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:53:07,601 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:53:07,602 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:53:07,603 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:53:07,604 [DEBUG] httpcore.connection: close.started
2025-10-16 08:53:07,604 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:53:07,962 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-20e7fbe1-d6f1-47a4-a05b-99f22268dbc3', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:53:07\n\n        ### Ví dụ minh họa cách kết hợp dữ liệu giá & tin tức:\n        **Dữ liệu giá:**\n        📊 VCB — Giá hiện tại: 62,500 VNĐ (-0.95%)\n\n        **Tin tức:**\n        VN-Index xuất hiện tín hiệu tạo đỉnh ngắn hạn, nhóm chứng khoán báo lỗ quý 3/2025.\n\n        **Trả lời mẫu:**\n        Hôm nay cổ phiếu VCB giảm 0.95%, diễn biến cùng xu hướng điều chỉnh chung của thị trường\n        khi VN-Index có tín hiệu tạo đỉnh ngắn hạn. Một số thông tin tiêu cực từ nhóm chứng khoán\n        gây áp lực chốt lời, khiến dòng tiền trở nên thận trọng. Xu hướng ngắn hạn: giảm nhẹ.\n        \n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-1...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 tháng, hoàn thành 100,7% kế hoạch năm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nvà đối tác chiến lược. SHS đạt lợi nhuận trước thuế hơn 1...\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:53:07,964 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:53:07,964 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:53:08,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019846B29B50>
2025-10-16 08:53:08,091 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001983AE3E7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:53:08,154 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019858D4F5D0>
2025-10-16 08:53:08,154 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:53:08,154 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:53:08,159 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:53:08,159 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:53:08,160 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:53:14,520 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4079'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:53:08 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:53:14,522 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:53:14,523 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:53:14,524 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:53:14,525 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:53:14,525 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:53:14,526 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4079', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:53:08 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:53:14,526 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:53:14,534 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:53:14.535985
2025-10-16 08:56:27,871 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:56:28,801 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:56:29,334 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:56:29,982 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:56:29,986 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:56:30,854 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:30,857 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E622D5D0>
2025-10-16 08:56:30,858 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,860 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:30,861 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,862 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:30,863 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,864 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:56:30 GMT')])
2025-10-16 08:56:30,865 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:56:30,866 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,868 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:30,868 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:30,869 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:30,869 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:30,870 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:30,871 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:30,873 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E622D550>
2025-10-16 08:56:30,874 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,877 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:30,877 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,878 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:30,880 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,880 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:30 GMT')])
2025-10-16 08:56:30,881 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:56:30,883 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,883 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:30,884 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:30,885 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:30,886 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:30,886 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:33,103 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:33,133 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:56:33,416 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:56:33,727 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:33,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:56:33,968 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:33,968 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E7E85150>
2025-10-16 08:56:33,968 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:33,976 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:33,977 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:33,977 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:33,980 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:56:33,984 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:33 GMT')])
2025-10-16 08:56:33,987 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:56:33,987 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:56:33,989 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:33,991 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:33,991 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:33,992 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:33,992 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:34,279 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:34,541 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:34,708 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:56:35,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:35,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:35,309 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:56:35,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:56:35,848 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:56:36,148 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:56:36,412 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:56:36,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:56:36,805 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:56:37,079 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:56:37,947 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:56:38,412 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:56:38,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:56:38,843 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:56:38,863 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:56:39,355 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:56:39,447 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:56:39,926 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:56:40,002 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:56:40,009 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:56:40,043 [DEBUG] matplotlib: interactive is False
2025-10-16 08:56:40,044 [DEBUG] matplotlib: platform is win32
2025-10-16 08:56:40,098 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:56:40,101 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:56:40,569 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:41,019 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:56:41,420 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:41,920 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:41,934 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:42,392 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:42,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:42,784 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:44,794 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:45,244 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:47,249 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:47,694 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:47,702 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:56:51,129 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:56:51,973 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:56:55,434 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:56:56,048 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:56,055 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001778CD771D0>
2025-10-16 08:56:56,055 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:56,062 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,066 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:55 GMT')])
2025-10-16 08:56:56,068 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:56:56,068 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,070 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:56,071 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:56,072 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:56,072 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:56,072 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:56,374 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-01f49d29-49c4-48dc-9664-ad5bfd59f679', 'json_data': {'messages': [{'content': 'Bạn là trợ lý AI tài chính thông minh, trả lời bằng tiếng Việt, súc tích và chính xác.', 'role': 'system'}, {'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-1...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 tháng, hoàn thành 100,7% kế hoạch năm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nvà đối tác chiến lược. SHS đạt lợi nhuận trước thuế hơn 1...\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 08:56:55\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:56:56,374 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:56:56,377 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:56:56,499 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177860D9210>
2025-10-16 08:56:56,499 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000177E688E7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:56:56,576 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017786549E50>
2025-10-16 08:56:56,577 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,578 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:56,578 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,580 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:56,580 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:57:00,969 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'3273'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:56:56 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:57:00,970 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:57:00,972 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:57:00,974 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:57:00,975 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:57:00,976 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:57:00,977 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '3273', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:56:56 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:57:00,978 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:57:00,993 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:57:00,994 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:57:00,995 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:57:00,996 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:57:00.995922
2025-10-16 09:04:57,123 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:04:58,039 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:04:58,621 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:04:59,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:04:59,355 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:05:00,252 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:00,255 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E2FD95D0>
2025-10-16 09:05:00,256 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,257 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:00,259 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,259 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:00,260 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,260 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:04:59 GMT')])
2025-10-16 09:05:00,262 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:05:00,263 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,263 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:00,265 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:00,265 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:00,266 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:00,267 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:00,268 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:00,269 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E4FCE810>
2025-10-16 09:05:00,271 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,272 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:00,273 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,274 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:00,275 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,275 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:04:59 GMT')])
2025-10-16 09:05:00,276 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:05:00,278 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:00,280 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:00,281 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:00,281 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:00,281 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:02,461 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:02,489 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:05:02,790 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:05:03,602 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:03,630 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:05:03,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:03,833 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E6BC6090>
2025-10-16 09:05:03,834 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:03,836 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:03,837 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:03,839 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:03,839 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:03,841 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:05:03 GMT')])
2025-10-16 09:05:03,842 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 09:05:03,843 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:03,846 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:03,847 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:03,848 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:03,848 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:03,849 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:04,149 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:04,428 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:04,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:05:04,814 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:05,107 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:05,135 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:05:05,425 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:05:05,789 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:05:06,104 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:05:06,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:05:06,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:05:06,800 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:05:07,101 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 09:05:07,988 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:05:08,413 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:05:08,417 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:05:08,847 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:05:08,869 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:05:09,338 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 09:05:09,427 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:05:09,917 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 09:05:09,999 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 09:05:10,006 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 09:05:10,044 [DEBUG] matplotlib: interactive is False
2025-10-16 09:05:10,046 [DEBUG] matplotlib: platform is win32
2025-10-16 09:05:10,104 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 09:05:10,109 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 09:05:10,627 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:11,217 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 09:05:11,644 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:12,140 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:12,151 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:12,644 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:12,653 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:13,157 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:15,160 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:15,776 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:17,781 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:18,300 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:18,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:05:21,579 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:05:22,441 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:05:25,924 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:05:26,882 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:26,885 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E4999B50>
2025-10-16 09:05:26,886 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:26,887 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:26,889 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:26,890 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:26,891 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:26,917 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:05:26 GMT')])
2025-10-16 09:05:26,917 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 09:05:26,917 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:26,919 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:26,921 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:26,921 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:26,922 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:26,922 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:27,330 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1ebe878a-c22c-4dbc-a74c-7dedf4bdf2b7', 'json_data': {'messages': [{'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-1...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 tháng, hoàn thành 100,7% kế hoạch năm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nvà đối tác chiến lược. SHS đạt lợi nhuận trước thuế hơn 1...\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 09:05:26\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.7}}
2025-10-16 09:05:27,332 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 09:05:27,333 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 09:05:27,459 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C987546C50>
2025-10-16 09:05:27,461 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C9E562E720> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 09:05:27,534 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C98CE69510>
2025-10-16 09:05:27,535 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:27,537 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:27,538 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:27,539 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:27,539 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:40,263 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'8165'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 02:05:27 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 09:05:40,263 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 09:05:40,263 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:40,269 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:40,269 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:40,271 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:40,271 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '8165', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 02:05:27 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 09:05:40,273 [DEBUG] openai._base_client: request_id: None
2025-10-16 09:05:40,286 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 09:05:40,287 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 09:05:40,288 [DEBUG] RAGPipeline: intent: market
2025-10-16 09:05:40,288 [DEBUG] RAGPipeline: timestamp: 2025-10-16T09:05:40.288757
2025-10-16 09:13:12,791 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:13:13,733 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:13:14,318 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:13:14,955 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:13:14,962 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:13:15,792 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:15,795 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002906145CFD0>
2025-10-16 09:13:15,795 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:13:15 GMT')])
2025-10-16 09:13:15,801 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:15,802 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:15,805 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:15,805 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:15,809 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002906145FFD0>
2025-10-16 09:13:15,810 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,812 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:15,812 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,813 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:15,814 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,814 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 02:13:15 GMT')])
2025-10-16 09:13:15,815 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:13:15,817 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,818 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:15,819 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:15,819 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:15,820 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:15,820 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:18,302 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:18,329 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:13:18,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:13:18,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:18,991 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:13:19,491 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:19,795 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:19,822 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:13:20,164 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:20,457 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:20,488 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:13:20,783 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:13:21,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:13:21,912 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:13:22,198 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:13:22,224 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:13:22,578 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:13:22,885 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 09:13:23,795 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:13:24,188 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:13:24,188 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:13:24,599 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:13:24,620 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:13:25,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 09:13:25,157 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:13:25,643 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 09:13:25,712 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 09:13:25,720 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 09:13:25,751 [DEBUG] matplotlib: interactive is False
2025-10-16 09:13:25,752 [DEBUG] matplotlib: platform is win32
2025-10-16 09:13:25,805 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 09:13:25,813 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 09:13:26,276 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:26,845 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 09:13:27,242 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:27,693 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:27,709 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:28,163 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:28,174 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:28,817 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:30,820 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:31,274 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:33,279 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:33,738 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:33,745 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:13:37,201 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:13:38,154 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:13:41,396 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:13:42,231 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:42,234 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002900AB66AD0>
2025-10-16 09:13:42,235 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,237 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:42,238 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,239 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:42,240 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,242 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:13:41 GMT')])
2025-10-16 09:13:42,243 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 09:13:42,244 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,246 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:42,247 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:42,248 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:42,249 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:42,251 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:42,602 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-d0c3de4e-6405-4e73-b56f-2e51965f3461', 'json_data': {'messages': [{'content': "- Luôn trả lời bằng TIẾNG VIỆT nếu có từ ngữ chuyên ngành (VNINDEX, VN30,..) thì giữ nguyên.\n\n## Instruction:\nBạn là **trợ lý AI tài chính Việt Nam**, chuyên phân tích xu hướng thị trường, cổ phiếu và tin tức.\n1. Khi intent = 'market' thì KẾT HỢP dữ liệu API (giá cổ phiếu, thị trường) với tin tức (Context).\n2. Khi intent = 'stock' thì Trình bày thông tin giá cổ phiếu ngắn gọn.\n3. KHÔNG khuyến nghị đầu tư tuyệt đối.\n## Constraints:\n- Luôn trả lời bằng TIẾNG VIỆT, ngắn gọn, tự nhiên.\n- KHÔNG dùng mã code, KHÔNG in cấu trúc JSON.\n- KHÔNG nói “Tôi không phải chuyên gia tài chính”.\n- Giữ nguyên các ký hiệu như VNINDEX, VCB, VN30,...\n## Bối cảnh thời gian:\nHôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.\n\n\n## Retrieved Context:\nDưới đây là các tin tức gần nhất, hãy ưu tiên sử dụng chúng để phân tích thị trường:\n\n[Tin tức cập nhập đến: Hôm nay là Thứ Năm, Ngày 16 tháng 10 năm 2025.\nNgày hôm qua là Ngày 15 tháng 10 năm 2025.\nNgày mai là Ngày 17 tháng 10 năm 2025.\nTuần sau sẽ bắt đầu từ Ngày 23 tháng 10 năm 2025.\nTuần trước bắt đầu từ Ngày 09 tháng 10 năm 2025.]\n\n[Chứng khoán ngày 16-10: Cổ phiếu ngân hàng, bất động sản… dẫn dắt dòng tiền? | 15-10-2025 22:47:00] (score=0.75, rerank=5.4403)\nDIG, NVL có mức tăng giá đáng chú ý. Kết thúc phiên giao dịch, VN- Index đóng cửa tại 1.757 điểm, giảm 3 điểm (tương đương 0,18%) Theo nhận định của Công ty Chứng khoán VCBS, VN-Index đang trong giai đoạn củng cố động lực quanh vùng 1.750-1.780 điểm. Sự phân hóa giữa các nhóm cổ phiếu blue-chip cho thấy thị trường đang điều chỉnh sau đợt tăng giá mạnh trước đó. VCBS khuyến nghị nhà đầu tư cân nhắc chốt lời ngắn hạn đối với các mã đã đạt mục tiêu hoặc có tín hiệu đảo chiều, đồng thời duy trì tỉ trọng ở các mã vẫn giữ xu hướng tăng. Trong khi đó, Công ty Chứng khoán Rồng Việt (VDSC) cho biết thanh khoản phiên 15-10 ...\n\n[SHS đạt 1.379 tỷ đồng lợi nhuận sau 9 tháng, hoàn thành 100,7% kế hoạch năm 2025 | 15-10-2025 17:30:00] (score=0.5455, rerank=4.3467)\nLợi nhuận trước thuế Quý 3 gấp 8 lần cùng kỳ, hoàn thành ...\n## Dữ liệu API:\n📊 **TỔNG QUAN THỊ TRƯỜNG VIỆT NAM**  \n📉 **VNINDEX**: 1,757.95 điểm (-3.11, -0.18%)  \n📉 **VN30**: 2,009.64 điểm (-4.05, -0.20%)  \n\n📊 **Top cổ phiếu tăng mạnh**  \n🔺 BTH (172247.81%)  \n🔺 TCO (11900.59%)  \n🔺 VNI (8736.93%)  \n\n📊 **Top cổ phiếu giảm mạnh**  \n🔻 PTC (-99.96%)  \n🔻 TOP (-99.67%)  \n🔻 HTP (-98.51%)  \n🕒 Cập nhật: 16-10-2025 09:13:42\n## Task Type:\nIntent: market\nMô tả: Phân tích xu hướng cổ phiếu hoặc thị trường bằng cách kết hợp dữ liệu API và tin tức gần nhất.\n\n## Task Input:\n**User:** Thị trường chứng khoán hôm qua có gì biến động?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'system'}, {'content': 'Thị trường chứng khoán hôm qua có gì biến động?', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.7}}
2025-10-16 09:13:42,604 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 09:13:42,605 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 09:13:42,779 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002900AB65310>
2025-10-16 09:13:42,781 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029061AC2570> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 09:13:42,857 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029006254C10>
2025-10-16 09:13:42,859 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,860 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:42,860 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,862 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:42,862 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:13:55,471 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'7630'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 02:13:42 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 09:13:55,473 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 09:13:55,473 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:13:55,518 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:55,519 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:55,520 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:55,521 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '7630', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 02:13:42 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 09:13:55,522 [DEBUG] openai._base_client: request_id: None
2025-10-16 09:13:55,533 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 09:13:55,534 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 09:13:55,535 [DEBUG] RAGPipeline: intent: market
2025-10-16 09:13:55,535 [DEBUG] RAGPipeline: timestamp: 2025-10-16T09:13:55.535459
2025-10-16 09:15:32,725 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:15:33,639 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:15:34,205 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:15:34,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:15:34,860 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:15:35,667 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:35,670 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451B4ED690>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:35,675 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,675 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:15:35 GMT')])
2025-10-16 09:15:35,677 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:15:35,677 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,678 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:35,679 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:35,680 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:35,680 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:35,681 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:35,683 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:35,685 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451B4ED750>
2025-10-16 09:15:35,686 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,688 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:35,689 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,690 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:35,691 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,692 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:15:35 GMT')])
2025-10-16 09:15:35,693 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:15:35,694 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,695 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:35,696 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:35,696 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:35,697 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:35,697 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:37,758 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:37,784 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:15:38,157 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:15:38,484 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:38,513 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:15:38,693 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:38,697 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451D146D10>
2025-10-16 09:15:38,698 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:15:38,699 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:38,699 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:15:38,700 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:38,701 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:15:38,704 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:15:38 GMT')])
2025-10-16 09:15:38,704 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 09:15:38,704 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:15:38,711 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:38,712 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:38,713 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:38,714 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:38,714 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:39,019 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,304 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,331 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:15:39,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,940 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,967 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:15:40,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:15:40,545 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:15:40,856 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:15:41,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:15:41,175 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:15:41,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:15:41,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
