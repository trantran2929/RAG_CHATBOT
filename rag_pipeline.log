2025-10-14 07:54:09,940 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 07:54:09,965 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002197E857CD0>
2025-10-14 07:54:09,966 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 07:54:09,967 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 07:54:09,967 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 07:54:09,968 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 07:54:09,968 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 00:54:09 GMT')])
2025-10-14 07:54:09,998 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 07:54:09,998 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 07:54:09,999 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 07:54:09,999 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 07:54:09,999 [DEBUG] httpcore.connection: close.started
2025-10-14 07:54:09,999 [DEBUG] httpcore.connection: close.complete
2025-10-14 07:55:40,454 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:55:42,353 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 07:55:42,390 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:55:42,900 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 07:55:42,923 [INFO] RAGPipeline: router: API
2025-10-14 07:55:42,923 [INFO] RAGPipeline: intent: stock
2025-10-14 07:59:53,808 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:59:54,380 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 07:59:54,394 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 07:59:54,966 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 07:59:54,976 [INFO] RAGPipeline: router: API
2025-10-14 07:59:54,977 [INFO] RAGPipeline: intent: stock
2025-10-14 08:07:36,113 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:07:38,708 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-14 08:07:38,727 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:07:39,260 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-14 08:07:39,272 [INFO] RAGPipeline: router: API
2025-10-14 08:07:39,272 [INFO] RAGPipeline: intent: stock
2025-10-14 08:11:52,094 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:11:52,097 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020069873C90>
2025-10-14 08:11:52,097 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:11:52,098 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:11:52,099 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:11:52,111 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:11:51 GMT')])
2025-10-14 08:11:52,112 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:11:52,112 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:11:52,113 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:11:52,113 [DEBUG] httpcore.connection: close.started
2025-10-14 08:11:52,113 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:18:56,012 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:18:56,015 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023A0E7E5550>
2025-10-14 08:18:56,017 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:18:56,019 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:18:56,020 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:18:56,022 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:18:56,024 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:18:56,038 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:18:55 GMT')])
2025-10-14 08:18:56,039 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:18:56,040 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:18:56,042 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:18:56,043 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:18:56,044 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:18:56,046 [DEBUG] httpcore.connection: close.started
2025-10-14 08:18:56,046 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:19,564 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:20:21,489 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:20:21,942 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:20:22,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:20:22,585 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:20:23,295 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:23,307 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000183EFA2F1D0>
2025-10-14 08:20:23,308 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,310 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:20:22 GMT')])
2025-10-14 08:20:23,315 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 08:20:23,316 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,317 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:23,318 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:23,319 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:23,320 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:23,321 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:23,323 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:23,338 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000183EFA3B710>
2025-10-14 08:20:23,338 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,339 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:23,341 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,343 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:23,343 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:20:23,344 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:20:22 GMT')])
2025-10-14 08:20:23,345 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 08:20:23,346 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:23,348 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:23,350 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:23,351 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:23,894 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 08:20:24,543 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 08:20:25,970 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 08:20:26,281 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 08:20:26,587 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:26,937 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:28,739 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:28,764 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:29,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:29,391 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:29,416 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 08:20:29,519 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:29,521 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018475FA72D0>
2025-10-14 08:20:29,521 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:20:29,524 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:29,524 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:20:29,525 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:29,526 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:20:29,544 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:20:29 GMT')])
2025-10-14 08:20:29,545 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 08:20:29,545 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:20:29,562 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:29,563 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:29,563 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:29,564 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:29,565 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:20:29,964 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 08:20:30,609 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:20:30,922 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:20:31,220 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 08:20:31,505 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:20:31,828 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:20:32,122 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:20:32,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 08:20:32,539 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 08:20:32,838 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 08:20:33,729 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:20:34,092 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:20:34,100 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:20:34,462 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:20:34,484 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:20:35,032 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 08:20:35,275 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:20:35,738 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 08:20:35,802 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 08:20:35,810 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 08:20:35,841 [DEBUG] matplotlib: interactive is False
2025-10-14 08:20:35,842 [DEBUG] matplotlib: platform is win32
2025-10-14 08:20:35,892 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 08:20:35,898 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 08:20:36,555 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:20:37,106 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 08:20:38,355 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:20:38,355 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001847941BA90>
2025-10-14 08:20:38,355 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:20:38,362 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:20:38,364 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:20:38,364 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:20:38,365 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:20:38,368 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Tue, 14 Oct 2025 01:20:37 GMT')])
2025-10-14 08:20:38,372 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:20:38,372 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:20:38,374 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:20:38,376 [DEBUG] httpcore.connection: close.started
2025-10-14 08:20:38,377 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:32:39,712 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:32:42,446 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:32:44,413 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:32:45,140 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:32:45,150 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:32:46,228 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:32:50,265 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-14 08:32:50,266 [DEBUG] root: Unable to get server version: [WinError 10061] No connection could be made because the target machine actively refused it, server version defaults to None
2025-10-14 08:32:50,268 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:32:54,292 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-14 08:34:12,613 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 08:34:14,920 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 08:34:15,637 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 08:34:16,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 08:34:16,414 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 08:34:17,439 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:17,442 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2368CF6D0>
2025-10-14 08:34:17,442 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,445 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:17,445 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,447 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:17,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,449 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:17 GMT')])
2025-10-14 08:34:17,452 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 08:34:17,454 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,456 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:17,457 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:17,458 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:17,460 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:17,461 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:17,461 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:17,467 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2368D3C90>
2025-10-14 08:34:17,469 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,470 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:17,473 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,474 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:17,475 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 08:34:17,478 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:17 GMT')])
2025-10-14 08:34:17,480 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 08:34:17,485 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 08:34:17,486 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:17,487 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:17,488 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:17,488 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:17,490 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:18,267 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 08:34:19,063 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 08:34:22,325 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 08:34:22,608 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 08:34:22,913 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:23,275 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:25,495 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:25,527 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:25,826 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:26,445 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:26,476 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 08:34:26,797 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:26,812 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2DC396890>
2025-10-14 08:34:26,812 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:34:26,815 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:26,815 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:34:26,817 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:26,817 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:34:26,838 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:34:26 GMT')])
2025-10-14 08:34:26,839 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 08:34:26,840 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:34:26,856 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:26,857 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:26,858 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:26,859 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:26,859 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:34:27,259 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:27,534 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 08:34:27,560 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 08:34:28,162 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:28,424 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 08:34:28,447 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 08:34:28,726 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 08:34:29,008 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 08:34:29,326 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:34:29,599 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 08:34:29,628 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 08:34:30,154 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 08:34:30,442 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 08:34:31,484 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:34:32,229 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:34:32,232 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 08:34:32,918 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 08:34:32,996 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:34:33,549 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 08:34:33,635 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 08:34:34,828 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 08:34:35,112 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 08:34:35,127 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 08:34:35,155 [DEBUG] matplotlib: interactive is False
2025-10-14 08:34:35,157 [DEBUG] matplotlib: platform is win32
2025-10-14 08:34:35,279 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 08:34:35,291 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 08:34:38,095 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 08:34:45,462 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 08:34:46,586 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:34:46,611 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2DF8CC450>
2025-10-14 08:34:46,612 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:34:46,616 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:34:46,616 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:34:46,619 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:34:46,619 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:34:46,637 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:34:46 GMT')])
2025-10-14 08:34:46,638 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:34:46,639 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:34:46,640 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:34:46,641 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:34:46,641 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:34:46,641 [DEBUG] httpcore.connection: close.started
2025-10-14 08:34:46,644 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:37:21,141 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:37:21,142 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001785EB70690>
2025-10-14 08:37:21,142 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:37:21,144 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:37:21,145 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:37:21,150 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:37:20 GMT')])
2025-10-14 08:37:21,152 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:37:21,152 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:37:21,153 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:37:21,153 [DEBUG] httpcore.connection: close.started
2025-10-14 08:37:21,153 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:37:53,815 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:37:53,817 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001785EB1EA90>
2025-10-14 08:37:53,817 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:37:53,818 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:37:53,818 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:37:53,819 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:37:53,819 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:37:53,825 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 01:37:53 GMT')])
2025-10-14 08:37:53,825 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:37:53,825 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:37:53,826 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:37:53,826 [DEBUG] httpcore.connection: close.started
2025-10-14 08:37:53,827 [DEBUG] httpcore.connection: close.complete
2025-10-14 08:38:47,837 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 08:38:47,839 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000178FD8E4150>
2025-10-14 08:38:47,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 08:38:47,840 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 08:38:47,841 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 08:38:47,842 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 08:38:47,842 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 08:38:47,847 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 01:38:47 GMT')])
2025-10-14 08:38:47,848 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 08:38:47,848 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 08:38:47,849 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 08:38:47,849 [DEBUG] httpcore.connection: close.started
2025-10-14 08:38:47,849 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:47,310 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:41:49,322 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:41:49,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:41:50,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:41:50,437 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:41:51,164 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:51,185 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025B86AFF4D0>
2025-10-14 09:41:51,187 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,189 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:51,190 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,191 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:51,192 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,195 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:41:51 GMT')])
2025-10-14 09:41:51,196 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:41:51,196 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:51,198 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:51,198 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:51,202 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:51,203 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:51,204 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025B86B0B690>
2025-10-14 09:41:51,206 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,206 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:51,208 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,210 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:51,210 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:41:51,212 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:41:51 GMT')])
2025-10-14 09:41:51,213 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:41:51,215 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:41:51,217 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:51,217 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:51,218 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:51,218 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:51,219 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:51,943 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:41:52,605 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:41:54,009 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:41:54,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:41:54,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:54,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:56,556 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:56,586 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:56,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:57,174 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:57,198 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:41:57,301 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:41:57,303 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025C86297950>
2025-10-14 09:41:57,304 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:41:57,305 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:41:57,306 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:41:57,307 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:41:57,308 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:41:57,364 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:41:57 GMT')])
2025-10-14 09:41:57,364 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:41:57,366 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:41:57,387 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:41:57,388 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:41:57,388 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:41:57,389 [DEBUG] httpcore.connection: close.started
2025-10-14 09:41:57,390 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:41:57,773 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,049 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,074 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:41:58,381 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,695 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:41:58,723 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:41:58,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:41:59,286 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:41:59,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:41:59,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:41:59,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:42:00,483 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:42:00,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:42:01,597 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:42:01,959 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:42:01,964 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:42:02,343 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:42:02,362 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:42:02,792 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:42:02,880 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:42:03,341 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:42:03,406 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:42:03,409 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:42:03,440 [DEBUG] matplotlib: interactive is False
2025-10-14 09:42:03,441 [DEBUG] matplotlib: platform is win32
2025-10-14 09:42:03,491 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:42:03,493 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:42:04,141 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:42:05,387 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:42:06,507 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:42:06,521 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025C89E44850>
2025-10-14 09:42:06,521 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:42:06,526 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:42:06,526 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:42:06,528 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:42:06,528 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:42:06,547 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:42:06 GMT')])
2025-10-14 09:42:06,549 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:42:06,550 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:42:06,551 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:42:06,551 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:42:06,552 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:42:06,552 [DEBUG] httpcore.connection: close.started
2025-10-14 09:42:06,553 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:23,058 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:43:24,927 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:43:25,388 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:43:26,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:43:26,024 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:43:26,813 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:26,828 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268677FF7D0>
2025-10-14 09:43:26,828 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,828 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:26,831 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,832 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:26,832 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,833 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:43:26 GMT')])
2025-10-14 09:43:26,835 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:26,836 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:26,836 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:26,836 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:26,841 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:26,843 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026867803C90>
2025-10-14 09:43:26,844 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,846 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:26,846 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,847 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:26,849 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:43:26,850 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:43:26 GMT')])
2025-10-14 09:43:26,850 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:43:26,853 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:43:26,854 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:26,855 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:26,855 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:26,856 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:26,857 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:27,151 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:43:27,842 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:43:29,550 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:43:29,841 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:43:30,152 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:30,558 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:32,553 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:32,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:32,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:33,192 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:33,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:43:33,356 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:33,358 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268ED79C990>
2025-10-14 09:43:33,358 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:43:33,361 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:33,362 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:43:33,362 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:33,364 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:43:33,396 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:43:33 GMT')])
2025-10-14 09:43:33,397 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:43:33,397 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:43:33,417 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:33,418 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:33,418 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:33,420 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:33,420 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:43:33,862 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,146 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,182 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:43:34,529 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,821 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:43:34,852 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:43:35,140 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:43:35,444 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:43:35,765 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:43:36,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:43:36,071 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:43:36,502 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:43:36,791 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:43:37,689 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:43:38,215 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:43:38,219 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:43:38,705 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:43:38,731 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:43:39,308 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:43:39,412 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:43:39,972 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:43:40,060 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:43:40,066 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:43:40,099 [DEBUG] matplotlib: interactive is False
2025-10-14 09:43:40,100 [DEBUG] matplotlib: platform is win32
2025-10-14 09:43:40,171 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:43:40,175 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:43:40,948 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:43:41,827 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:43:42,500 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:43:42,503 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000268EE40F8D0>
2025-10-14 09:43:42,503 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:43:42,509 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:43:42,510 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:43:42,523 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:43:42 GMT')])
2025-10-14 09:43:42,523 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:43:42,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:43:42,526 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:43:42,528 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:43:42,529 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:43:42,530 [DEBUG] httpcore.connection: close.started
2025-10-14 09:43:42,530 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:20,177 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:46:22,060 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:46:22,515 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:46:23,640 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:46:23,648 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:46:24,371 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:24,371 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000176992FF750>
2025-10-14 09:46:24,371 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,371 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:24,378 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,381 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:46:23 GMT')])
2025-10-14 09:46:24,381 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:46:24,381 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:24,383 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:24,383 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:24,383 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:24,387 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:24,389 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017699303E10>
2025-10-14 09:46:24,389 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,391 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:24,392 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,392 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:24,394 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:46:24,394 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:23 GMT')])
2025-10-14 09:46:24,396 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:46:24,400 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:46:24,400 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:24,401 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:24,401 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:24,403 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:24,404 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:24,690 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:46:25,373 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:46:26,931 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:46:27,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:46:27,522 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:27,853 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:29,501 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:29,530 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:29,818 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:30,160 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:30,195 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:46:30,300 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:30,315 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017699466C50>
2025-10-14 09:46:30,316 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:46:30,316 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:30,318 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:46:30,318 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:30,319 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:46:30,345 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:30 GMT')])
2025-10-14 09:46:30,347 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:46:30,348 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:46:30,364 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:30,365 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:30,366 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:30,366 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:30,368 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:46:30,786 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,084 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:46:31,462 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:46:31,785 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:46:32,074 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:46:32,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:46:32,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:46:33,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:46:33,042 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:46:33,692 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:46:33,993 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:46:34,835 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:46:35,180 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:46:35,184 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:46:35,541 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:46:35,556 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:46:35,994 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:46:36,988 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:46:39,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:46:39,190 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:46:39,190 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:46:39,224 [DEBUG] matplotlib: interactive is False
2025-10-14 09:46:39,225 [DEBUG] matplotlib: platform is win32
2025-10-14 09:46:39,274 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:46:39,274 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:46:39,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:46:40,753 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:46:41,167 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:46:41,169 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001775FFE0DD0>
2025-10-14 09:46:41,170 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:46:41,171 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:46:41,174 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:46:41,176 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:46:41,176 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:46:41,187 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:46:41 GMT')])
2025-10-14 09:46:41,190 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:46:41,190 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:46:41,192 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:46:41,193 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:46:41,193 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:46:41,193 [DEBUG] httpcore.connection: close.started
2025-10-14 09:46:41,195 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:38,854 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 09:47:40,774 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 09:47:41,235 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 09:47:41,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 09:47:41,885 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 09:47:42,606 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:42,608 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BEADE666D0>
2025-10-14 09:47:42,610 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,612 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:42,612 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,613 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:42,613 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:42 GMT')])
2025-10-14 09:47:42,615 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:42,615 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:42,618 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:42,619 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:42,619 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:42,620 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:42,622 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BEAE4AAF90>
2025-10-14 09:47:42,623 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,625 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:42,627 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,628 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:42,629 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 09:47:42,629 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 02:47:42 GMT')])
2025-10-14 09:47:42,629 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 09:47:42,633 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 09:47:42,634 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:42,634 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:42,635 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:42,635 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:42,635 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:42,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 09:47:43,615 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 09:47:45,108 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 09:47:45,398 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 09:47:45,689 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:46,113 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:47,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:47,890 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:48,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:48,503 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:48,532 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 09:47:48,648 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:48,651 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BED81C3790>
2025-10-14 09:47:48,652 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:47:48,653 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:48,654 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:47:48,655 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:48,657 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:47:48,676 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:48 GMT')])
2025-10-14 09:47:48,676 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 09:47:48,680 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:47:48,698 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:48,699 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:48,699 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:48,701 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:48,701 [DEBUG] httpcore.connection: close.complete
2025-10-14 09:47:49,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:49,438 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 09:47:49,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 09:47:50,003 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:50,305 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 09:47:50,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 09:47:50,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 09:47:50,966 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 09:47:51,301 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:47:51,605 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 09:47:51,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 09:47:52,163 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 09:47:52,469 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 09:47:53,289 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:47:53,649 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:47:53,652 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 09:47:54,017 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 09:47:54,038 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:47:54,501 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 09:47:55,651 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 09:47:56,078 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 09:47:56,148 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 09:47:56,155 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 09:47:56,182 [DEBUG] matplotlib: interactive is False
2025-10-14 09:47:56,183 [DEBUG] matplotlib: platform is win32
2025-10-14 09:47:56,232 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 09:47:56,232 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 09:47:56,951 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 09:47:57,720 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 09:47:58,310 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 09:47:58,331 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001BF5CE2F350>
2025-10-14 09:47:58,331 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 09:47:58,337 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 09:47:58,339 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 09:47:58,340 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 09:47:58,340 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 09:47:58,352 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 02:47:58 GMT')])
2025-10-14 09:47:58,354 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 09:47:58,354 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 09:47:58,355 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 09:47:58,356 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 09:47:58,356 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 09:47:58,356 [DEBUG] httpcore.connection: close.started
2025-10-14 09:47:58,358 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:47,355 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:16:49,299 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:16:49,780 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:16:50,428 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:16:50,434 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:16:51,146 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:51,150 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020C81BFE890>
2025-10-14 10:16:51,150 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,150 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:51,155 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,156 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:51,156 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,157 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:50 GMT')])
2025-10-14 10:16:51,157 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:16:51,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,159 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:51,161 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:51,161 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:51,162 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:51,163 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:51,164 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:51,166 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020C827D3850>
2025-10-14 10:16:51,168 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,169 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:51,171 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:16:51,172 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:50 GMT')])
2025-10-14 10:16:51,173 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:51,175 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:51,175 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:51,175 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:51,511 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:16:52,166 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:16:53,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:16:53,934 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:16:54,243 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:54,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:56,582 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:56,623 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:56,917 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:57,243 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:57,267 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:16:57,415 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:16:57,417 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D861E3E90>
2025-10-14 10:16:57,417 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:16:57,420 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:16:57,422 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:16:57,423 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:16:57,423 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:16:57,448 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:16:57 GMT')])
2025-10-14 10:16:57,451 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:16:57,452 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:16:57,470 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:16:57,470 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:16:57,472 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:16:57,473 [DEBUG] httpcore.connection: close.started
2025-10-14 10:16:57,474 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:16:57,980 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,276 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,304 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:16:58,641 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:16:58,953 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:16:59,244 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:16:59,542 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:16:59,861 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:17:00,158 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:17:00,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:17:00,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:17:00,878 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:17:01,773 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:17:02,289 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:17:02,294 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:17:02,743 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:17:02,770 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:17:03,355 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:17:03,461 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:17:04,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:17:04,170 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:17:04,177 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:17:04,216 [DEBUG] matplotlib: interactive is False
2025-10-14 10:17:04,217 [DEBUG] matplotlib: platform is win32
2025-10-14 10:17:04,283 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:17:04,286 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:17:05,163 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:17:06,042 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:17:06,588 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:17:06,590 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020D86EC0110>
2025-10-14 10:17:06,590 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:17:06,593 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:17:06,598 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:17:06,613 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:17:06 GMT')])
2025-10-14 10:17:06,613 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:17:06,613 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:17:06,617 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:17:06,618 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:17:06,619 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:17:06,620 [DEBUG] httpcore.connection: close.started
2025-10-14 10:17:06,621 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:32:31,626 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:32:31,628 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029604AF90D0>
2025-10-14 10:32:31,628 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:32:31,629 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:32:31,630 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:32:31,644 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:32:31 GMT')])
2025-10-14 10:32:31,645 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:32:31,645 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:32:31,647 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:32:31,647 [DEBUG] httpcore.connection: close.started
2025-10-14 10:32:31,648 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:34:01,113 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:34:01,115 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029604880690>
2025-10-14 10:34:01,115 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:34:01,117 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:34:01,118 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:34:01,132 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:34:00 GMT')])
2025-10-14 10:34:01,132 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:34:01,133 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:34:01,134 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:34:01,134 [DEBUG] httpcore.connection: close.started
2025-10-14 10:34:01,135 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:34:20,724 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:34:20,744 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029623B489D0>
2025-10-14 10:34:20,744 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:34:20,746 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:34:20,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:34:20,760 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:34:20 GMT')])
2025-10-14 10:34:20,760 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:34:20,760 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:34:20,761 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:34:20,761 [DEBUG] httpcore.connection: close.started
2025-10-14 10:34:20,762 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:35:03,973 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:35:03,995 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029615700690>
2025-10-14 10:35:03,995 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:35:03,996 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:35:03,998 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:35:04,010 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:35:03 GMT')])
2025-10-14 10:35:04,011 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:35:04,011 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:35:04,012 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:35:04,012 [DEBUG] httpcore.connection: close.started
2025-10-14 10:35:04,013 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:36:02,576 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:36:02,578 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029557C06B90>
2025-10-14 10:36:02,578 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:36:02,579 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:36:02,579 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:36:02,580 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:36:02,580 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:36:02 GMT')])
2025-10-14 10:36:02,594 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:36:02,594 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:36:02,596 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:36:02,596 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:36:02,596 [DEBUG] httpcore.connection: close.started
2025-10-14 10:36:02,596 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:38:18,800 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:38:18,802 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002ACDB3E8050>
2025-10-14 10:38:18,802 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:38:18,804 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:38:18,804 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:38:18,805 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:38:18,805 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:38:18,817 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:38:18 GMT')])
2025-10-14 10:38:18,818 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:38:18,818 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:38:18,819 [DEBUG] httpcore.connection: close.started
2025-10-14 10:38:18,819 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:22,327 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:40:23,174 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:40:23,637 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:40:24,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:40:24,286 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:40:25,057 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:25,077 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000224078CF610>
2025-10-14 10:40:25,077 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,080 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:25,081 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,081 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:25,082 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,083 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:24 GMT')])
2025-10-14 10:40:25,084 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:25,085 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:25,088 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:25,088 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:25,088 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:25,090 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:25,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000224078D3910>
2025-10-14 10:40:25,093 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,095 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:25,097 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:40:25,098 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:40:24 GMT')])
2025-10-14 10:40:25,098 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:25,100 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:25,104 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:25,105 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:25,512 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:40:25,643 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:40:27,268 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:40:27,557 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:40:27,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:28,134 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:29,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:29,911 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:30,194 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:30,488 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:30,518 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:40:30,643 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:30,647 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002248000A190>
2025-10-14 10:40:30,648 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:40:30,650 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:30,650 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:40:30,651 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:30,652 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:40:30,682 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:30 GMT')])
2025-10-14 10:40:30,683 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:40:30,683 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:40:30,691 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:30,702 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:30,703 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:30,703 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:30,704 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:40:31,104 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:31,831 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:40:31,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:40:32,162 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:32,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:40:32,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:40:32,733 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:40:32,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:40:33,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:40:33,548 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:40:33,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:40:34,055 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:40:34,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:40:35,236 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:40:35,620 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:40:35,624 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:40:36,872 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:40:36,893 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:40:39,105 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:40:39,586 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:40:40,035 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:40:40,102 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:40:40,105 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:40:40,138 [DEBUG] matplotlib: interactive is False
2025-10-14 10:40:40,139 [DEBUG] matplotlib: platform is win32
2025-10-14 10:40:40,190 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:40:40,192 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:40:40,889 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:40:41,469 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:40:41,914 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:40:41,918 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000022506AEF4D0>
2025-10-14 10:40:41,918 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:40:41,921 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:40:41,923 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:40:41,929 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:40:41 GMT')])
2025-10-14 10:40:41,929 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:40:41,932 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:40:41,932 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:40:41,934 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:40:41,934 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:40:41,935 [DEBUG] httpcore.connection: close.started
2025-10-14 10:40:41,935 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:15,824 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-14 10:42:16,675 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-14 10:42:17,142 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-14 10:42:17,784 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-14 10:42:17,785 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-14 10:42:18,493 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:18,506 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A2753F990>
2025-10-14 10:42:18,508 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,510 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:18,511 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,511 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:18,513 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,513 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:42:18 GMT')])
2025-10-14 10:42:18,514 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-14 10:42:18,516 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:18,517 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:18,517 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:18,517 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:18,521 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:18,522 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020A27542BD0>
2025-10-14 10:42:18,523 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,525 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:18,525 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,526 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:18,527 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-14 10:42:18,527 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:42:18 GMT')])
2025-10-14 10:42:18,528 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-14 10:42:18,531 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-14 10:42:18,533 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:18,533 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:18,534 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:18,534 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:18,535 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:18,854 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-14 10:42:19,002 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-14 10:42:20,446 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-14 10:42:20,740 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-14 10:42:21,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:21,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:22,994 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:23,023 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:23,330 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:23,910 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:23,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-14 10:42:24,040 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:24,055 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020ADC677510>
2025-10-14 10:42:24,056 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:42:24,058 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:24,058 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:42:24,059 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:24,060 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:42:24,081 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Tue, 14 Oct 2025 03:42:23 GMT')])
2025-10-14 10:42:24,083 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-14 10:42:24,083 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:42:24,101 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:24,102 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:24,103 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:24,103 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:24,104 [DEBUG] httpcore.connection: close.complete
2025-10-14 10:42:24,777 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:25,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,242 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-14 10:42:26,562 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-14 10:42:26,883 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-14 10:42:27,178 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-14 10:42:27,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-14 10:42:28,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:42:28,293 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-14 10:42:28,323 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-14 10:42:28,739 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-14 10:42:29,021 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-14 10:42:29,847 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:42:30,195 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:42:30,196 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 10:42:30,546 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 10:42:30,564 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:42:30,972 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 10:42:31,043 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 10:42:31,493 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 10:42:31,556 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 10:42:31,562 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 10:42:31,592 [DEBUG] matplotlib: interactive is False
2025-10-14 10:42:31,593 [DEBUG] matplotlib: platform is win32
2025-10-14 10:42:31,641 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 10:42:31,646 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 10:42:32,283 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 10:42:32,773 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 10:42:33,169 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-14 10:42:33,180 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000020ADD1474D0>
2025-10-14 10:42:33,181 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-14 10:42:33,183 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-14 10:42:33,183 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-14 10:42:33,185 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-14 10:42:33,185 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-14 10:42:33,192 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Tue, 14 Oct 2025 03:42:32 GMT')])
2025-10-14 10:42:33,194 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-14 10:42:33,194 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-14 10:42:33,196 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-14 10:42:33,197 [DEBUG] httpcore.http11: response_closed.started
2025-10-14 10:42:33,197 [DEBUG] httpcore.http11: response_closed.complete
2025-10-14 10:42:33,197 [DEBUG] httpcore.connection: close.started
2025-10-14 10:42:33,197 [DEBUG] httpcore.connection: close.complete
2025-10-14 15:46:29,887 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:46:50,938 [INFO] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:47:32,977 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:47:33,343 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:47:33,346 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:47:33,706 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:47:33,733 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:47:34,185 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:47:34,273 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:47:34,725 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:47:34,842 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:47:34,848 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:47:34,880 [DEBUG] matplotlib: interactive is False
2025-10-14 15:47:34,880 [DEBUG] matplotlib: platform is win32
2025-10-14 15:47:34,952 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:47:34,956 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:47:35,904 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:47:36,435 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:47:36,808 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:47:57,851 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:51:37,544 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:51:37,875 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:51:37,879 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:51:38,214 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:51:38,232 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:51:38,635 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:51:38,705 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:51:39,138 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:51:39,201 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:51:39,207 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:51:39,235 [DEBUG] matplotlib: interactive is False
2025-10-14 15:51:39,236 [DEBUG] matplotlib: platform is win32
2025-10-14 15:51:39,285 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:51:39,288 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:51:39,965 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:51:40,523 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:51:40,850 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:52:01,882 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-14 15:58:48,547 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:58:48,891 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:58:48,894 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-14 15:58:49,247 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-14 15:58:49,265 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:58:49,699 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-14 15:58:49,787 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-14 15:58:50,214 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-14 15:58:50,279 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-14 15:58:50,286 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-14 15:58:50,316 [DEBUG] matplotlib: interactive is False
2025-10-14 15:58:50,317 [DEBUG] matplotlib: platform is win32
2025-10-14 15:58:50,370 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-14 15:58:50,374 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-14 15:58:51,019 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-14 15:58:51,478 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-14 15:58:51,767 [DEBUG] urllib3.connectionpool: Starting new HTTP connection (1): 46.32.184.182:8080
2025-10-14 15:59:12,791 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-15 08:38:37,074 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:38:40,079 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:40:07,068 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:40:07,783 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:40:07,787 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:40:09,503 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:09,509 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E0FB42D0>
2025-10-15 08:40:09,510 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,513 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:09,513 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,515 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:09,515 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,522 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:40:09 GMT')])
2025-10-15 08:40:09,523 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:40:09,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,527 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:09,528 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:09,528 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:09,529 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:09,530 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:09,531 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:09,546 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E0FB6850>
2025-10-15 08:40:09,547 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,549 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:09,549 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,550 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:09,550 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:40:09,551 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:40:09 GMT')])
2025-10-15 08:40:09,552 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:40:09,555 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:40:09,555 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:09,556 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:09,556 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:09,557 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:09,558 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:14,504 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:14,537 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:40:14,867 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:40:15,232 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:15,265 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:40:16,587 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:16,604 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C2E2BB5910>
2025-10-15 08:40:16,604 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:40:16,607 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:16,608 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:40:16,608 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:16,610 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:40:16,673 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:40:16 GMT')])
2025-10-15 08:40:16,673 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:40:16,677 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:40:16,711 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:16,712 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:16,712 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:16,713 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:16,713 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:17,220 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:17,506 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:40:17,538 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:40:17,859 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:18,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:40:18,683 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:40:18,979 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:40:19,272 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:40:19,596 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:40:19,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:40:19,920 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:40:20,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:40:20,580 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:40:21,638 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:40:22,045 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:40:22,049 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:40:22,389 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:40:22,469 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:40:22,891 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:40:22,976 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:40:23,407 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:40:23,637 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:40:23,646 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:40:23,691 [DEBUG] matplotlib: interactive is False
2025-10-15 08:40:23,691 [DEBUG] matplotlib: platform is win32
2025-10-15 08:40:23,812 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:40:23,823 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:40:26,458 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:40:26,914 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:40:28,443 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:40:28,461 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C28747E850>
2025-10-15 08:40:28,462 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:40:28,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:40:28,465 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:40:28,466 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:40:28,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:40:28,522 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 01:40:28 GMT')])
2025-10-15 08:40:28,524 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:40:28,525 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:40:28,525 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:40:28,527 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:40:28,527 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:40:28,527 [DEBUG] httpcore.connection: close.started
2025-10-15 08:40:28,530 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:40:28,867 [DEBUG] RAGPipeline: llm_status: generator_not_initialized
2025-10-15 08:47:13,764 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:47:14,476 [DEBUG] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:47:14,993 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:47:15,667 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:47:15,672 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:47:16,484 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:16,486 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE48E454D0>
2025-10-15 08:47:16,486 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:16 GMT')])
2025-10-15 08:47:16,487 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:47:16,487 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,491 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:16,492 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:16,492 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:16,492 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:16,492 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:16,493 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:16,494 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE48E46690>
2025-10-15 08:47:16,494 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,495 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:16,495 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,496 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:16,496 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:47:16,498 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:16 GMT')])
2025-10-15 08:47:16,498 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:47:16,499 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:47:16,499 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:16,500 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:16,500 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:16,500 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:16,501 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:18,745 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:18,779 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:47:19,157 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:47:19,476 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:19,510 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:47:19,694 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:47:19,709 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001FE4AD211D0>
2025-10-15 08:47:19,709 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:47:19,711 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:47:19,753 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 01:47:19 GMT')])
2025-10-15 08:47:19,753 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:47:19,753 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:47:19,766 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:47:19,767 [DEBUG] httpcore.connection: close.started
2025-10-15 08:47:19,767 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:47:20,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:20,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:47:20,576 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:47:20,885 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:21,193 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:47:21,489 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:47:21,772 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:47:22,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:47:22,868 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:47:23,151 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:47:23,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:47:23,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:47:23,860 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:49:01,781 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:49:03,687 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:49:04,212 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:49:04,831 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:49:04,833 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:49:05,540 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:05,545 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB49118290>
2025-10-15 08:49:05,546 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,547 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:05,547 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,549 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:05,550 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,551 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:05 GMT')])
2025-10-15 08:49:05,551 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:49:05,552 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:05,553 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:05,554 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:05,555 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:05,557 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:05,573 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB4911B7D0>
2025-10-15 08:49:05,573 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,575 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:05,576 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,576 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:05,578 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:49:05,579 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:49:05 GMT')])
2025-10-15 08:49:05,580 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:49:05,580 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:05,581 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:05,581 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:05,581 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:07,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:07,550 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:49:07,857 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:49:08,173 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:08,208 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:49:08,957 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:08,959 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB4AD0FCD0>
2025-10-15 08:49:08,960 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:49:08,961 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:08,965 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:49:09,007 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:08 GMT')])
2025-10-15 08:49:09,009 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:49:09,010 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:49:09,034 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:09,035 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:09,036 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:09,036 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:09,038 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:09,527 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:09,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:49:09,873 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:49:10,200 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:10,504 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:49:10,552 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:49:10,864 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:49:11,186 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:49:11,506 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:49:11,796 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:49:11,823 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:49:12,190 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:49:12,484 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:49:13,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:49:13,659 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:49:13,662 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:49:14,076 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:49:14,093 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:49:14,512 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:49:14,590 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:49:15,020 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:49:15,082 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:49:15,089 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:49:15,116 [DEBUG] matplotlib: interactive is False
2025-10-15 08:49:15,117 [DEBUG] matplotlib: platform is win32
2025-10-15 08:49:15,165 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:49:15,170 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:49:15,676 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:49:16,330 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:49:17,097 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:49:17,100 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002EB55AEB790>
2025-10-15 08:49:17,101 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:49:17,103 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:49:17,104 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:49:17,113 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:49:17 GMT')])
2025-10-15 08:49:17,115 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:49:17,116 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:49:17,117 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:49:17,117 [DEBUG] httpcore.connection: close.started
2025-10-15 08:49:17,120 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:49:17,296 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:49:17,296 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:49:17,300 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:49:38,334 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:49:38,335 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:49:38,365 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:49:38,366 [INFO] openai._base_client: Retrying request to /chat/completions in 0.402170 seconds
2025-10-15 08:49:38,769 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:49:38,769 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:49:38,769 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:49:59,809 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:49:59,809 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:49:59,811 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:49:59,811 [INFO] openai._base_client: Retrying request to /chat/completions in 0.998753 seconds
2025-10-15 08:50:00,813 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-7564d632-1f7f-423f-a6e0-c21e73152243', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:50:00,813 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:50:00,814 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:50:21,845 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:50:21,846 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:50:21,849 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 08:50:21,850 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 08:50:21,851 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 08:52:34,899 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:52:34,902 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002BA0D0DC090>
2025-10-15 08:52:34,903 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:52:34,905 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:52:34,906 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:52:34,908 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:52:34,909 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:52:34,921 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 01:52:34 GMT')])
2025-10-15 08:52:34,922 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:52:34,922 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:52:34,923 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:52:34,924 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:52:34,925 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:52:34,926 [DEBUG] httpcore.connection: close.started
2025-10-15 08:52:34,927 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:52:35,199 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:52:35,199 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:52:35,202 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:52:56,238 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:52:56,239 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:52:56,241 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:52:56,241 [INFO] openai._base_client: Retrying request to /chat/completions in 0.410208 seconds
2025-10-15 08:52:56,655 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:52:56,656 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:52:56,657 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:53:17,686 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:53:17,688 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:53:17,688 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:53:17,691 [INFO] openai._base_client: Retrying request to /chat/completions in 0.808713 seconds
2025-10-15 08:53:18,500 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-da9b004c-acbe-4c6f-96ea-069c9f3c89c7', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:53:18,500 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:53:18,503 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:53:39,531 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:53:39,532 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:53:39,536 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 08:53:39,536 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 08:53:39,538 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 08:58:52,263 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 08:58:54,165 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 08:58:54,674 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 08:58:55,325 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 08:58:55,329 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 08:58:56,075 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:56,080 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9D3F8290>
2025-10-15 08:58:56,080 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,082 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:56,084 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,084 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:56,085 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,086 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:58:55 GMT')])
2025-10-15 08:58:56,088 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 08:58:56,088 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,089 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:56,090 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:56,090 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:56,091 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:56,093 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:58:56,094 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:56,096 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9D3FAE50>
2025-10-15 08:58:56,098 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,100 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:56,101 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,101 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:56,102 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 08:58:56,103 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:58:56 GMT')])
2025-10-15 08:58:56,103 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 08:58:56,103 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 08:58:56,107 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:56,108 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:56,108 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:56,109 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:56,109 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:58:58,152 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:58:58,183 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:58:58,485 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:58:58,806 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:58:58,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 08:58:59,624 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:58:59,627 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023B9EFE97D0>
2025-10-15 08:58:59,627 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:58:59,629 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:58:59,630 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:58:59,631 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:58:59,632 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:58:59,666 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 01:58:59 GMT')])
2025-10-15 08:58:59,668 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 08:58:59,668 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:58:59,695 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:58:59,696 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:58:59,696 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:58:59,697 [DEBUG] httpcore.connection: close.started
2025-10-15 08:58:59,698 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:59:00,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:59:00,470 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 08:59:00,501 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 08:59:00,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:59:01,120 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 08:59:01,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 08:59:01,446 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 08:59:01,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 08:59:02,060 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:59:02,351 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 08:59:02,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 08:59:02,716 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 08:59:03,035 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 08:59:03,851 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:59:04,231 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:59:04,234 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 08:59:04,604 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 08:59:04,624 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:59:05,063 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 08:59:05,142 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 08:59:05,586 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 08:59:05,650 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 08:59:05,656 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 08:59:05,686 [DEBUG] matplotlib: interactive is False
2025-10-15 08:59:05,687 [DEBUG] matplotlib: platform is win32
2025-10-15 08:59:05,738 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 08:59:05,743 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 08:59:06,175 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 08:59:06,753 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 08:59:07,515 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 08:59:07,518 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023BA93670D0>
2025-10-15 08:59:07,519 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 08:59:07,521 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 08:59:07,521 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 08:59:07,523 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 08:59:07,525 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 08:59:07,539 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 01:59:07 GMT')])
2025-10-15 08:59:07,539 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 08:59:07,539 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 08:59:07,542 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 08:59:07,544 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 08:59:07,544 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 08:59:07,545 [DEBUG] httpcore.connection: close.started
2025-10-15 08:59:07,546 [DEBUG] httpcore.connection: close.complete
2025-10-15 08:59:07,744 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:07,745 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:07,746 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:59:28,766 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:59:28,768 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:59:28,772 [DEBUG] openai._base_client: 2 retries left
2025-10-15 08:59:28,773 [INFO] openai._base_client: Retrying request to /chat/completions in 0.438809 seconds
2025-10-15 08:59:29,213 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:29,213 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:29,213 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 08:59:50,240 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 08:59:50,241 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 08:59:50,242 [DEBUG] openai._base_client: 1 retry left
2025-10-15 08:59:50,242 [INFO] openai._base_client: Retrying request to /chat/completions in 0.769119 seconds
2025-10-15 08:59:51,015 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-9aba134d-e2dc-4949-96d0-07eb95234207', 'json_data': {'messages': [{'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00 | score=0.750]\nKhng c 3 (1.813-1.820). Kch bn km tch cc:Gi vn ng trong m hnh i ngang 1.600-1.700 im vi thanh khon suy gim, nh u t t chc tip tc duy tr bn rng mnh m nh 2 thng trc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00 | score=0.625]\nTrong bi cnh VN-Index "quay u" iu chnh v cui phin 14/10, c phiuCRV ca CTCP Tp on Bt ng sn CRVvn gy ch  vi nh u t. Doanh nghip ny mi cho sn HoSE t ngy 10/10, v sau 3 phin giao dch, c phiu ny  thit lp chui tng trn lin tip. ng ca, th gi CRV tng k ngy 6/11/1955 ti Thy Nguyn, Hi Phng. V doanh nhn n t "t cng" ny hin ang s hu khi ti sn tr gi hng nghn t ng khi trc tip nm gi hn 262 triu c phiu TCH. V k hoch k...\n\n[Cp nht s liu CTCK ngy 15/10: Chng khon VPS li gn 1.400 t trong qu 3, nhiu cng ty bo li tng mnh | 15-10-2025 00:03:00 | score=0.562]\nTnh n sng 15/10,  c 9 CTCK cng b BCTC qu 3/2025. Chng khon VPS cng b BCTC qu 3 vi doanh thu hot ng trong k t 2.708 t ng, tng 65% so vi cng k nm trc. Trong , doanh thu mi gii ng gp 1.523 t, tng 113%, li cho vay v phi thu cng tng 1,5 ln ln 706 t. Sau\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 08:59:51,015 [DEBUG] openai._base_client: Sending HTTP Request: POST http://10.14.80.7:8000/v1/chat/completions
2025-10-15 08:59:51,016 [DEBUG] httpcore.connection: connect_tcp.started host='10.14.80.7' port=8000 local_address=None timeout=None socket_options=None
2025-10-15 09:00:12,037 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectTimeout(TimeoutError(10060, 'A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond', None, 10060, None))
2025-10-15 09:00:12,038 [DEBUG] openai._base_client: Encountered httpx.TimeoutException
Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 101, in map_httpcore_exceptions
    yield
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 250, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 256, in handle_request
    raise exc from None
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection_pool.py", line 236, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 101, in handle_request
    raise exc
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 78, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_sync\connection.py", line 124, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_backends\sync.py", line 207, in connect_tcp
    with map_exceptions(exc_map):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpcore\_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\openai\_base_client.py", line 982, in request
    response = self._client.send(
               ^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 914, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 942, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 979, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_client.py", line 1014, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 249, in handle_request
    with map_httpcore_exceptions():
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\contextlib.py", line 158, in __exit__
    self.gen.throw(typ, value, traceback)
  File "c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\httpx\_transports\default.py", line 118, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectTimeout: [WinError 10060] A connection attempt failed because the connected party did not properly respond after a period of time, or established connection failed because connected host has failed to respond
2025-10-15 09:00:12,039 [DEBUG] openai._base_client: Raising timeout error
2025-10-15 09:00:12,039 [DEBUG] RAGPipeline: llm_status: error
2025-10-15 09:00:12,039 [DEBUG] RAGPipeline: llm_error: Request timed out.
2025-10-15 09:35:06,192 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 09:35:08,310 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 09:35:08,876 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 09:35:09,511 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 09:35:09,516 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 09:35:10,427 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:10,442 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DACEBE90>
2025-10-15 09:35:10,442 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,444 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:10,445 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,446 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:10,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,450 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 02:35:10 GMT')])
2025-10-15 09:35:10,450 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 09:35:10,450 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,454 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:10,455 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:10,456 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:10,457 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:10,458 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:10,459 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:10,463 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DACFAE50>
2025-10-15 09:35:10,464 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:10,466 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,468 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:10,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:35:10,470 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:35:10 GMT')])
2025-10-15 09:35:10,470 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 09:35:10,473 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:35:10,474 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:10,475 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:10,476 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:10,476 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:10,476 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:10,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:10,772 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:35:11,044 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:35:11,357 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:11,384 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 09:35:12,206 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:35:12,218 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000134DA6D9750>
2025-10-15 09:35:12,219 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:35:12,221 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:35:12,221 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:35:12,223 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:35:12,224 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:35:12,316 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:35:11 GMT')])
2025-10-15 09:35:12,317 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 09:35:12,318 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:35:12,359 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:35:12,362 [DEBUG] httpcore.connection: close.started
2025-10-15 09:35:12,362 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:35:12,829 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:13,114 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:35:13,145 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 09:35:13,917 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:14,193 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:35:14,221 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:35:14,497 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 09:35:14,773 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:35:15,093 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:35:15,369 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:35:15,395 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 09:35:15,729 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 09:35:16,018 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 09:36:56,948 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 09:36:59,012 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 09:36:59,602 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 09:37:00,388 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 09:37:00,397 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 09:37:01,225 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:01,226 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025582628350>
2025-10-15 09:37:01,228 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,230 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:01,230 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,231 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:01,232 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,232 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:00 GMT')])
2025-10-15 09:37:01,235 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 09:37:01,235 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,236 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:01,238 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:01,239 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:01,240 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:01,242 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:01,243 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:01,245 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000025582629B10>
2025-10-15 09:37:01,246 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,248 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:01,250 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 09:37:01,253 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:00 GMT')])
2025-10-15 09:37:01,254 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 09:37:01,255 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:01,257 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:01,259 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:01,260 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:01,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/config.json HTTP/1.1" 200 0
2025-10-15 09:37:02,323 [INFO] accelerate.utils.modeling: We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
2025-10-15 09:37:05,908 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/generation_config.json HTTP/1.1" 200 0
2025-10-15 09:37:06,214 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/custom_generate/generate.py HTTP/1.1" 404 0
2025-10-15 09:37:06,503 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /google/gemma-3-1b-it/resolve/main/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:06,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/google/gemma-3-1b-it/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:09,400 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:09,430 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:09,738 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:10,067 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:10,092 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 09:37:10,292 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:10,296 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002560009CA50>
2025-10-15 09:37:10,297 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:37:10,298 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:10,300 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:37:10,301 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:10,302 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:37:10,355 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 02:37:09 GMT')])
2025-10-15 09:37:10,357 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 09:37:10,359 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:37:10,389 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:10,390 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:10,392 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:10,392 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:10,393 [DEBUG] httpcore.connection: close.complete
2025-10-15 09:37:10,972 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,256 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,283 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 09:37:11,648 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,954 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 09:37:11,982 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 09:37:12,271 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 09:37:12,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 09:37:12,898 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:37:13,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 09:37:13,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 09:37:13,641 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 09:37:13,940 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 09:37:14,926 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 09:37:15,391 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 09:37:15,395 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 09:37:15,885 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 09:37:15,908 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 09:37:16,458 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 09:37:16,573 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 09:37:17,136 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 09:37:17,225 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 09:37:17,232 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 09:37:17,266 [DEBUG] matplotlib: interactive is False
2025-10-15 09:37:17,267 [DEBUG] matplotlib: platform is win32
2025-10-15 09:37:17,338 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 09:37:17,345 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 09:37:18,177 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 09:37:18,893 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 09:37:19,439 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 09:37:19,456 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002568CB35C50>
2025-10-15 09:37:19,456 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 09:37:19,458 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 09:37:19,461 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 09:37:19,462 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 09:37:19,463 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 09:37:19,490 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 02:37:19 GMT')])
2025-10-15 09:37:19,490 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 09:37:19,490 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 09:37:19,495 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 09:37:19,495 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 09:37:19,496 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 09:37:19,497 [DEBUG] httpcore.connection: close.started
2025-10-15 09:37:19,497 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:17,327 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:15:19,545 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:15:20,201 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:15:20,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:15:20,944 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:15:21,908 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:21,908 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018064EF8290>
2025-10-15 14:15:21,912 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,913 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:21,913 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,916 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:21,916 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,918 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:15:21 GMT')])
2025-10-15 14:15:21,919 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:15:21,920 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,921 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:21,922 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:21,922 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:21,924 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:21,926 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:21,927 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:21,940 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018064EFAC10>
2025-10-15 14:15:21,941 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,943 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:21,946 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:15:21,947 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:15:21 GMT')])
2025-10-15 14:15:21,948 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:21,950 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:21,950 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:21,954 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:24,634 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:24,674 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:15:24,975 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:15:25,317 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:25,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:15:26,144 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:26,164 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018066ACDDD0>
2025-10-15 14:15:26,164 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:26,167 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:26,168 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:26,169 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:26,170 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:26,177 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:15:25 GMT')])
2025-10-15 14:15:26,178 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:15:26,179 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:26,181 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:26,182 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:26,183 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:26,183 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:26,184 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:26,514 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:26,799 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:15:26,827 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:15:27,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:27,434 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:15:27,461 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:15:27,752 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:15:28,031 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:15:28,351 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:15:28,646 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:15:28,675 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:15:29,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:15:29,380 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:15:30,396 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:15:30,837 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:15:30,841 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:15:31,443 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:15:31,465 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:15:31,995 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:15:32,109 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:15:32,689 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:15:32,780 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:15:32,786 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:15:32,827 [DEBUG] matplotlib: interactive is False
2025-10-15 14:15:32,827 [DEBUG] matplotlib: platform is win32
2025-10-15 14:15:32,893 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:15:32,902 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:15:33,563 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:15:34,551 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:15:35,108 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:15:35,115 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000180066FF750>
2025-10-15 14:15:35,117 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,119 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:35,119 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,121 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:35,122 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,128 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:15:34 GMT')])
2025-10-15 14:15:35,130 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:15:35,131 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,132 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:35,133 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:35,134 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:35,135 [DEBUG] httpcore.connection: close.started
2025-10-15 14:15:35,137 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:15:35,444 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-620186c7-4611-42e2-922e-52bd95d1a981', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6875, rerank=-6.2736)\nng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu Cng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu \n(Source: )\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:15:35,446 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:15:35,447 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:15:35,546 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800CFA7C10>
2025-10-15 14:15:35,547 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001806555E600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:15:35,621 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001800CDBFAD0>
2025-10-15 14:15:35,623 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:15:35,624 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:15:35,624 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:15:35,625 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:15:35,626 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:15:38,928 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2719'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:15:35 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:15:38,929 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:15:38,930 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:15:38,931 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:15:38,932 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:15:38,932 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:15:38,933 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2719', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:15:35 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:15:38,934 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:16:27,800 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:16:29,865 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:16:30,440 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:16:31,136 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:16:31,140 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:16:32,012 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:32,017 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9D93F8910>
2025-10-15 14:16:32,019 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,021 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:32,022 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,022 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:32,023 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,024 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:16:31 GMT')])
2025-10-15 14:16:32,025 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:16:32,027 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,028 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:32,029 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:32,029 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:32,030 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:32,032 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:32,034 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:32,036 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9D9564690>
2025-10-15 14:16:32,036 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,038 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:32,039 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,039 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:32,041 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:16:32,041 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:16:31 GMT')])
2025-10-15 14:16:32,042 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:16:32,044 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:16:32,045 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:32,045 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:32,046 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:32,047 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:32,047 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:34,271 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:34,302 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:16:34,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:16:35,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:35,597 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:16:36,355 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:36,366 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9DB10BB50>
2025-10-15 14:16:36,367 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:36,369 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:36,371 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:36,372 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:36,374 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:36,380 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:16:36 GMT')])
2025-10-15 14:16:36,381 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:16:36,382 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:36,384 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:36,385 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:36,386 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:36,387 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:36,388 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:36,691 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:36,991 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,021 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:16:37,348 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,657 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:16:37,687 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:16:37,996 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:16:38,292 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:16:38,610 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:16:38,902 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:16:38,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:16:39,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:16:39,568 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:16:40,545 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:16:40,992 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:16:40,997 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:16:41,433 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:16:41,450 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:16:41,935 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:16:42,032 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:16:42,460 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:16:42,530 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:16:42,537 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:16:42,567 [DEBUG] matplotlib: interactive is False
2025-10-15 14:16:42,572 [DEBUG] matplotlib: platform is win32
2025-10-15 14:16:42,626 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:16:42,629 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:16:43,149 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:16:44,049 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:16:44,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:16:44,950 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:16:45,118 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:16:45,143 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F2379B50>
2025-10-15 14:16:45,143 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,146 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:45,146 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,147 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:45,149 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,153 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:16:44 GMT')])
2025-10-15 14:16:45,155 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:16:45,155 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,157 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:45,158 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:45,159 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:45,159 [DEBUG] httpcore.connection: close.started
2025-10-15 14:16:45,161 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:16:45,455 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-12fc42d8-9cc2-4bd2-97cc-b18a43034d35', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n\n## D liu gi/ th trng: \n **VCB**  Gi hin ti: 63,000.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -100.00 (-0.16%)  \n Khi lng: 4,362,400  \n Cp nht: 15-10-2025 14:16:44\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu  ng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc  nhn nh xu hng.\n\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:16:45,460 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:16:45,461 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:16:45,576 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F7BCDE10>
2025-10-15 14:16:45,576 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D9D9BBE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:16:45,653 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D9F0F2D3D0>
2025-10-15 14:16:45,653 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:16:45,655 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:16:45,655 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:16:45,658 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:16:45,658 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:16:48,959 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2697'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:16:45 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:16:48,960 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:16:48,961 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:16:48,962 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:16:48,963 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:16:48,965 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:16:48,965 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2697', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:16:45 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:16:48,966 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:19:02,354 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:19:02,355 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2E9B35910>
2025-10-15 14:19:02,356 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,357 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:19:02,359 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,366 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:19:02 GMT')])
2025-10-15 14:19:02,367 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:19:02,367 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:19:02,368 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:19:02,368 [DEBUG] httpcore.connection: close.started
2025-10-15 14:19:02,368 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:19:02,588 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-8ace584e-30a1-4a02-8c55-fd9aef97ad7c', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. Nu ch c gi c phiu, hy m t tnh hnh gi hin ti.\n4. Nu ch c tin tc, hy tm tt xu hng th trng.\n5. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - KHNG dng ngn ng lp trnh, khng code, khng markdown, khng in ra cu trc JSON.\n- KHNG thm tin t nh `text`, `json`, `yaml`, `tool_code`, v.v.\n- KHNG ni "Ti khng phi chuyn gia ti chnh" hoc thm li m u/ngoi l.\n- Tr li ngn gn, t nhin, u tin ting Vit, c th gi nguyn thut ng (VNINDEX, VCB,...).\n\n\n\n## Current Date/Time Context:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n(Lun s dng thng tin trn khi ngi dng hi v ngy, gi, hm qua, mai, tun trc/sau.)\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tm tt ngn gn tin tc lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n[Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntr ti sn tng mnh. C th, vi hn 170,6 triu c phiu VIC nm gi trc tip, b Phm Thu Hng hin s hu khi ti sn c tnh khong 37.500 t ng, tng ng vi hn 1,4 t USD. Nh vy, tnh n nay, t ph Phm Nht Vng v b Phm Thu Hng cng l cp v chng doanh nhn duy nht t  khc thuc thm quyn. Theo thng bo ny, ngy cht danh sch c ng  ly  kin l 30/10 v thi gian ly  kin c ng d kin l trong thng 11. T ph Phm Nht Vng cng va hon tt vic dng hn 60 triu c phiu VIC (tng ng 1,55% vn iu l ca Vingroup)  gp vn vo CTCP N VRE, vn ha Tp on Vingroup ln u tin vt ngng 800.000 t ng. y cng l k lc mi ca th trng chng khon Vit Nam. c bit, cng ngy, theo d liu cp nht ca Forbes, ti sn ca t ph Phm Nht Vng, Ch tch Tp on Vingroup  t 20,3 t USD trong, tc l tng gp 3 ln s Phin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b thay th bng c o chiu bt ng trong bui chiu. C th, khi lc cu suy yu dn, phe bn bt u tn dng c hi  cht li, nht  nhm c phiu \n(Source: )\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00] (score=0.6667, rerank=-7.0788)\ntc nng ln doanh thu 5.000 t v li nhun sau thu 2.000 t ng. Nu hon thnh, y s l giai on tng trng mnh nht trong lch s Bt ng sn CRV. Trc khi nim yt, vo thng 7/2025, i hi ng c ng CRV  thng qua phng n pht hnh thm 16,81 triu c phiu cho c ng hin h\n(Source: )\n\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00] (score=0.6, rerank=-6.283)\ntrc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr su hn  h tr quanh 1.500 /- im. Khi th trng xc nhn ng ca di trung bnh trt ngn hn, c phiu trong ti khon gy qua ng trung bnh trt l tn hiu k thut xc nhn Bo co chin lc th trng mi y caChng khon An Bnh (ABS)nhn nh hin ti ang l giai on th trng tng gi tr li sau nhp iu chnh ngn hn 5 tun va qua. V mt nh gi, P/E ca VN-Index cho 4 qu gn nht  tng t mc 14,7x ngy 8/9 ln mc 15,4x ngy 8/10/2025, gn t ti\n(Source: )\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** Hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:19:02,590 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:19:02,590 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:19:02,693 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2EE6DE450>
2025-10-15 14:19:02,693 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001E2CFD0C0E0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:19:02,767 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001E2EA4A2850>
2025-10-15 14:19:02,767 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:19:02,768 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:19:06,159 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2373'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:19:02 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:19:06,159 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:19:06,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:19:06,160 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:19:06,160 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2373', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:19:02 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:19:06,161 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:28:18,625 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:28:18,643 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000023788294A90>
2025-10-15 14:28:18,643 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:28:18,644 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:28:18,645 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:28:18,652 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 07:28:18 GMT')])
2025-10-15 14:28:18,653 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:28:18,653 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:28:18,653 [DEBUG] httpcore.connection: close.started
2025-10-15 14:28:18,655 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:28:18,878 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a2867fb5-b4bc-4cfb-b5ae-183b497bab6b', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n\n\n## Bi cnh thi gian: \n Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tr v thng tin lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n[Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntr ti sn tng mnh. C th, vi hn 170,6 triu c phiu VIC nm gi trc tip, b Phm Thu Hng hin s hu khi ti sn c tnh khong 37.500 t ng, tng ng vi hn 1,4 t USD. Nh vy, tnh n nay, t ph Phm Nht Vng v b Phm Thu Hng cng l cp v chng doanh nhn duy nht t  khc thuc thm quyn. Theo thng bo ny, ngy cht danh sch c ng  ly  kin l 30/10 v thi gian ly  kin c ng d kin l trong thng 11. T ph Phm Nht Vng cng va hon tt vic dng hn 60 triu c phiu VIC (tng ng 1,55% vn iu l ca Vingroup)  gp vn vo CTCP N VRE, vn ha Tp on Vingroup ln u tin vt ngng 800.000 t ng. y cng l k lc mi ca th trng chng khon Vit Nam. c bit, cng ngy, theo d liu cp nht ca Forbes, ti sn ca t ph Phm Nht Vng, Ch tch Tp on Vingroup  t 20,3 t USD trong, tc l tng gp 3 ln s Phin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b thay th bng c o chiu bt ng trong bui chiu. C th, khi lc cu suy yu dn, phe bn bt u tn dng c hi  cht li, nht  nhm c phiu \n(Source: )\n\n[Mt c phiu bt ng sn bc u kch trn 3 phin lin tip | 15-10-2025 00:16:00] (score=0.6667, rerank=-7.0788)\ntc nng ln doanh thu 5.000 t v li nhun sau thu 2.000 t ng. Nu hon thnh, y s l giai on tng trng mnh nht trong lch s Bt ng sn CRV. Trc khi nim yt, vo thng 7/2025, i hi ng c ng CRV  thng qua phng n pht hnh thm 16,81 triu c phiu cho c ng hin h\n(Source: )\n\n[ABS: VN-Index bc vo nhp tng mi, mc tiu 1.820 im | 15-10-2025 00:06:00] (score=0.6, rerank=-6.283)\ntrc  khin cho ng lng gim, gi gim qua h tr 1.586-1.600 im. Th trng c th tm v mc h tr su hn  h tr quanh 1.500 /- im. Khi th trng xc nhn ng ca di trung bnh trt ngn hn, c phiu trong ti khon gy qua ng trung bnh trt l tn hiu k thut xc nhn Bo co chin lc th trng mi y caChng khon An Bnh (ABS)nhn nh hin ti ang l giai on th trng tng gi tr li sau nhp iu chnh ngn hn 5 tun va qua. V mt nh gi, P/E ca VN-Index cho 4 qu gn nht  tng t mc 14,7x ngy 8/9 ln mc 15,4x ngy 8/10/2025, gn t ti\n(Source: )\n\n## Task Type:\nIntent: rag\nM t: Phn tch cu hi tng qut da trn ng cnh c sn.\n\n\n## Task Input:\n**User:** hm nay c tin tc g mi?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:28:18,880 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:28:18,880 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:28:19,006 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000237EAA5A0D0>
2025-10-15 14:28:19,006 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000237E3FEFE30> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:28:19,072 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000237EABD5710>
2025-10-15 14:28:19,072 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:28:19,073 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:28:19,074 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:28:22,401 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2291'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:28:19 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:28:22,401 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:28:22,402 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:28:22,403 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2291', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:28:19 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:28:22,403 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:30:42,965 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:30:44,952 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:30:45,537 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:30:46,270 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:30:46,274 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:30:47,027 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:47,048 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B431BA8110>
2025-10-15 14:30:47,049 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,051 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:47,051 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,052 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:47,054 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,055 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:30:46 GMT')])
2025-10-15 14:30:47,056 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:30:47,057 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,058 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:47,059 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:47,059 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:47,060 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:47,061 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:47,062 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:47,079 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B431BAB110>
2025-10-15 14:30:47,081 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,082 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:47,084 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,085 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:47,086 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:30:47,087 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:30:46 GMT')])
2025-10-15 14:30:47,088 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:30:47,088 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:30:47,093 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:47,093 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:47,094 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:47,096 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:47,097 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:49,261 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:49,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:30:49,588 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:30:49,905 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:49,930 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:30:50,686 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:50,688 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B433A4FF50>
2025-10-15 14:30:50,689 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:50,691 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:50,692 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:50,693 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:50,694 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:30:50,696 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:30:50 GMT')])
2025-10-15 14:30:50,697 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:30:50,698 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:30:50,700 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:50,701 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:50,702 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:50,703 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:50,704 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:51,029 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:51,324 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:30:51,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:30:51,670 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:52,434 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:30:52,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:30:52,742 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:30:53,039 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:30:53,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:30:53,670 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:30:53,696 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:30:54,046 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:30:54,339 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:30:55,239 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:30:55,630 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:30:55,633 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:30:55,990 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:30:56,015 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:30:56,430 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:30:56,542 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:30:57,008 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:30:57,075 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:30:57,080 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:30:57,110 [DEBUG] matplotlib: interactive is False
2025-10-15 14:30:57,112 [DEBUG] matplotlib: platform is win32
2025-10-15 14:30:57,178 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:30:57,181 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:30:57,647 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:30:58,313 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:30:58,747 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:30:59,267 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:30:59,487 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:30:59,489 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B44AAEF3D0>
2025-10-15 14:30:59,492 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,495 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:59,496 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,497 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:59,499 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,502 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:30:59 GMT')])
2025-10-15 14:30:59,503 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:30:59,505 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,507 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:30:59,508 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:30:59,509 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:30:59,511 [DEBUG] httpcore.connection: close.started
2025-10-15 14:30:59,512 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:30:59,809 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-6c91dfd5-ffd6-4e57-b1c3-f05606a41f21', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n\n\n## Bi cnh thi gian: \n Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tr v thng tin lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n\n## D liu gi/ th trng: \n **VCB**  Gi hin ti: 62,900.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -200.00 (-0.32%)  \n Khi lng: 4,676,100  \n Cp nht: 15-10-2025 14:30:59\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu  ng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc  nhn nh xu hng.\n\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:30:59,810 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:30:59,811 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:30:59,921 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B45032DA10>
2025-10-15 14:30:59,923 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B43220E600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:30:59,989 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B44AA9D450>
2025-10-15 14:30:59,990 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:30:59,991 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:30:59,992 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:30:59,993 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:30:59,994 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:31:03,288 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2732'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:30:59 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:31:03,288 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:31:03,289 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:31:03,290 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:31:03,291 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:31:03,291 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:31:03,292 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2732', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:30:59 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:31:03,294 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:47:57,019 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 14:47:59,052 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 14:47:59,626 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 14:48:00,278 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 14:48:00,283 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 14:48:01,136 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:01,156 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA15E985D0>
2025-10-15 14:48:01,156 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,158 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:01,158 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,160 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:01,160 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,161 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:48:00 GMT')])
2025-10-15 14:48:01,162 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 14:48:01,163 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,165 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:01,165 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:01,166 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:01,167 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:01,167 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:01,168 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:01,171 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA15EA8990>
2025-10-15 14:48:01,173 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,175 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:01,176 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,177 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:01,177 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 14:48:01,180 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:48:00 GMT')])
2025-10-15 14:48:01,181 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 14:48:01,183 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 14:48:01,184 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:01,185 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:01,186 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:01,186 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:01,187 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:03,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:03,420 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:48:03,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:48:04,052 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:04,080 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 14:48:04,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:04,859 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA17AEF850>
2025-10-15 14:48:04,860 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:04,861 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:04,863 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:04,865 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:04,866 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:04,868 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 07:48:04 GMT')])
2025-10-15 14:48:04,869 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 14:48:04,869 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:04,872 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:04,873 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:04,874 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:04,875 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:04,875 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:05,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:05,949 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 14:48:05,975 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 14:48:06,295 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:06,578 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 14:48:06,604 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 14:48:06,896 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 14:48:07,655 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 14:48:08,496 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:48:08,779 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 14:48:08,806 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 14:48:09,166 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 14:48:09,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 14:48:10,492 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:48:10,933 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:48:10,937 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 14:48:11,304 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 14:48:11,323 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:48:11,765 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 14:48:11,852 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 14:48:12,273 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 14:48:12,345 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 14:48:12,352 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 14:48:12,382 [DEBUG] matplotlib: interactive is False
2025-10-15 14:48:12,384 [DEBUG] matplotlib: platform is win32
2025-10-15 14:48:12,433 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 14:48:12,437 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 14:48:12,924 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:48:13,721 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 14:48:14,110 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:48:14,629 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:48:14,795 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:48:14,797 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA2DD0A310>
2025-10-15 14:48:14,798 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:14,800 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:14,801 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:14,802 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:14,802 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:14,808 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 07:48:14 GMT')])
2025-10-15 14:48:14,810 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:48:14,810 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:14,811 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:14,812 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:14,813 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:14,814 [DEBUG] httpcore.connection: close.started
2025-10-15 14:48:14,815 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:48:15,075 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1b81a76c-d088-43bc-9977-ee19dced0fd4', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n\n\n## Bi cnh thi gian: \n Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tr v thng tin lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n\n## D liu gi/ th trng: \n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 14:48:14\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu  ng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc  nhn nh xu hng.\n\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:48:15,075 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:48:15,076 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:48:15,161 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA345143D0>
2025-10-15 14:48:15,162 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CA164FE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:48:15,221 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA3451D090>
2025-10-15 14:48:15,222 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:48:15,223 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:48:15,224 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:48:15,225 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:48:15,225 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:48:18,494 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2737'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:48:14 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:48:18,495 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:48:18,496 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:48:18,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:48:18,497 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:48:18,498 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:48:18,498 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2737', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:48:14 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:48:18,500 [DEBUG] openai._base_client: request_id: None
2025-10-15 14:49:43,552 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 14:49:44,168 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 14:49:44,197 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 14:49:44,213 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA2D9EFFD0>
2025-10-15 14:49:44,214 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,215 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:49:44,217 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,218 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:49:44,219 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,224 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 07:49:43 GMT')])
2025-10-15 14:49:44,225 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 14:49:44,226 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,228 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:49:44,229 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:49:44,230 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:49:44,231 [DEBUG] httpcore.connection: close.started
2025-10-15 14:49:44,232 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:49:44,443 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a408af3c-11b2-446a-ac10-c31b5c65303a', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n\n\n## Bi cnh thi gian: \n Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tr v thng tin lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n\n## D liu gi/ th trng: \n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 14:49:44\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu  ng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc  nhn nh xu hng.\n\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 14:49:44,445 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 14:49:44,446 [DEBUG] httpcore.connection: close.started
2025-10-15 14:49:44,447 [DEBUG] httpcore.connection: close.complete
2025-10-15 14:49:44,447 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 14:49:44,550 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA322F6C50>
2025-10-15 14:49:44,551 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CA164FE600> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 14:49:44,615 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CA322D3610>
2025-10-15 14:49:44,617 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 14:49:44,617 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 14:49:44,619 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 14:49:44,620 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 14:49:44,621 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 14:49:47,966 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2674'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 07:49:44 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 14:49:47,967 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 14:49:47,968 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 14:49:47,969 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 14:49:47,970 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 14:49:47,971 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 14:49:47,971 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2674', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 07:49:44 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 14:49:47,972 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:10:45,828 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:10:46,423 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:10:46,451 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:10:46,453 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DA8E550>
2025-10-15 15:10:46,455 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,458 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:10:46,459 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,461 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:10:46,461 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,467 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:10:46 GMT')])
2025-10-15 15:10:46,470 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:10:46,471 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,472 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:10:46,473 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:10:46,473 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:10:46,474 [DEBUG] httpcore.connection: close.started
2025-10-15 15:10:46,475 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:10:46,714 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-b52c442d-bc1b-40b9-bb69-13bf511aac02', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn dng gc\n\n## Instruction:\n Bn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n\n\n## Constraints:\n - Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n\n\n## Bi cnh thi gian: \n Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## Examples (ch minh ha nh dng hi thoi, KHNG lp li ni dung v d, ch dng  tham kho cu trc):\n\n    **- Example 1:**\n    **User:** Hy cho ti thng tin v mt m c phiu.  \n    **Assistant:** Tr v thng tin lin quan n m c phiu .\n\n    **- Example 2:**\n    **User:** Th trng chng khon Vit Nam c xu hng g ni bt?  \n    **Assistant:** Phn tch xu hng da trn tin tc v d liu, ngn gn, sc tch.\n\n\n## D liu gi/ th trng: \n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 15:10:46\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu  ng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc  nhn nh xu hng.\n\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:10:46,716 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:10:46,717 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:10:46,845 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DAFBC50>
2025-10-15 15:10:46,846 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001B2462180E0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:10:46,904 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001B25DC70650>
2025-10-15 15:10:46,905 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:10:46,907 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:10:46,908 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:10:46,909 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:10:46,909 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:10:50,168 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2541'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:10:46 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:10:50,169 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:10:50,170 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:10:50,171 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:10:50,171 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:10:50,172 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:10:50,172 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2541', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:10:46 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:10:50,173 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:22:06,461 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:22:08,447 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:22:09,037 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:22:09,694 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:22:09,697 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:22:10,511 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:10,513 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C351A88C10>
2025-10-15 15:22:10,513 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,516 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:10,516 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,517 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:10,518 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,519 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:22:10 GMT')])
2025-10-15 15:22:10,520 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:22:10,520 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,521 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:10,521 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:10,522 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:10,522 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:10,523 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:10,524 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:10,526 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C351478E10>
2025-10-15 15:22:10,527 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,529 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:10,530 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,530 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:10,531 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:22:10,531 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:22:10 GMT')])
2025-10-15 15:22:10,533 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:22:10,536 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:22:10,537 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:10,537 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:10,538 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:10,539 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:10,540 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:12,803 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:12,832 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:22:13,141 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:22:13,469 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:13,497 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:22:14,279 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:14,282 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35390B7D0>
2025-10-15 15:22:14,284 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:14,287 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:14,288 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:14,289 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:14,290 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:14,294 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:22:14 GMT')])
2025-10-15 15:22:14,296 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:22:14,297 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:14,299 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:14,300 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:14,301 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:14,302 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:14,302 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:14,608 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:14,897 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:22:14,925 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:22:15,260 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:15,549 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:22:15,577 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:22:15,875 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:22:16,150 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:22:16,466 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:22:16,973 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:22:17,001 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:22:17,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:22:17,650 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:22:18,573 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:22:18,966 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:22:18,970 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:22:19,363 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:22:19,389 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:22:19,912 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:22:20,018 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:22:20,593 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:22:20,691 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:22:20,698 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:22:20,733 [DEBUG] matplotlib: interactive is False
2025-10-15 15:22:20,735 [DEBUG] matplotlib: platform is win32
2025-10-15 15:22:20,793 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:22:20,796 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:22:21,344 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:22:21,924 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:22:22,333 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:22:22,784 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:22:23,017 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:22:23,020 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35E972690>
2025-10-15 15:22:23,022 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,024 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:23,026 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,028 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:23,029 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,031 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:22:22 GMT')])
2025-10-15 15:22:23,033 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:22:23,034 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,036 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:23,037 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:23,038 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:23,038 [DEBUG] httpcore.connection: close.started
2025-10-15 15:22:23,040 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:22:23,299 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-4823973f-a194-4c46-8fe1-73eafb49ee3c', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh bin ng gi vi tnh hnh chung th trng.\n        - Nu nguyn nhn, kt lun xu hng ngn hn (tng / gim / trung lp).\n        - KHNG lit k tiu  tin tc.\n        \n## D liu API / Th trng:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 15:22:22\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:22:23,301 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:22:23,302 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:22:23,433 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C370100550>
2025-10-15 15:22:23,434 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C3520EA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:22:23,502 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C35E9779D0>
2025-10-15 15:22:23,504 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:22:23,506 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:22:23,506 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:22:23,508 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:22:23,509 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:22:26,793 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2839'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:22:23 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:22:26,794 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:22:26,795 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:22:26,795 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:22:26,796 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:22:26,797 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:22:26,798 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2839', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:22:23 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:22:26,798 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:36:17,822 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:36:19,970 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:36:20,905 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:36:21,658 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:36:21,663 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:36:22,402 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:36:26,440 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-15 15:36:26,440 [DEBUG] root: Unable to get server version: [WinError 10061] No connection could be made because the target machine actively refused it, server version defaults to None
2025-10-15 15:36:26,443 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:36:30,478 [DEBUG] httpcore.connection: connect_tcp.failed exception=ConnectError(ConnectionRefusedError(10061, 'No connection could be made because the target machine actively refused it', None, 10061, None))
2025-10-15 15:38:31,611 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:38:31,617 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:38:32,313 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:32,313 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC1C3A6C50>
2025-10-15 15:38:32,317 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,318 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:32,320 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,321 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:32,321 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,330 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:38:32 GMT')])
2025-10-15 15:38:32,331 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:38:32,332 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,333 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:32,335 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:32,335 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:32,335 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:32,337 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:32,338 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:32,340 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC1C38BD10>
2025-10-15 15:38:32,341 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,343 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:32,344 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,345 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:32,346 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:38:32,347 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:38:32 GMT')])
2025-10-15 15:38:32,348 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:38:32,348 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:38:32,351 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:32,352 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:32,353 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:32,354 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:32,356 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:35,200 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:35,232 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:38:35,546 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:38:35,867 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:35,898 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:38:37,272 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:37,279 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC6F479B50>
2025-10-15 15:38:37,281 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:37,283 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:37,284 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:37,286 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:37,286 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:37,314 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:38:37 GMT')])
2025-10-15 15:38:37,316 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:38:37,317 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:37,318 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:37,319 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:37,320 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:37,322 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:37,322 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:37,637 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:37,913 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:38:37,945 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:38:38,274 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:38,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:38:38,573 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:38:38,846 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:38:39,119 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:38:39,422 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:38:39,676 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:38:39,708 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:38:40,192 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:38:40,471 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:38:41,435 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:38:41,876 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:38:41,882 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:38:42,262 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:38:42,297 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:38:42,833 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:38:42,932 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:38:43,411 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:38:43,548 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:38:43,555 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:38:43,589 [DEBUG] matplotlib: interactive is False
2025-10-15 15:38:43,591 [DEBUG] matplotlib: platform is win32
2025-10-15 15:38:43,667 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:38:43,675 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:38:44,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:38:45,432 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:38:46,281 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:38:46,281 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0A604D90>
2025-10-15 15:38:46,281 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,289 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:46,291 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,292 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:46,293 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,309 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:38:46 GMT')])
2025-10-15 15:38:46,310 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:38:46,311 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,313 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:46,313 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:46,314 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:46,315 [DEBUG] httpcore.connection: close.started
2025-10-15 15:38:46,315 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:38:46,583 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-cc03452e-c5d6-419c-b8b2-3b23c81fd685', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Tr li ngn gn, chnh xc theo thng tin c trong Context hoc API.\n        - Nu khng c thng tin, ni r "Hin ti cha c d liu ph hp".\n        \n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: general\nM t: Tr li chung cc cu hi khng xc nh r intent.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:38:46,583 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:38:46,588 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:38:46,721 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BBED850>
2025-10-15 15:38:46,722 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EC6ED37140> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:38:46,791 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BBED910>
2025-10-15 15:38:46,791 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:38:46,793 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:38:46,794 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:38:46,796 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:38:46,797 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:38:50,058 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2697'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:38:47 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:38:50,060 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:38:50,060 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:38:50,060 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2697', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:38:47 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:38:50,060 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:40:56,856 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:40:57,344 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:40:57,360 [DEBUG] RAGPipeline: router: API
2025-10-15 15:40:57,360 [DEBUG] RAGPipeline: intent: stock
2025-10-15 15:45:22,277 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:45:22,280 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC6E849950>
2025-10-15 15:45:22,280 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,284 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:45:22,285 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,286 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:45:22,288 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,291 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:45:22 GMT')])
2025-10-15 15:45:22,293 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:45:22,294 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,295 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:45:22,296 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:45:22,297 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:45:22,298 [DEBUG] httpcore.connection: close.started
2025-10-15 15:45:22,300 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:45:22,461 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-03239c57-c5be-44be-a108-9019dd13587a', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Tr li ngn gn, chnh xc theo thng tin c trong Context hoc API.\n        - Nu khng c thng tin, ni r "Hin ti cha c d liu ph hp".\n        \n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: general\nM t: Tr li chung cc cu hi khng xc nh r intent.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:45:22,462 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:45:22,463 [DEBUG] httpcore.connection: close.started
2025-10-15 15:45:22,464 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:45:22,464 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:45:22,601 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0BC6F790>
2025-10-15 15:45:22,601 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EC6ED37140> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:45:22,666 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EC0F9E43D0>
2025-10-15 15:45:22,667 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:45:22,668 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:45:22,669 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:45:22,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:45:22,672 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:45:25,897 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2738'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:45:23 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:45:25,899 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:45:25,900 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:45:25,901 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:45:25,902 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:45:25,902 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:45:25,902 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2738', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:45:23 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:45:25,904 [DEBUG] openai._base_client: request_id: None
2025-10-15 15:58:36,357 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 15:58:38,273 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 15:58:38,856 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 15:58:39,965 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 15:58:39,970 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 15:58:40,816 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:40,818 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4D898950>
2025-10-15 15:58:40,820 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,821 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:40,823 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,824 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:40,824 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,825 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 08:58:40 GMT')])
2025-10-15 15:58:40,826 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 15:58:40,826 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,828 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:40,829 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:40,829 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:40,829 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:40,830 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:40,833 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:40,834 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4D580C50>
2025-10-15 15:58:40,836 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,837 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:40,840 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 15:58:40,841 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:58:40 GMT')])
2025-10-15 15:58:40,842 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 15:58:40,843 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 15:58:40,844 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:40,845 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:40,847 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:40,848 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:40,848 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:43,027 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:43,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:58:43,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:58:43,663 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:43,691 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 15:58:44,434 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:44,439 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C4F47FED0>
2025-10-15 15:58:44,439 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:44,442 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:44,444 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:44,445 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:44,447 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:44,450 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 08:58:44 GMT')])
2025-10-15 15:58:44,450 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 15:58:44,450 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:44,454 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:44,456 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:44,456 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:44,456 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:44,456 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:44,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,066 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,094 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 15:58:45,413 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,693 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 15:58:45,722 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 15:58:45,992 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 15:58:46,264 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 15:58:46,571 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:58:46,843 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 15:58:46,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 15:58:47,222 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 15:58:47,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 15:58:48,511 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:58:48,967 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:58:48,970 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 15:58:49,439 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 15:58:49,459 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:58:49,933 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 15:58:50,011 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 15:58:50,523 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 15:58:50,597 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 15:58:50,603 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 15:58:50,640 [DEBUG] matplotlib: interactive is False
2025-10-15 15:58:50,641 [DEBUG] matplotlib: platform is win32
2025-10-15 15:58:50,690 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 15:58:50,698 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 15:58:51,165 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:58:51,899 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 15:58:52,291 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 15:58:52,864 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 15:58:53,030 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 15:58:53,033 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C6BF28750>
2025-10-15 15:58:53,033 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,035 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:53,036 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,037 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:53,038 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,041 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 08:58:52 GMT')])
2025-10-15 15:58:53,042 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 15:58:53,043 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,044 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:53,046 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:53,046 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:53,047 [DEBUG] httpcore.connection: close.started
2025-10-15 15:58:53,048 [DEBUG] httpcore.connection: close.complete
2025-10-15 15:58:53,301 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-21ff0da9-6299-4824-9ad0-d75e1d7434b7', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh bin ng gi vi tnh hnh chung th trng.\n        - Nu nguyn nhn, kt lun xu hng ngn hn (tng / gim / trung lp).\n        - KHNG lit k tiu  tin tc.\n        \n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 15:58:52\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 15:58:53,302 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 15:58:53,304 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 15:58:53,439 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C654B90D0>
2025-10-15 15:58:53,440 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000012C4DEFA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 15:58:53,517 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000012C64F80850>
2025-10-15 15:58:53,518 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 15:58:53,519 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 15:58:56,811 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2690'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 08:58:54 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 15:58:56,812 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 15:58:56,813 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 15:58:56,815 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 15:58:56,816 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 15:58:56,817 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 15:58:56,819 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2690', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 08:58:54 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 15:58:56,819 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:03:35,004 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:03:36,982 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:03:37,518 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:03:38,620 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:03:38,629 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:03:39,457 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:39,465 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EC7B8890>
2025-10-15 16:03:39,466 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:03:39 GMT')])
2025-10-15 16:03:39,468 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:39,468 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:39,475 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:39,476 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:39,476 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:39,480 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EC7B9810>
2025-10-15 16:03:39,481 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,483 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:39,484 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,484 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:39,486 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:03:39,488 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:03:39 GMT')])
2025-10-15 16:03:39,491 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:03:39,494 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:03:39,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:39,498 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:39,501 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:39,502 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:39,503 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:41,961 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:41,992 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:03:42,275 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:03:42,587 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:42,615 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:03:43,404 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:43,407 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000175EE37BB50>
2025-10-15 16:03:43,408 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:43,411 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:43,412 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:43,414 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:43,414 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:43,419 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:03:43 GMT')])
2025-10-15 16:03:43,419 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:03:43,419 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:43,424 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:43,424 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:43,425 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:43,425 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:43,427 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:43,751 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:44,020 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:03:44,048 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:03:44,346 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:45,054 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:03:45,085 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:03:45,398 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:03:45,693 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:03:45,983 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:03:46,261 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:03:46,290 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:03:46,618 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:03:46,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:03:47,874 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:03:48,284 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:03:48,288 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:03:48,644 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:03:48,664 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:03:49,111 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:03:49,198 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:03:49,647 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:03:49,727 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:03:49,734 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:03:49,764 [DEBUG] matplotlib: interactive is False
2025-10-15 16:03:49,765 [DEBUG] matplotlib: platform is win32
2025-10-15 16:03:49,816 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:03:49,817 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:03:50,281 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:03:50,966 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:03:51,270 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:03:51,867 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:03:52,045 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:03:52,047 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001758BA082D0>
2025-10-15 16:03:52,048 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,049 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:52,051 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,052 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:52,053 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,055 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:03:51 GMT')])
2025-10-15 16:03:52,056 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:03:52,057 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,059 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:52,060 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:52,060 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:52,061 [DEBUG] httpcore.connection: close.started
2025-10-15 16:03:52,061 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:03:52,303 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-c0602ee4-b2ea-46ff-84a0-e04361bea2e0', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh **mc tng/gim gi c phiu** vi xu hng th trng (VNINDEX, VN30...) c m t trong tin tc.\n        - Ch tm tt ni dung tin tc c **nh hng n c phiu ** (v d: nhm ngn hng, chng khon, th trng chung).\n        - Nu r nguyn nhn chnh khin gi bin ng (nu c).\n        - Kt lun xu hng ngn hn: tng nh / gim nh / trung lp.\n        - KHNG lit k tiu  tin tc, KHNG lp nguyn vn ni dung.\n        - Vit theo ging **phn tch ti chnh ngn gn, t nhin, r rng**.\n        - V d mong i:\n        > Hm nay c phiu VCB gim 0.95%, din bin cng chiu vi xu hng iu chnh ca VN-Index khi xut hin tn hiu to nh ngn hn. Tin tiu cc t nhm chng khon khin dng tin thn trng. Xu hng ngn hn: gim nh.\n        \n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 16:03:51\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:03:52,307 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:03:52,307 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:03:52,445 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001758BA2AE90>
2025-10-15 16:03:52,446 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000175ECE1A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:03:52,522 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001759012AF50>
2025-10-15 16:03:52,523 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:03:52,523 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:03:52,525 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:03:52,526 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:03:52,527 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:03:55,827 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2732'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:03:53 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:03:55,828 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:03:55,829 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:03:55,830 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:03:55,830 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2732', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:03:53 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:03:55,834 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:03:55,843 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:03:55,844 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:03:55,845 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:03:55,845 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:03:55,847 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:03:55.847240
2025-10-15 16:10:14,841 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:10:16,827 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:10:17,426 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:10:18,265 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:10:18,273 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:10:19,154 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:19,156 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD9248A90>
2025-10-15 16:10:19,157 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,160 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:19,161 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,161 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:19,163 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,164 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:10:19 GMT')])
2025-10-15 16:10:19,165 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:10:19,166 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,167 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:19,168 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:19,169 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:19,170 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:19,171 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:19,172 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:19,174 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD924AE90>
2025-10-15 16:10:19,176 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,176 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:19,178 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,179 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:19,180 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:10:19,182 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:19 GMT')])
2025-10-15 16:10:19,182 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:10:19,184 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:10:19,185 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:19,187 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:19,187 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:19,188 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:19,189 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:21,441 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:21,473 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:10:21,765 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:10:22,090 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:22,122 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:10:22,883 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:22,886 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AD990ED90>
2025-10-15 16:10:22,887 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:22,889 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:22,890 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:22,891 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:22,892 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:22,894 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:22 GMT')])
2025-10-15 16:10:22,895 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:10:22,896 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:22,898 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:22,900 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:22,901 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:22,902 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:22,903 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:23,212 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:23,509 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:10:23,541 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:10:23,856 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:24,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:10:24,181 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:10:24,474 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:10:24,754 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:10:25,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:10:25,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:10:25,383 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:10:25,833 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:10:26,128 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:10:27,003 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:10:27,414 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:10:27,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:10:27,834 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:10:27,854 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:10:28,335 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:10:28,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:10:28,883 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:10:28,954 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:10:28,960 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:10:28,993 [DEBUG] matplotlib: interactive is False
2025-10-15 16:10:28,994 [DEBUG] matplotlib: platform is win32
2025-10-15 16:10:29,047 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:10:29,052 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:10:29,543 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:10:30,256 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:10:30,629 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:10:31,165 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:10:31,340 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:10:31,342 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AF18A8FD0>
2025-10-15 16:10:31,342 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,346 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:31,347 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,349 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:31,350 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,351 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:10:31 GMT')])
2025-10-15 16:10:31,354 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:10:31,355 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,356 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:31,356 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:31,358 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:31,358 [DEBUG] httpcore.connection: close.started
2025-10-15 16:10:31,358 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:10:31,611 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-3408844a-2984-47a6-b9ee-bd1ed570bef5', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, lun tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Tr li bng TING VIT, t nhin, ngn gn, r rng.\n- KHNG dng m code hoc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn k hiu nh VNINDEX, VN30, VCB,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n### Hng dn phn hi:\n- Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n- So snh **mc tng/gim c phiu** vi xu hng th trng (VNINDEX, VN30...).\n- Ch chn tin tc **lin quan nhm ngnh** hoc **th trng chung**.\n- Gii thch nguyn nhn bin ng, kt lun xu hng ngn hn (tng / gim / trung lp).\n- KHNG lit k tiu  tin, KHNG lp nguyn vn ni dung.\n- Ging vn: phn tch ti chnh ngn gn, t nhin.\n- V d:\n> Hm nay c phiu VCB gim 0.95%, din bin cng chiu vi xu hng iu chnh ca VN-Index khi xut hin tn hiu to nh ngn hn. Dng tin c du hiu thn trng, thanh khon gim nh. Xu hng ngn hn: gim nh.\n\n\n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 16:10:31\n\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n### Tr li r rng, 35 cu, theo hng phn tch ti chnh ngn hn.\n\n\n**Assistant:**', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:10:31,617 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:10:31,618 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:10:31,734 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AE624DAD0>
2025-10-15 16:10:31,735 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000026AD98AA960> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:10:31,831 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000026AF18AB450>
2025-10-15 16:10:31,833 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:10:31,835 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:10:31,835 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:10:31,836 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:10:31,837 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:10:35,138 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2760'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:10:32 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:10:35,139 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:10:35,140 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:10:35,141 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:10:35,144 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2760', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:10:32 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:10:35,144 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:10:35,154 [DEBUG] RAGPipeline: fallback_trigger: LLM output too short
2025-10-15 16:10:35,154 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:10:35,156 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:10:35,157 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:10:35,157 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:10:35,159 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:10:35.159338
2025-10-15 16:14:07,194 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 16:14:09,157 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 16:14:09,786 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 16:14:10,473 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 16:14:10,477 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 16:14:11,214 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:11,216 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254307B8B90>
2025-10-15 16:14:11,217 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,219 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:11,221 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,221 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:14:11 GMT')])
2025-10-15 16:14:11,222 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 16:14:11,223 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,223 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:11,224 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:11,224 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:11,224 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:11,225 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:11,227 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:11,229 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000254307BAE90>
2025-10-15 16:14:11,230 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,232 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:11,233 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,233 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:11,235 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 16:14:11,236 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 09:14:11 GMT')])
2025-10-15 16:14:11,237 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 16:14:11,237 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 16:14:11,239 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:11,239 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:11,241 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:11,241 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:11,241 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:13,386 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:13,418 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:14:13,730 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:14:14,188 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:14,216 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 16:14:14,970 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:14,972 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002543265C6D0>
2025-10-15 16:14:14,973 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:14,976 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:14,976 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:14,977 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:14,978 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:14,980 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 09:14:14 GMT')])
2025-10-15 16:14:14,981 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 16:14:14,982 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:14,984 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:14,985 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:14,986 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:14,986 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:14,987 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:15,280 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:15,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 16:14:15,607 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 16:14:15,932 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:16,224 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 16:14:16,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 16:14:16,553 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 16:14:16,849 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 16:14:17,169 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:14:17,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 16:14:17,486 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 16:14:17,832 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 16:14:18,142 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 16:14:19,047 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:14:19,450 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:14:19,457 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 16:14:19,841 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 16:14:19,860 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:14:20,321 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 16:14:20,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 16:14:20,904 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 16:14:20,993 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 16:14:21,000 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 16:14:21,030 [DEBUG] matplotlib: interactive is False
2025-10-15 16:14:21,031 [DEBUG] matplotlib: platform is win32
2025-10-15 16:14:21,088 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 16:14:21,091 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 16:14:21,587 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:14:22,180 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 16:14:22,504 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 16:14:22,961 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 16:14:23,121 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 16:14:23,146 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002544EE40190>
2025-10-15 16:14:23,147 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,148 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:23,150 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,151 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:23,151 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,157 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 09:14:22 GMT')])
2025-10-15 16:14:23,158 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 16:14:23,159 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,160 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:23,161 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:23,162 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:23,162 [DEBUG] httpcore.connection: close.started
2025-10-15 16:14:23,163 [DEBUG] httpcore.connection: close.complete
2025-10-15 16:14:23,418 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a97f4b67-0dbb-4ea2-b4e1-0dc88a761853', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh bin ng gi vi tnh hnh chung th trng.\n        - Nu nguyn nhn, kt lun xu hng ngn hn (tng / gim / trung lp).\n        - KHNG lit k tiu  tin tc.\n        \n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 16:14:22\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.6548, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so \n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 16:14:23,420 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 16:14:23,421 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 16:14:23,536 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002543D76AE90>
2025-10-15 16:14:23,536 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000025430E1A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 16:14:23,615 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002544EC6FD10>
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 16:14:23,617 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 16:14:23,621 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 16:14:23,622 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 16:14:26,885 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2703'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 09:14:24 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 16:14:26,886 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 16:14:26,887 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 16:14:26,888 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 16:14:26,888 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 16:14:26,889 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 16:14:26,890 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2703', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 09:14:24 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 16:14:26,890 [DEBUG] openai._base_client: request_id: None
2025-10-15 16:14:26,898 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 16:14:26,898 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 16:14:26,901 [DEBUG] RAGPipeline: intent: stock_news
2025-10-15 16:14:26,902 [DEBUG] RAGPipeline: llm_response_len: 1247
2025-10-15 16:14:26,903 [DEBUG] RAGPipeline: timestamp: 2025-10-15T16:14:26.903181
2025-10-15 19:17:13,733 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:17:14,828 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:17:15,837 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:17:15,839 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C719D96B50>
2025-10-15 19:17:15,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:17:15,844 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:17:15,844 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:17:15,846 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:17:15,847 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:17:15,871 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'zstd'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:17:15 GMT')])
2025-10-15 19:17:15,871 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:17:15,871 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:17:15,876 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:17:15,878 [DEBUG] httpcore.connection: close.started
2025-10-15 19:17:15,878 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:17:16,241 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-a9e7dd50-7546-481d-9d74-f5af37adfc3c', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh bin ng gi vi tnh hnh chung th trng.\n        - Nu nguyn nhn, kt lun xu hng ngn hn (tng / gim / trung lp).\n        - KHNG lit k tiu  tin tc.\n        \n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 19:17:14\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=2.9442)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay xy ra, nht l sau chui tng im mnh nht lch s, nhng iu ny c xem l nhp kim tra li (re-test) cn thit. Ri ro xu hng ch thc s xut hin khi vng h tr b xuyn thng i km thanh khon bn tng mnh. Trong kch bn tch cc, cc nhp iu chnh l c hi  ti c cu danh m\n(Source: )\n\n[Doanh nghip thp u tin cng b BCTC qu 3/2025: Li nhun "bc hi" 90% so vi cng k | 15-10-2025 11:29:00] (score=0.6667, rerank=-2.0305)\ntrng thp qu 3/2025 tri qua giai on y thch thc v chu tc ng mnh ca vic M sit cht thu quan cng nh phng v thng mi t cc quc gia khin tnh hnh cng thng thng mi leo thang. iu ny dn n sn lng sn xut gim 57% v tiu th gim 57% khin doanh thu bn hng gim\n(Source: )\n\n[Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy | 15-10-2025 09:45:00] (score=0.75, rerank=2.694)\nPhin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b thay th bng c o chiu bt ng trong bui chiu. C th, khi lc cu suy yu dn, phe bn bt u tn dng c hi  cht li, nht  nhm c phiu \n(Source: )\n\n[Ngn hng MB ng k mua 45,76 triu c phiu cho bn ca MBS | 15-10-2025 09:38:00] (score=0.6667, rerank=3.8618)\n b sung vn cho vay margin. Nu tip tc hon tt t cho bn ny, MBS s nng vn iu l ln mc 6.587,1 t ng. Sau khi hon tt cho bn c phiu cho c ng hin hu, MBS s tip tc pht hnh 8,59 triu c phiu theo chng trnh la chn ngi lao ng (ESOP) vi gi 10.000 ng/c phiu Ngn hng TMCP Qun i (MB, m: MBB, sn HoSE) va ng k thc hin quyn mua c phiu cho bn thm ca CTCP Chng khon MB (MBS). Theo , MB ng k thc hin 381,37 triu quyn mua tng n\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** C phiu VCB hm nay bin ng nh no?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:17:16,248 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:17:16,250 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:17:16,338 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83FE50>
2025-10-15 19:17:16,340 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:17:16,450 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA15A90>
2025-10-15 19:17:16,450 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:17:16,452 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:17:16,452 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:17:16,454 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:17:16,454 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:17:19,886 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2883'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:17:16 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:17:19,886 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:17:19,889 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:17:19,892 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2883', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:17:16 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:17:19,892 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:17:19,917 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:17:19,917 [INFO] RAGPipeline: route: hybrid
2025-10-15 19:17:19,917 [INFO] RAGPipeline: intent: stock_news
2025-10-15 19:17:19,919 [INFO] RAGPipeline: llm_response_len: 1289
2025-10-15 19:17:19,919 [INFO] RAGPipeline: timestamp: 2025-10-15T19:17:19.919516
2025-10-15 19:18:27,735 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:18:33,490 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:18:34,535 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:18:34,537 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83F750>
2025-10-15 19:18:34,539 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,541 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:18:34,542 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,544 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:18:34,544 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,554 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:18:34 GMT')])
2025-10-15 19:18:34,555 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:18:34,555 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,556 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:18:34,556 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:18:34,558 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:18:34,558 [DEBUG] httpcore.connection: close.started
2025-10-15 19:18:34,558 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:18:34,610 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-ce49cf66-9093-42ab-a233-3317e430655b', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Vit 35 cu, kt hp d liu gi (API) v tin tc (Context).\n        - So snh bin ng gi vi tnh hnh chung th trng.\n        - Nu nguyn nhn, kt lun xu hng ngn hn (tng / gim / trung lp).\n        - KHNG lit k tiu  tin tc.\n        \n## D liu gi c phiu:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 19:18:33\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.625, rerank=-0.7421)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay Th trng chng khon Vit Nam ang  giai on thng hoa him thy. VN-Index lin tc bt ph  tin ln mc 1.765 im, mc nh cao nht trong lch s hot ng. Tuy nhin, khi ch s chung  i kh xa so vi vng y v khng t c phiu  ghi nhn mc tng "bng ln", nhiu nh u t e ng\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.5833, rerank=-1.478)\nCng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. Phn ln doanh thu ca CVS n t li t khon u t nm gi n ngy o hn (HTM) vi gn 4 t ng. im tch cc l li t cho vay v phi thu \n(Source: )\n\n[Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy | 15-10-2025 09:45:00] (score=0.75, rerank=0.2283)\nPhin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b thay th bng c o chiu bt ng trong bui chiu. C th, khi lc cu suy yu dn, phe bn bt u tn dng c hi  cht li, nht  nhm c phiu \n(Source: )\n\n[Ngn hng MB ng k mua 45,76 triu c phiu cho bn ca MBS | 15-10-2025 09:38:00] (score=0.6, rerank=3.3085)\n b sung vn cho vay margin. Nu tip tc hon tt t cho bn ny, MBS s nng vn iu l ln mc 6.587,1 t ng. Sau khi hon tt cho bn c phiu cho c ng hin hu, MBS s tip tc pht hnh 8,59 triu c phiu theo chng trnh la chn ngi lao ng (ESOP) vi gi 10.000 ng/c phiu Ngn hng TMCP Qun i (MB, m: MBB, sn HoSE) va ng k thc hin quyn mua c phiu cho bn thm ca CTCP Chng khon MB (MBS). Theo , MB ng k thc hin 381,37 triu quyn mua tng ng 45,76 triu c phiu do MBS ph\n## Task Type:\nIntent: stock_news\nM t: Kt hp d liu gi c phiu (API) vi tin tc (Context)  phn tch xu hng ngn hn.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:18:34,617 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:18:34,619 [DEBUG] httpcore.connection: close.started
2025-10-15 19:18:34,619 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:18:34,621 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:18:34,704 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA50610>
2025-10-15 19:18:34,704 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:18:34,775 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71EA525D0>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:18:34,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:18:38,220 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2754'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:18:34 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:18:38,225 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:18:38,225 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:18:38,228 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2754', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:18:34 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:18:38,228 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:18:38,230 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:18:38,230 [INFO] RAGPipeline: route: hybrid
2025-10-15 19:18:38,232 [INFO] RAGPipeline: intent: stock_news
2025-10-15 19:18:38,232 [INFO] RAGPipeline: llm_response_len: 1247
2025-10-15 19:18:38,232 [INFO] RAGPipeline: timestamp: 2025-10-15T19:18:38.232435
2025-10-15 19:19:09,122 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:19:09,126 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83FBD0>
2025-10-15 19:19:09,128 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,130 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:19:09,130 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,132 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:19:09,135 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,148 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'zstd'), (b'date', b'Wed, 15 Oct 2025 12:19:08 GMT')])
2025-10-15 19:19:09,150 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:19:09,152 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,154 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:19:09,155 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:19:09,156 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:19:09,156 [DEBUG] httpcore.connection: close.started
2025-10-15 19:19:09,156 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:19:09,220 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1ba8402a-1801-4b0b-ac46-bfeb9c955483', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': '- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI chuyn v ti chnh Vit Nam**, c nhim v:\n1. Phn tch xu hng th trng v c phiu Vit Nam da trn d liu (API) v tin tc (Context).\n2. Khi c c d liu gi c phiu (API) v tin tc (Context), hy kt hp c hai:\n   - So snh gi tng/gim vi tin tc cng ngy.\n   - Nu ngn gn nguyn nhn hoc din bin chnh.\n3. KHNG a ra khuyn ngh u t tuyt i, ch m t v nhn nh.\n\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n        ### Hng dn phn hi:\n        - Tr li ngn gn, chnh xc theo thng tin c trong Context hoc API.\n        - Nu khng c thng tin, ni r "Hin ti cha c d liu ph hp".\n        \n## Conversation History:\n**User:** Phn tch c phiu VCB hm nay?\n**Assistant:** Tm tt nhanh tin tc lin quan:\n- Tn hiu to nh ngn hn ca VN-Index (15-10-2025 13:36:00): c phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng ...\n- L din cng ty chng khon u tin bo l trong qu 3/2025 (15-10-2025 10:49:00): Cng ty C phn Chng khon CV (CVS) cng b BCTC qu 3/2025, ghi nhn doanh thu hot ng t gn 8 t, tng trng 72% so vi cng k nm trc. P...\n- Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy (15-10-2025 09:45:00): Phin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b tha...\n- Ngn hng MB ng k mua 45,76 triu c phiu cho bn ca MBS (15-10-2025 09:38:00):  b sung vn cho vay margin. Nu tip tc hon tt t cho bn ny, MBS s nng vn iu l ln mc 6.587,1 t ng. Sau khi hon tt cho bn c p...\n- Lch s kin v tin vn chng khon ngy 15/10/2025 (15-10-2025 05:00:00): Tin doanh nghip VFR -Cng ty C phn Vn ti v Thu tu:Ngy 22/10/2025 l ngy ng k cui cng  cht danh sch c ng nhn c tc nm 2024 bn...\n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n[Tn hiu to nh ngn hn ca VN-Index | 15-10-2025 13:36:00] (score=0.7667, rerank=-8.1688)\nc phiu tr, trong khi phn cn li ca th trng suy yu  y l du hiu cnh bo sm v s phn phi. Th hai,v mt k thut, cc ch bo ng lng nh RSI c th i vo vng qu mua (trn 70), nhng trong giai on xu hng tng mnh, y khng phi l du hiu o chiu ng tin cy. Thay\n(Source: )\n\n[L din cng ty chng khon u tin bo l trong qu 3/2025 | 15-10-2025 10:49:00] (score=0.625, rerank=-6.2736)\nng, tng trng mnh 157% so vi cng k nm trc. Tuy vy, cng ty chng khon ny l trc thu hn 18 t ng, tch cc hn khon l 24 t trong cng k nm 2024. Nm 2025, CVS t k hoch doanh thu gn 55 t ng, gp gn 5 ln thc hin nm trc. Tuy nhin, cng ty t k hoch l sau thu\n(Source: )\n\n[Vingroup lp k lc cha tng c trong lch s VN, t ph Phm Nht Vng to k tch trong cng 1 ngy | 15-10-2025 09:45:00] (score=0.625, rerank=-2.0621)\ntr ti sn tng mnh. C th, vi hn 170,6 triu c phiu VIC nm gi trc tip, b Phm Thu Hng hin s hu khi ti sn c tnh khong 37.500 t ng, tng ng vi hn 1,4 t USD. Nh vy, tnh n nay, t ph Phm Nht Vng v b Phm Thu Hng cng l cp v chng doanh nhn duy nht t  khc thuc thm quyn. Theo thng bo ny, ngy cht danh sch c ng  ly  kin l 30/10 v thi gian ly  kin c ng d kin l trong thng 11. T ph Phm Nht Vng cng va hon tt vic dng hn 60 triu c phiu VIC (tng ng 1,55% vn iu l ca Vingroup)  gp vn vo CTCP N VRE, vn ha Tp on Vingroup ln u tin vt ngng 800.000 t ng. y cng l k lc mi ca th trng chng khon Vit Nam. c bit, cng ngy, theo d liu cp nht ca Forbes, ti sn ca t ph Phm Nht Vng, Ch tch Tp on Vingroup  t 20,3 t USD trong, tc l tng gp 3 ln s Phin giao dch ngy 14/10 ca th trng chng khon Vit Nam din ra y kch tnh. Th trng k vng v mt nhp bt ph mnh m, nhng li b thay th bng c o chiu bt ng trong bui chiu. C th, khi lc cu suy yu dn, phe bn bt u tn dng c hi  cht li, nht  nhm c phiu \n(Source: )\n\n[Mt c phiu bt ng sn bc u k\n## Task Type:\nIntent: news\nM t: Tm tt tin tc chng khon ni bt.\n\n## Task Input:\n**User:** hm nay c tin tc g mi?\n\n\n## Task Output:\n\n**Assistant:**', 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:19:09,228 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:19:09,229 [DEBUG] httpcore.connection: close.started
2025-10-15 19:19:09,231 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:19:09,233 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:19:09,292 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83D350>
2025-10-15 19:19:09,292 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C77FCD7920> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:19:09,363 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C71E83E810>
2025-10-15 19:19:09,363 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:19:09,366 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:19:09,368 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:19:12,736 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2577'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:19:09 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:19:12,736 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:19:12,738 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:19:12,739 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:19:12,739 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:19:12,740 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:19:12,740 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2577', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:19:09 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:19:12,740 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:19:12,742 [INFO] RAGPipeline: llm_status: response_generated
2025-10-15 19:19:12,742 [INFO] RAGPipeline: route: rag
2025-10-15 19:19:12,742 [INFO] RAGPipeline: intent: news
2025-10-15 19:19:12,743 [INFO] RAGPipeline: llm_response_len: 1254
2025-10-15 19:19:12,743 [INFO] RAGPipeline: timestamp: 2025-10-15T19:19:12.743934
2025-10-15 19:55:07,311 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 19:55:11,217 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 19:55:13,352 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 19:55:15,061 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 19:55:15,073 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 19:55:17,544 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:17,547 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA8E718D10>
2025-10-15 19:55:17,547 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,554 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:17,556 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,556 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:17,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,564 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:55:17 GMT')])
2025-10-15 19:55:17,568 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 19:55:17,568 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,570 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:17,573 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:17,575 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:17,576 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:17,579 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:17,581 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:17,589 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA8ED2AE10>
2025-10-15 19:55:17,591 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,594 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:17,597 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,600 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:17,603 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:55:17,606 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:55:17 GMT')])
2025-10-15 19:55:17,609 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 19:55:17,613 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:55:17,616 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:17,618 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:17,620 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:17,620 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:17,624 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:23,565 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:23,638 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:55:24,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:55:24,585 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:24,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 19:55:26,389 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:26,396 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EA90BCBB50>
2025-10-15 19:55:26,397 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:26,400 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:26,404 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:26,404 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:26,408 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:26,430 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:55:26 GMT')])
2025-10-15 19:55:26,433 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 19:55:26,434 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:26,440 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:26,440 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:26,444 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:26,444 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:26,447 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:26,810 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:27,146 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:55:27,215 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 19:55:27,657 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:28,066 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:55:28,136 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:55:28,986 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 19:55:29,396 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:55:29,911 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:55:30,318 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:55:30,393 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 19:55:30,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 19:55:31,242 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 19:55:33,597 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:55:34,873 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:55:34,883 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:55:35,857 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:55:35,922 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:55:37,033 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 19:55:37,221 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:55:41,395 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 19:55:41,662 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 19:55:41,680 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 19:55:41,772 [DEBUG] matplotlib: interactive is False
2025-10-15 19:55:41,775 [DEBUG] matplotlib: platform is win32
2025-10-15 19:55:41,961 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 19:55:41,970 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 19:55:43,699 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:55:44,862 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 19:55:45,671 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:55:46,803 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/price/symbols/getList HTTP/1.1" 200 None
2025-10-15 19:55:48,681 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:55:48,687 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA6549190>
2025-10-15 19:55:48,687 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:48,694 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:48,694 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:48,700 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:48,702 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:48,718 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:55:48 GMT')])
2025-10-15 19:55:48,721 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:55:48,721 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:48,727 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:48,729 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:48,730 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:48,745 [DEBUG] httpcore.connection: close.started
2025-10-15 19:55:48,748 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:55:49,114 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1d0c1a19-36f1-4c14-948a-832afa5f1fb3', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## D liu API:\n **VCB**  Gi hin ti: 62,500.0 VN  \n M ca: 63,100.0 | Cao nht: 67,500.0 | Thp nht: 58,700.0  \n Thay i: -600.00 (-0.95%)  \n Khi lng: 5,218,800  \n Cp nht: 15-10-2025 19:55:46\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Phn tch c phiu VCB hm nay?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:55:49,119 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:55:49,124 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:55:49,277 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA6859310>
2025-10-15 19:55:49,279 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001EA8F38A720> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:55:49,337 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001EAA7A5A790>
2025-10-15 19:55:49,337 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:55:49,346 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:55:52,745 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2576'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:55:49 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:55:52,747 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:55:52,750 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:55:52,755 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:55:52,755 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:55:52,757 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:55:52,757 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2576', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:55:49 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:55:52,761 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:55:52,790 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 19:55:52,790 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 19:55:52,793 [DEBUG] RAGPipeline: intent: market
2025-10-15 19:55:52,794 [DEBUG] RAGPipeline: timestamp: 2025-10-15T19:55:52.794082
2025-10-15 19:57:33,807 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 19:57:37,058 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 19:57:38,287 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 19:57:46,824 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 19:57:46,836 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 19:57:48,784 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:48,808 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA716FF50>
2025-10-15 19:57:48,811 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,814 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:48,816 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,816 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:48,819 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,820 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:57:48 GMT')])
2025-10-15 19:57:48,823 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 19:57:48,825 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,827 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:48,828 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:48,830 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:48,831 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:48,833 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:48,836 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:48,842 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA71776D0>
2025-10-15 19:57:48,844 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,846 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:48,849 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,852 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:48,854 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 19:57:48,857 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:57:48 GMT')])
2025-10-15 19:57:48,857 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 19:57:48,861 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 19:57:48,864 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:48,867 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:48,868 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:48,868 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:48,871 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:53,684 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:53,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:57:54,124 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:57:55,011 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:55,092 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 19:57:56,733 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:57:56,737 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEA8D42E10>
2025-10-15 19:57:56,739 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:57:56,743 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:57:56,745 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:57:56,748 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:57:56,750 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:57:56,757 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 12:57:56 GMT')])
2025-10-15 19:57:56,759 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 19:57:56,761 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:57:56,768 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:57:56,770 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:57:56,773 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:57:56,775 [DEBUG] httpcore.connection: close.started
2025-10-15 19:57:56,775 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:57:57,165 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:57,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 19:57:57,649 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 19:57:58,086 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:58,494 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 19:57:58,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 19:57:58,893 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 19:57:59,211 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 19:57:59,623 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:57:59,933 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 19:58:00,008 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 19:58:00,544 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 19:58:00,954 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 19:58:03,099 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:58:04,032 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:58:04,039 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 19:58:04,948 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 19:58:04,997 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:58:06,078 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 19:58:06,280 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 19:58:07,288 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 19:58:07,447 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 19:58:07,461 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 19:58:07,536 [DEBUG] matplotlib: interactive is False
2025-10-15 19:58:07,540 [DEBUG] matplotlib: platform is win32
2025-10-15 19:58:07,676 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 19:58:07,685 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 19:58:08,888 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:10,171 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 19:58:10,862 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:11,998 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:12,039 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:13,273 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:13,300 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:14,389 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:16,400 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:17,445 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:19,454 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 19:58:20,613 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 19:58:20,629 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 19:58:23,995 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 19:58:25,190 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 19:58:29,217 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 19:58:31,203 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 19:58:31,206 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEBFFE15D0>
2025-10-15 19:58:31,210 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,215 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:58:31,217 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,220 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:58:31,223 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,229 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 12:58:31 GMT')])
2025-10-15 19:58:31,231 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 19:58:31,233 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,234 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:58:31,237 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:58:31,239 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:58:31,241 [DEBUG] httpcore.connection: close.started
2025-10-15 19:58:31,241 [DEBUG] httpcore.connection: close.complete
2025-10-15 19:58:31,503 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-44cf9865-4a49-4d41-b314-699ba0341ca4', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 15-10-2025 19:58:30\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n## Retrieved Context:\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm nay c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 19:58:31,508 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 19:58:31,510 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 19:58:31,618 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEC3649A90>
2025-10-15 19:58:31,620 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001CEA77D67B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 19:58:31,697 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001CEBFD9CC10>
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 19:58:31,700 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 19:58:31,706 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 19:58:31,708 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 19:58:34,981 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2710'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 12:58:31 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 19:58:34,983 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 19:58:34,986 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 19:58:34,988 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 19:58:34,992 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 19:58:34,994 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 19:58:34,997 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2710', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 12:58:31 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 19:58:34,998 [DEBUG] openai._base_client: request_id: None
2025-10-15 19:58:35,033 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 19:58:35,037 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 19:58:35,039 [DEBUG] RAGPipeline: intent: market
2025-10-15 19:58:35,042 [DEBUG] RAGPipeline: timestamp: 2025-10-15T19:58:35.042144
2025-10-15 20:10:44,282 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-15 20:10:47,695 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-15 20:10:49,070 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-15 20:10:50,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-15 20:10:50,412 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-15 20:10:52,731 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:10:52,737 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E0861FE10>
2025-10-15 20:10:52,739 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,744 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:10:52,745 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,746 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:10:52,747 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,750 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Wed, 15 Oct 2025 13:10:52 GMT')])
2025-10-15 20:10:52,752 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-15 20:10:52,752 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,752 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:10:52,756 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:10:52,758 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:10:52,759 [DEBUG] httpcore.connection: close.started
2025-10-15 20:10:52,761 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:10:52,763 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:10:52,769 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E08627710>
2025-10-15 20:10:52,771 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,775 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:10:52,777 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,780 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:10:52,786 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-15 20:10:52,790 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 13:10:52 GMT')])
2025-10-15 20:10:52,794 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-15 20:10:52,798 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-15 20:10:52,803 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:10:52,805 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:10:52,808 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:10:52,810 [DEBUG] httpcore.connection: close.started
2025-10-15 20:10:52,812 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:10:58,807 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:10:59,319 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 20:11:00,115 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 20:11:00,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:00,850 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-15 20:11:02,563 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:11:02,568 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E0A208250>
2025-10-15 20:11:02,568 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:02,570 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:02,570 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:02,578 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:02,581 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:02,598 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Wed, 15 Oct 2025 13:11:02 GMT')])
2025-10-15 20:11:02,601 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-15 20:11:02,603 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:02,609 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:02,611 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:02,613 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:02,615 [DEBUG] httpcore.connection: close.started
2025-10-15 20:11:02,617 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:11:03,099 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:03,515 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-15 20:11:04,125 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-15 20:11:10,045 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:11:10,471 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-15 20:11:18,057 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-15 20:11:19,487 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-15 20:11:19,999 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-15 20:11:20,515 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 20:11:21,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-15 20:11:21,638 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-15 20:11:23,584 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-15 20:11:23,995 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-15 20:11:26,123 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 20:11:27,069 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 20:11:27,076 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-15 20:11:27,980 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-15 20:11:28,032 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 20:11:29,104 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-15 20:11:29,290 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-15 20:11:30,354 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-15 20:11:30,541 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-15 20:11:30,557 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-15 20:11:30,640 [DEBUG] matplotlib: interactive is False
2025-10-15 20:11:30,644 [DEBUG] matplotlib: platform is win32
2025-10-15 20:11:30,774 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-15 20:11:30,784 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-15 20:11:32,020 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:33,223 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-15 20:11:33,986 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:35,108 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:35,140 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:36,154 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:36,179 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:37,330 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:39,340 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:40,418 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:42,429 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-15 20:11:43,522 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-15 20:11:43,531 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 20:11:46,898 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 20:11:48,191 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-15 20:11:51,425 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-15 20:11:53,386 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-15 20:11:53,396 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E1F5D8C90>
2025-10-15 20:11:53,396 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,401 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:53,407 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,427 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'date', b'Wed, 15 Oct 2025 13:11:53 GMT')])
2025-10-15 20:11:53,427 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-15 20:11:53,431 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,435 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:53,438 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:53,441 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:53,441 [DEBUG] httpcore.connection: close.started
2025-10-15 20:11:53,445 [DEBUG] httpcore.connection: close.complete
2025-10-15 20:11:53,718 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-002f83d7-c65c-4a8e-8888-6aa22e7fe133', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 15-10-2025 20:11:52\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th T, Ngy 15 thng 10 nm 2025.\nNgy hm qua l Ngy 14 thng 10 nm 2025.\nNgy mai l Ngy 16 thng 10 nm 2025.\nTun sau s bt u t Ngy 22 thng 10 nm 2025.\nTun trc bt u t Ngy 08 thng 10 nm 2025.]\n\n(Khng tm thy ni dung tin tc ph hp.)\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm nay c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 512, 'stream': False, 'temperature': 0.6}}
2025-10-15 20:11:53,721 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-15 20:11:53,723 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-15 20:11:53,853 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E21266590>
2025-10-15 20:11:53,853 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028E08C827B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-15 20:11:53,933 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028E24B9D790>
2025-10-15 20:11:53,935 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-15 20:11:53,941 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-15 20:11:53,944 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-15 20:11:53,947 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-15 20:11:53,949 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-15 20:11:57,273 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'2827'), (b'Content-Type', b'application/json'), (b'Date', b'Wed, 15 Oct 2025 13:11:53 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-15 20:11:57,273 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-15 20:11:57,278 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-15 20:11:57,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-15 20:11:57,280 [DEBUG] httpcore.http11: response_closed.started
2025-10-15 20:11:57,284 [DEBUG] httpcore.http11: response_closed.complete
2025-10-15 20:11:57,285 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '2827', 'content-type': 'application/json', 'date': 'Wed, 15 Oct 2025 13:11:53 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-15 20:11:57,287 [DEBUG] openai._base_client: request_id: None
2025-10-15 20:11:57,309 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-15 20:11:57,313 [DEBUG] RAGPipeline: route: hybrid
2025-10-15 20:11:57,315 [DEBUG] RAGPipeline: intent: market
2025-10-15 20:11:57,315 [DEBUG] RAGPipeline: timestamp: 2025-10-15T20:11:57.315857
2025-10-16 08:15:48,041 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:15:50,972 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:15:52,369 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:15:53,678 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:15:53,689 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:15:55,799 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:15:55,805 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D108C1E350>
2025-10-16 08:15:55,806 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,809 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:15:55,810 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,810 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:15:55,814 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,814 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:15:55 GMT')])
2025-10-16 08:15:55,817 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:15:55,820 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,822 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:15:55,823 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:15:55,824 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:15:55,828 [DEBUG] httpcore.connection: close.started
2025-10-16 08:15:55,828 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:15:55,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:15:55,838 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D108C2BCD0>
2025-10-16 08:15:55,839 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,843 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:15:55,846 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,848 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:15:55,848 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:15:55,850 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:15:55 GMT')])
2025-10-16 08:15:55,853 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:15:55,856 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:15:55,858 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:15:55,860 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:15:55,860 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:15:55,863 [DEBUG] httpcore.connection: close.started
2025-10-16 08:15:55,864 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:00,336 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:00,368 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:16:00,743 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:16:01,154 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:01,189 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:16:01,641 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:16:01,650 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D10AACDC50>
2025-10-16 08:16:01,650 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:01,657 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:01,660 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:01,660 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:01,666 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:01,666 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:16:01 GMT')])
2025-10-16 08:16:01,672 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:16:01,675 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:01,679 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:01,682 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:01,684 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:01,685 [DEBUG] httpcore.connection: close.started
2025-10-16 08:16:01,686 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:02,072 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:02,388 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:16:02,418 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:16:02,895 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:03,307 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:16:03,335 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:16:03,714 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:16:04,333 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:16:04,685 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:16:05,082 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:16:05,459 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:16:05,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:16:06,375 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:16:08,659 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:16:09,494 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:16:09,504 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:16:10,308 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:16:10,464 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:16:11,356 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:16:11,537 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:16:12,311 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:16:12,861 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:16:12,890 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:16:12,968 [DEBUG] matplotlib: interactive is False
2025-10-16 08:16:12,972 [DEBUG] matplotlib: platform is win32
2025-10-16 08:16:13,217 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:16:13,239 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:16:18,728 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:19,909 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:16:21,210 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:22,052 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:22,111 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:22,945 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:22,974 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:23,865 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:25,875 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:26,837 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:28,847 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:16:29,761 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:16:29,774 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:16:32,897 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:16:34,268 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:16:37,531 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:16:39,558 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:16:39,563 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D127172E10>
2025-10-16 08:16:39,565 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:39,569 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:39,572 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:39,576 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:39,578 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:39,609 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:16:39 GMT')])
2025-10-16 08:16:39,612 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:16:39,615 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:39,619 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:39,621 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:39,621 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:39,625 [DEBUG] httpcore.connection: close.started
2025-10-16 08:16:39,626 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:16:40,093 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-14eda29d-bcee-4b1b-9b08-b1efba36ce5f', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:16:38\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon Vietcap b nhim Ph Ch tch HQT thng trc | 16-10-2025 06:02:00] (score=0.7381, rerank=5.3302)\nCng ty c phn Chng khon Vietcap (MCK: VCI, sn HoSE) va cng b ngh quyt v vic b nhim Ph Ch tch HQT thng trc trong thi gian cn li ca nhim k 2021-2026 i vi ng inh Quang Hon. ng inh Quang Hon. nh: VCI Theo gii thiu, ng inh Quang Hon sinh nm 1976, c bng Thc s Kinh t chuyn ngnh Ti chnh v bng C nhn chuyn ngnh K ton - Kim ton ca trng i hc Kinh t TP.HCM. ng thi, ng c chng ch kim ton vin c lp ca B Ti chnh v l thnh vin lu nm ca Hip hi K ton vin cng chng - Vng quc Anh (ACCA). ng c hn 25 nm kinh nghim trong lnh vc t vn ti chnh, k ton v kim ton khi tng lm vic ti Cng ty kim ton quc t KPMG vi chc v Trng phng Kim ton, ph trch cc d n kim ton, sot xt ti chnh cho cc tp on a quc gia cng nh c...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm nay c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:16:40,100 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:16:40,104 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:16:40,214 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D11562CC90>
2025-10-16 08:16:40,214 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001D17D766180> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:16:40,286 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001D12715AD10>
2025-10-16 08:16:40,291 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:16:40,293 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:16:40,293 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:16:40,298 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:16:40,299 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:16:46,731 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4910'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:16:40 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:16:46,732 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:16:46,733 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:16:46,735 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:16:46,736 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:16:46,736 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:16:46,736 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4910', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:16:40 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:16:46,738 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:16:46,750 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:16:46,752 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:16:46.752113
2025-10-16 08:24:47,131 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:24:48,061 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:24:48,623 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:24:49,274 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:24:49,279 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:24:50,266 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:50,268 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E243FF90>
2025-10-16 08:24:50,268 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,268 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:50,272 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,273 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:50,273 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,276 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:24:49 GMT')])
2025-10-16 08:24:50,278 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:24:50,279 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:50,281 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:50,281 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:50,283 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:50,284 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:50,285 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:50,286 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E244AE90>
2025-10-16 08:24:50,286 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:24:50,291 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:24:49 GMT')])
2025-10-16 08:24:50,296 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:24:50,296 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:24:50,298 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:50,299 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:50,300 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:50,301 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:50,303 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:52,401 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:52,432 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:24:52,715 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:24:53,019 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,046 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:24:53,255 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:24:53,257 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236E42CFB10>
2025-10-16 08:24:53,259 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:24:53,261 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:24:53,262 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:24:53,263 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:24:53,264 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:24:53,267 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:24:52 GMT')])
2025-10-16 08:24:53,268 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:24:53,269 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:24:53,270 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:24:53,272 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:24:53,272 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:24:53,273 [DEBUG] httpcore.connection: close.started
2025-10-16 08:24:53,274 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:24:53,551 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,820 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:24:53,846 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:24:54,156 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:54,413 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:24:54,449 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:24:54,720 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:24:54,993 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:24:55,344 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:24:55,616 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:24:55,950 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:24:56,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:24:56,555 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:24:57,449 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:24:57,848 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:24:57,852 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:24:58,229 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:24:58,251 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:24:58,694 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:24:58,770 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:24:59,232 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:24:59,333 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:24:59,344 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:24:59,378 [DEBUG] matplotlib: interactive is False
2025-10-16 08:24:59,379 [DEBUG] matplotlib: platform is win32
2025-10-16 08:24:59,435 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:24:59,438 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:24:59,994 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:00,618 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:25:00,924 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:01,508 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:01,522 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:02,250 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:02,261 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:02,845 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:04,848 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:05,388 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:07,391 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:25:07,919 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:25:07,923 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:25:10,584 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:25:11,623 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:25:14,272 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:25:14,977 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:25:14,977 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF063E10>
2025-10-16 08:25:14,987 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:25:14,987 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:25:14,990 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:25:14,992 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:25:14,992 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:25:14,994 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:25:14 GMT')])
2025-10-16 08:25:14,996 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:25:14,996 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:25:14,997 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:25:14,999 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:25:14,999 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:25:15,000 [DEBUG] httpcore.connection: close.started
2025-10-16 08:25:15,000 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:25:15,379 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-d18afc2c-9f40-47c9-8f8d-fa281fd7ced0', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:25:14\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-10 gim, cho thy trng thi thm d gia cung v cu. VDSC nh gi y l din bin bnh thng, v th trng cn thi gian  thu ht thm dng tin. VDSC d bo trong cc phin ti, VN- Index s...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:25:15,379 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:25:15,384 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:25:15,487 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF25EC50>
2025-10-16 08:25:15,492 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000236E2AAA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:25:15,554 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000236FF25F850>
2025-10-16 08:25:15,554 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:25:15,554 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:25:15,556 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:25:15,558 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:25:15,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:25:21,976 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'3964'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:25:15 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:25:21,978 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:25:21,979 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:25:21,980 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:25:21,980 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:25:21,981 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:25:21,982 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '3964', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:25:15 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:25:21,982 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:25:21,992 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:25:21,993 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:25:21.993170
2025-10-16 08:32:13,765 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:32:14,861 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:32:15,665 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:32:16,475 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:32:16,480 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:32:17,621 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:17,635 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33A74EC90>
2025-10-16 08:32:17,636 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,638 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:17,639 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,640 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:17,641 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,643 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:32:17 GMT')])
2025-10-16 08:32:17,645 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:32:17,645 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,646 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:17,648 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:17,649 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:17,650 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:17,650 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:17,651 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:17,656 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33A758DD0>
2025-10-16 08:32:17,659 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,662 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:17,664 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,666 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:17,666 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:32:17,670 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:32:17 GMT')])
2025-10-16 08:32:17,672 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:32:17,675 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:32:17,676 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:17,676 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:17,677 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:17,678 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:17,680 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:20,853 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:20,881 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:32:21,195 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:32:21,542 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:21,572 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:32:21,891 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:21,911 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B33C5FCC10>
2025-10-16 08:32:21,913 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:32:21,916 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:21,917 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:32:21,920 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:21,921 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:32:21,927 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:32:21 GMT')])
2025-10-16 08:32:21,929 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:32:21,931 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:32:21,934 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:21,935 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:21,937 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:21,938 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:21,940 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:32:22,254 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:22,540 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:32:22,569 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:32:22,934 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:23,218 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:32:23,246 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:32:23,555 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:32:23,838 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:32:24,167 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:32:24,485 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:32:24,516 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:32:24,907 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:32:25,188 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:32:26,481 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:32:26,970 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:32:26,973 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:32:27,506 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:32:27,532 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:32:28,127 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:32:28,247 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:32:28,832 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:32:28,935 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:32:28,945 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:32:28,986 [DEBUG] matplotlib: interactive is False
2025-10-16 08:32:28,987 [DEBUG] matplotlib: platform is win32
2025-10-16 08:32:29,072 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:32:29,077 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:32:29,711 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:30,474 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:32:30,912 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:31,547 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:31,562 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:32,168 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:32,182 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:32,904 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:34,909 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:35,465 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:37,470 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:32:38,083 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:32:38,092 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:32:41,710 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:32:42,719 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:32:46,250 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:32:47,019 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:32:47,022 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B346A91B50>
2025-10-16 08:32:47,023 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:32:47,025 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:32:47,026 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:32:47,027 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:32:47,029 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:32:47,033 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:32:46 GMT')])
2025-10-16 08:32:47,035 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:32:47,036 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:32:47,038 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:32:47,040 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:32:47,041 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:32:47,043 [DEBUG] httpcore.connection: close.started
2025-10-16 08:32:47,043 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:33:55,089 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:33:55,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002B39129C350>
2025-10-16 08:33:55,093 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:33:55,095 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:33:55,096 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:33:55,097 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:33:55,098 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:33:55,101 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:33:54 GMT')])
2025-10-16 08:33:55,102 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:33:55,102 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:33:55,104 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:33:55,105 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:33:55,105 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:33:55,106 [DEBUG] httpcore.connection: close.started
2025-10-16 08:33:55,107 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:20,360 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:34:21,330 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:34:21,928 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:34:22,613 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:34:22,617 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:34:23,431 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:23,434 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952D1689D0>
2025-10-16 08:34:23,434 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,436 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:23,438 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,438 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:23,440 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,441 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:23 GMT')])
2025-10-16 08:34:23,442 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:34:23,443 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,444 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:23,445 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:23,445 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:23,447 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:23,448 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:23,449 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:23,461 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952D169050>
2025-10-16 08:34:23,462 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:23,464 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:34:23,468 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:23 GMT')])
2025-10-16 08:34:23,468 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:34:23,470 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:23,471 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:23,471 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:23,473 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:25,872 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:25,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:34:26,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:34:26,538 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:26,567 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:34:26,765 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:26,765 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002952ED31F50>
2025-10-16 08:34:26,765 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:26,772 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:26,774 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:26,775 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:26,776 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:26,778 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:34:26 GMT')])
2025-10-16 08:34:26,779 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:34:26,781 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:26,784 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:26,785 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:26,786 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:26,787 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:26,788 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:27,101 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:27,394 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:34:27,427 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:34:27,747 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:28,037 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:34:28,065 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:34:28,354 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:34:28,642 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:34:28,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:34:29,257 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:34:29,287 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:34:29,649 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:34:29,968 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:34:30,893 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:34:31,266 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:34:31,274 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:34:31,670 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:34:31,688 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:34:32,153 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:34:32,247 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:34:32,730 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:34:32,799 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:34:32,805 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:34:32,841 [DEBUG] matplotlib: interactive is False
2025-10-16 08:34:32,841 [DEBUG] matplotlib: platform is win32
2025-10-16 08:34:32,906 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:34:32,910 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:34:33,411 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:34,023 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:34:34,359 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:34,758 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:34,774 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:35,227 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:35,239 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:35,652 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:37,656 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:38,068 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:40,078 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:34:40,624 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:34:40,630 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:34:44,087 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:34:45,201 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:34:48,747 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:34:49,432 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:34:49,433 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000295494FD850>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,433 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:49,440 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,442 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:34:49 GMT')])
2025-10-16 08:34:49,443 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:34:49,444 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,445 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:49,446 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:49,446 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:49,447 [DEBUG] httpcore.connection: close.started
2025-10-16 08:34:49,448 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:34:49,751 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-339a9dc7-2b84-466d-b2a7-703f61aae1d9', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:34:49\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-10 gim, cho thy trng thi thm d gia cung v cu. VDSC nh gi y l din bin bnh thng, v th trng cn thi gian  thu ht thm dng tin. VDSC d bo trong cc phin ti, VN- Index s...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:34:49,753 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:34:49,753 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:34:49,873 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029549501FD0>
2025-10-16 08:34:49,876 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000002952D7CA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:34:49,944 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029544B2FE90>
2025-10-16 08:34:49,944 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:34:49,947 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:34:49,947 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:34:49,948 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:34:49,949 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:34:56,440 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4508'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:34:49 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:34:56,441 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:34:56,441 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:34:56,441 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:34:56,443 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:34:56,443 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:34:56,444 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4508', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:34:49 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:34:56,444 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:34:56,449 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:34:56,454 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:34:56.454468
2025-10-16 08:39:11,816 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:39:12,731 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:39:13,295 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:39:13,950 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:39:13,953 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:39:14,732 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:14,752 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A51EA8790>
2025-10-16 08:39:14,753 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:14,755 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,759 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:39:14 GMT')])
2025-10-16 08:39:14,759 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:39:14,760 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,762 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:14,763 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:14,763 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:14,765 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:14,765 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:14,767 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:14,769 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A51B18A50>
2025-10-16 08:39:14,769 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,772 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:14,773 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,774 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:14,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:39:14,775 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:39:14 GMT')])
2025-10-16 08:39:14,776 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:39:14,776 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:39:14,780 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:14,781 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:14,781 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:14,781 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:14,784 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:17,047 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:17,075 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:39:17,356 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:39:17,662 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:17,689 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:39:17,890 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:17,892 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A53A6BB50>
2025-10-16 08:39:17,893 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:17,896 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:17,896 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:17,897 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:17,899 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:17,909 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:39:17 GMT')])
2025-10-16 08:39:17,909 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:39:17,912 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:17,914 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:17,915 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:17,916 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:17,916 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:17,918 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:18,203 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:18,467 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:39:18,777 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:39:19,082 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:19,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:39:19,376 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:39:19,644 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:39:19,932 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:39:20,228 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:39:20,499 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:39:20,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:39:20,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:39:21,230 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:39:22,133 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:39:22,554 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:39:22,557 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:39:22,949 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:39:22,969 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:39:23,481 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:39:23,580 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:39:24,051 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:39:24,125 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:39:24,131 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:39:24,170 [DEBUG] matplotlib: interactive is False
2025-10-16 08:39:24,172 [DEBUG] matplotlib: platform is win32
2025-10-16 08:39:24,231 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:39:24,234 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:39:24,771 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:25,481 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:39:25,781 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:26,336 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:26,356 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:26,893 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:26,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:27,496 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:29,500 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:29,970 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:31,974 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:39:32,427 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:39:32,435 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:39:35,945 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:39:36,903 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:39:40,253 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:39:41,031 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:39:41,033 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A7016EE90>
2025-10-16 08:39:41,033 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,036 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:41,037 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,038 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:41,039 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,042 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:39:40 GMT')])
2025-10-16 08:39:41,043 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:39:41,044 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,045 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:41,046 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:41,047 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:41,047 [DEBUG] httpcore.connection: close.started
2025-10-16 08:39:41,047 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:39:41,393 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-e6cc0fd5-4a80-4d45-b7ce-cfd234d0e432', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:39:40\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-10 gim, cho thy trng thi thm d gia cung v cu. VDSC nh gi y l din bin bnh thng, v th trng cn thi gian  thu ht thm dng ti...\n\n[SHS t 1.379 t ng li nhun sau 9 th...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:39:41,394 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:39:41,395 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:39:41,517 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A7016D050>
2025-10-16 08:39:41,517 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000028A5250A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:39:41,587 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000028A5E9E7C50>
2025-10-16 08:39:41,588 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:39:41,590 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:39:41,590 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:39:41,592 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:39:41,592 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:39:48,030 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4335'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:39:41 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:39:48,031 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:39:48,032 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:39:48,033 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:39:48,033 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:39:48,034 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:39:48,034 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4335', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:39:41 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:39:48,035 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:39:48,043 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:39:48,044 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:39:48,045 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:39:48,045 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:39:48.045392
2025-10-16 08:46:25,664 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:46:26,557 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:46:27,092 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:46:27,728 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:46:27,733 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:46:28,486 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:28,488 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8147E3790>
2025-10-16 08:46:28,489 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,491 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:28,491 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,492 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:28,493 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,494 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:46:28 GMT')])
2025-10-16 08:46:28,495 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:46:28,497 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,497 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:28,498 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:28,499 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:28,500 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:28,500 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:28,501 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:28,503 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8148E9B50>
2025-10-16 08:46:28,503 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,507 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:28,508 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,510 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:28,510 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:46:28,512 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:46:28 GMT')])
2025-10-16 08:46:28,512 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:46:28,513 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:28,515 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:28,516 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:28,517 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:30,659 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:30,688 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:46:30,988 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:46:31,317 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:31,342 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:46:31,537 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:31,550 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F8164F5E90>
2025-10-16 08:46:31,551 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:31,552 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:31,554 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:31,557 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:31,558 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:46:31,560 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:46:31 GMT')])
2025-10-16 08:46:31,562 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:46:31,564 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:46:31,565 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:31,567 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:31,568 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:31,568 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:31,569 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:31,882 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,164 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,191 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:46:32,517 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,813 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:46:32,840 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:46:33,142 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:46:33,439 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:46:33,760 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:46:34,047 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:46:34,073 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:46:34,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:46:34,741 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:46:35,640 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:46:36,035 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:46:36,041 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:46:36,390 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:46:36,408 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:46:36,862 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:46:36,950 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:46:37,393 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:46:37,467 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:46:37,469 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:46:37,512 [DEBUG] matplotlib: interactive is False
2025-10-16 08:46:37,512 [DEBUG] matplotlib: platform is win32
2025-10-16 08:46:37,590 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:46:37,597 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:46:38,111 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:38,750 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:46:39,059 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:39,557 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:39,574 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:40,140 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:40,154 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:40,703 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:42,707 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:43,268 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:45,273 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:46:45,777 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:46:45,782 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:46:49,293 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:46:50,150 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:46:53,924 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:46:54,649 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:46:54,651 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82BF69850>
2025-10-16 08:46:54,651 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:54,653 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:54,654 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:54,655 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:54,656 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:46:54,660 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:46:54 GMT')])
2025-10-16 08:46:54,660 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:46:54,661 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:46:54,662 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:46:54,663 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:46:54,663 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:46:54,663 [DEBUG] httpcore.connection: close.started
2025-10-16 08:46:54,665 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:46:55,006 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-fed4eac3-267f-497c-9646-b3316354d85d', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:46:54\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-10 gim, cho thy trng thi thm d gia cung v cu. VDSC nh gi y l din bin bnh thng, v th trng cn thi gian  thu ht thm dng tin. VDSC d bo trong cc phin ti, VN- Index s...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:46:55,008 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:46:55,008 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:46:55,135 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82BE53850>
2025-10-16 08:46:55,136 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001F814F4A7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:46:55,210 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001F82C5C5010>
2025-10-16 08:46:55,212 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:46:55,213 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:46:55,213 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:46:55,214 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:46:55,215 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:47:01,638 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4610'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:46:54 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:47:01,640 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:47:01,640 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:47:01,641 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:47:01,642 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:47:01,643 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:47:01,643 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4610', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:46:54 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:47:01,645 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:47:01,662 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:47:01,662 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:47:01,664 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:47:01,664 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:47:01.664317
2025-10-16 08:49:42,380 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:49:43,327 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:49:43,996 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:49:44,743 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:49:44,747 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:49:45,524 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:45,529 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018670D48A10>
2025-10-16 08:49:45,530 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,531 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:45,534 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,535 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:49:45 GMT')])
2025-10-16 08:49:45,536 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:49:45,537 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,537 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:45,538 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:45,538 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:45,539 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:45,539 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:45,541 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:45,544 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000018670D4BE10>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,544 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:45,548 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:49:45,550 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:49:45 GMT')])
2025-10-16 08:49:45,552 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:49:45,552 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:49:45,552 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:45,555 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:45,555 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:45,556 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:45,557 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:47,731 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:47,758 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:49:48,067 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:49:48,409 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:48,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:49:48,635 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:49:48,635 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000186729132D0>
2025-10-16 08:49:48,635 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:49:48,640 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:49:48,641 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:49:48,646 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:49:48 GMT')])
2025-10-16 08:49:48,646 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:49:48,646 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:49:48,650 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:49:48,650 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:49:48,652 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:49:48,653 [DEBUG] httpcore.connection: close.started
2025-10-16 08:49:48,653 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:49:48,949 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,234 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,266 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:49:49,639 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,936 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:49:49,964 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:49:50,264 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:49:50,576 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:49:50,901 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:49:51,190 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:49:51,219 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:49:51,620 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:49:51,916 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:49:52,822 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:49:53,228 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:49:53,231 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:49:53,648 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:49:53,669 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:49:54,131 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:49:54,222 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:49:54,663 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:49:54,734 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:49:54,741 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:49:54,772 [DEBUG] matplotlib: interactive is False
2025-10-16 08:49:54,773 [DEBUG] matplotlib: platform is win32
2025-10-16 08:49:54,825 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:49:54,829 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:49:55,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:55,795 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:49:56,114 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:56,536 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:56,550 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:56,936 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:56,947 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:57,409 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:49:59,412 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:49:59,812 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:50:01,819 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:50:02,288 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:50:02,298 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:50:05,767 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:50:06,686 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:50:10,227 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:50:11,137 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:50:11,139 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860DCFAE90>
2025-10-16 08:50:11,140 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,142 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:50:11,142 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,144 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:50:11,144 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,147 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:50:10 GMT')])
2025-10-16 08:50:11,148 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:50:11,150 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,151 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:50:11,152 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:50:11,153 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:50:11,154 [DEBUG] httpcore.connection: close.started
2025-10-16 08:50:11,155 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:50:11,570 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1a625da5-02fd-4fc0-afdd-d831339b3e32', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:50:11\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-1...\n\n[SHS t 1.379 t ng li nhun sau 9 thng, hon thnh 100,7% k hoch nm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nv i tc chin lc. SHS t li nhun trc thu hn 1...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:50:11,570 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:50:11,570 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:50:11,708 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860E2B0E90>
2025-10-16 08:50:11,709 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000186713AA7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:50:11,768 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001860E2B2310>
2025-10-16 08:50:11,770 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:50:11,771 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:50:11,772 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:50:11,774 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:50:11,775 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:50:18,136 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4265'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:50:12 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:50:18,137 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:50:18,138 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:50:18,140 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:50:18,141 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:50:18,141 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:50:18,142 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4265', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:50:12 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:50:18,143 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:50:18,156 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:50:18,157 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:50:18,157 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:50:18,158 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:50:18.158917
2025-10-16 08:52:38,845 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:52:39,823 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:52:40,379 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:52:41,025 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:52:41,029 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:52:41,805 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:41,808 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983A7DD2D0>
2025-10-16 08:52:41,808 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,808 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:41,811 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,812 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:41,812 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:52:41 GMT')])
2025-10-16 08:52:41,815 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,815 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:41,819 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:41,820 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:41,821 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:41,825 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983A7DF110>
2025-10-16 08:52:41,826 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,828 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:41,829 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,830 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:41,832 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:52:41,832 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:52:41 GMT')])
2025-10-16 08:52:41,833 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:52:41,833 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:52:41,836 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:41,837 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:41,837 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:41,837 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:41,837 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:43,875 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:43,906 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:52:44,209 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:52:44,534 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:44,558 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:52:44,757 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:52:44,759 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001983C3A2B50>
2025-10-16 08:52:44,759 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:52:44,761 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:52:44,762 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:52:44,763 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:52:44,764 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:52:44,766 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 01:52:44 GMT')])
2025-10-16 08:52:44,766 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:52:44,766 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:52:44,771 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:52:44,771 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:52:44,772 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:52:44,772 [DEBUG] httpcore.connection: close.started
2025-10-16 08:52:44,775 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:52:45,090 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:45,389 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:52:45,417 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:52:45,738 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:46,028 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:52:46,058 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:52:46,353 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:52:46,648 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:52:46,971 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:52:47,256 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:52:47,283 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:52:47,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:52:47,946 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:52:48,854 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:52:49,247 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:52:49,251 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:52:49,615 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:52:49,640 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:52:50,132 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:52:50,224 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:52:50,693 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:52:50,774 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:52:50,785 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:52:50,842 [DEBUG] matplotlib: interactive is False
2025-10-16 08:52:50,843 [DEBUG] matplotlib: platform is win32
2025-10-16 08:52:50,921 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:52:50,924 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:52:51,420 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:51,860 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:52:52,174 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:52,603 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:52,615 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:53,054 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:53,064 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:53,513 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:55,516 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:55,896 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:57,901 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:52:58,292 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:52:58,299 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:53:01,736 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:53:03,425 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:53:06,834 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:53:07,576 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:53:07,589 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019846B29B50>
2025-10-16 08:53:07,590 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:53:07,592 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:53:07,592 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:53:07,594 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:53:07,595 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:53:07,597 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:53:07 GMT')])
2025-10-16 08:53:07,598 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:53:07,600 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:53:07,601 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:53:07,602 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:53:07,603 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:53:07,604 [DEBUG] httpcore.connection: close.started
2025-10-16 08:53:07,604 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:53:07,962 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-20e7fbe1-d6f1-47a4-a05b-99f22268dbc3', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:53:07\n\n        ### V d minh ha cch kt hp d liu gi & tin tc:\n        **D liu gi:**\n         VCB  Gi hin ti: 62,500 VN (-0.95%)\n\n        **Tin tc:**\n        VN-Index xut hin tn hiu to nh ngn hn, nhm chng khon bo l qu 3/2025.\n\n        **Tr li mu:**\n        Hm nay c phiu VCB gim 0.95%, din bin cng xu hng iu chnh chung ca th trng\n        khi VN-Index c tn hiu to nh ngn hn. Mt s thng tin tiu cc t nhm chng khon\n        gy p lc cht li, khin dng tin tr nn thn trng. Xu hng ngn hn: gim nh.\n        \n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-1...\n\n[SHS t 1.379 t ng li nhun sau 9 thng, hon thnh 100,7% k hoch nm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nv i tc chin lc. SHS t li nhun trc thu hn 1...\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:53:07,964 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:53:07,964 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:53:08,091 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019846B29B50>
2025-10-16 08:53:08,091 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001983AE3E7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:53:08,154 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000019858D4F5D0>
2025-10-16 08:53:08,154 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:53:08,154 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:53:08,159 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:53:08,159 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:53:08,160 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:53:14,520 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'4079'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:53:08 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:53:14,522 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:53:14,523 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:53:14,524 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:53:14,525 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:53:14,525 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:53:14,526 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '4079', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:53:08 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:53:14,526 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:53:14,534 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:53:14,535 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:53:14.535985
2025-10-16 08:56:27,871 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 08:56:28,801 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 08:56:29,334 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 08:56:29,982 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 08:56:29,986 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 08:56:30,854 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:30,857 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E622D5D0>
2025-10-16 08:56:30,858 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,860 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:30,861 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,862 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:30,863 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,864 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 01:56:30 GMT')])
2025-10-16 08:56:30,865 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 08:56:30,866 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,868 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:30,868 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:30,869 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:30,869 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:30,870 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:30,871 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:30,873 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E622D550>
2025-10-16 08:56:30,874 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,877 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:30,877 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,878 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:30,880 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 08:56:30,880 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:30 GMT')])
2025-10-16 08:56:30,881 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 08:56:30,883 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 08:56:30,883 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:30,884 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:30,885 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:30,886 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:30,886 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:33,103 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:33,133 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:56:33,416 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:56:33,727 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:33,755 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 08:56:33,968 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:33,968 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177E7E85150>
2025-10-16 08:56:33,968 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:33,976 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:33,977 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:33,977 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:33,980 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:56:33,984 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:33 GMT')])
2025-10-16 08:56:33,987 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 08:56:33,987 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:56:33,989 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:33,991 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:33,991 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:33,992 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:33,992 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:34,279 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:34,541 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 08:56:34,708 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 08:56:35,014 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:35,282 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 08:56:35,309 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 08:56:35,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 08:56:35,848 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 08:56:36,148 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:56:36,412 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 08:56:36,440 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 08:56:36,805 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 08:56:37,079 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 08:56:37,947 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:56:38,412 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:56:38,418 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 08:56:38,843 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 08:56:38,863 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:56:39,355 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 08:56:39,447 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 08:56:39,926 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 08:56:40,002 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 08:56:40,009 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 08:56:40,043 [DEBUG] matplotlib: interactive is False
2025-10-16 08:56:40,044 [DEBUG] matplotlib: platform is win32
2025-10-16 08:56:40,098 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 08:56:40,101 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 08:56:40,569 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:41,019 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 08:56:41,420 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:41,920 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:41,934 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:42,392 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:42,403 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:42,784 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:44,794 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:45,244 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:47,249 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 08:56:47,694 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 08:56:47,702 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:56:51,129 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:56:51,973 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 08:56:55,434 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 08:56:56,048 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 08:56:56,055 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001778CD771D0>
2025-10-16 08:56:56,055 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,058 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:56,062 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,066 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 01:56:55 GMT')])
2025-10-16 08:56:56,068 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 08:56:56,068 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,070 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:56:56,071 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:56:56,072 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:56:56,072 [DEBUG] httpcore.connection: close.started
2025-10-16 08:56:56,072 [DEBUG] httpcore.connection: close.complete
2025-10-16 08:56:56,374 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-01f49d29-49c4-48dc-9664-ad5bfd59f679', 'json_data': {'messages': [{'content': 'Bn l tr l AI ti chnh thng minh, tr li bng ting Vit, sc tch v chnh xc.', 'role': 'system'}, {'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-1...\n\n[SHS t 1.379 t ng li nhun sau 9 thng, hon thnh 100,7% k hoch nm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nv i tc chin lc. SHS t li nhun trc thu hn 1...\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 08:56:55\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}, {'content': '', 'role': 'assistant'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 1024, 'stream': False, 'temperature': 0.6}}
2025-10-16 08:56:56,374 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 08:56:56,377 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 08:56:56,499 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x00000177860D9210>
2025-10-16 08:56:56,499 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x00000177E688E7B0> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 08:56:56,576 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000017786549E50>
2025-10-16 08:56:56,577 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 08:56:56,578 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 08:56:56,578 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 08:56:56,580 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 08:56:56,580 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 08:57:00,969 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'3273'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 01:56:56 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 08:57:00,970 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 08:57:00,972 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 08:57:00,974 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 08:57:00,975 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 08:57:00,976 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 08:57:00,977 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '3273', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 01:56:56 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 08:57:00,978 [DEBUG] openai._base_client: request_id: None
2025-10-16 08:57:00,993 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 08:57:00,994 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 08:57:00,995 [DEBUG] RAGPipeline: intent: market
2025-10-16 08:57:00,996 [DEBUG] RAGPipeline: timestamp: 2025-10-16T08:57:00.995922
2025-10-16 09:04:57,123 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:04:58,039 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:04:58,621 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:04:59,350 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:04:59,355 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:05:00,252 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:00,255 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E2FD95D0>
2025-10-16 09:05:00,256 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,257 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:00,259 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,259 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:00,260 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,260 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:04:59 GMT')])
2025-10-16 09:05:00,262 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:05:00,263 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,263 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:00,265 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:00,265 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:00,266 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:00,267 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:00,268 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:00,269 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E4FCE810>
2025-10-16 09:05:00,271 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,272 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:00,273 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,274 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:00,275 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:05:00,275 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:04:59 GMT')])
2025-10-16 09:05:00,276 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:05:00,278 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:05:00,280 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:00,280 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:00,281 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:00,281 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:00,281 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:02,461 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:02,489 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:05:02,790 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:05:03,602 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:03,630 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:05:03,831 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:03,833 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E6BC6090>
2025-10-16 09:05:03,834 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:03,836 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:03,837 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:03,839 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:03,839 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:03,841 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:05:03 GMT')])
2025-10-16 09:05:03,842 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 09:05:03,843 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:03,846 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:03,847 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:03,848 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:03,848 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:03,849 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:04,149 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:04,428 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:05:04,460 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:05:04,814 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:05,107 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:05:05,135 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:05:05,425 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:05:05,789 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:05:06,104 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:05:06,404 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:05:06,433 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:05:06,800 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:05:07,101 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 09:05:07,988 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:05:08,413 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:05:08,417 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:05:08,847 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:05:08,869 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:05:09,338 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 09:05:09,427 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:05:09,917 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 09:05:09,999 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 09:05:10,006 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 09:05:10,044 [DEBUG] matplotlib: interactive is False
2025-10-16 09:05:10,046 [DEBUG] matplotlib: platform is win32
2025-10-16 09:05:10,104 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 09:05:10,109 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 09:05:10,627 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:11,217 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 09:05:11,644 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:12,140 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:12,151 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:12,644 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:12,653 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:13,157 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:15,160 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:15,776 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:17,781 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:05:18,300 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:05:18,306 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:05:21,579 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:05:22,441 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:05:25,924 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:05:26,882 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:05:26,885 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C9E4999B50>
2025-10-16 09:05:26,886 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:26,887 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:26,889 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:26,890 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:26,891 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:26,917 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:05:26 GMT')])
2025-10-16 09:05:26,917 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 09:05:26,917 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:26,919 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:26,921 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:26,921 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:26,922 [DEBUG] httpcore.connection: close.started
2025-10-16 09:05:26,922 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:05:27,330 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-1ebe878a-c22c-4dbc-a74c-7dedf4bdf2b7', 'json_data': {'messages': [{'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.8333, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-1...\n\n[SHS t 1.379 t ng li nhun sau 9 thng, hon thnh 100,7% k hoch nm 2025 | 15-10-2025 17:30:00] (score=0.6667, rerank=3.5696)\nv i tc chin lc. SHS t li nhun trc thu hn 1...\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 09:05:26\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.7}}
2025-10-16 09:05:27,332 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 09:05:27,333 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 09:05:27,459 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C987546C50>
2025-10-16 09:05:27,461 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x000001C9E562E720> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 09:05:27,534 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001C98CE69510>
2025-10-16 09:05:27,535 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:05:27,537 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:05:27,538 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:05:27,539 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:05:27,539 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:05:40,263 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'8165'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 02:05:27 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 09:05:40,263 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 09:05:40,263 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:05:40,269 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:05:40,269 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:05:40,271 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:05:40,271 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '8165', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 02:05:27 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 09:05:40,273 [DEBUG] openai._base_client: request_id: None
2025-10-16 09:05:40,286 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 09:05:40,287 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 09:05:40,288 [DEBUG] RAGPipeline: intent: market
2025-10-16 09:05:40,288 [DEBUG] RAGPipeline: timestamp: 2025-10-16T09:05:40.288757
2025-10-16 09:13:12,791 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:13:13,733 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:13:14,318 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:13:14,955 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:13:14,962 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:13:15,792 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:15,795 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002906145CFD0>
2025-10-16 09:13:15,795 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,797 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:13:15 GMT')])
2025-10-16 09:13:15,801 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:15,802 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:15,802 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:15,805 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:15,805 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:15,809 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002906145FFD0>
2025-10-16 09:13:15,810 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,812 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:15,812 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,813 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:15,814 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:13:15,814 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'date', b'Thu, 16 Oct 2025 02:13:15 GMT')])
2025-10-16 09:13:15,815 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:13:15,817 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:13:15,818 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:15,819 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:15,819 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:15,820 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:15,820 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:18,302 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:18,329 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:13:18,645 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:13:18,963 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:18,991 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:13:19,491 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:19,795 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:13:19,822 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:13:20,164 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:20,457 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:13:20,488 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:13:20,783 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:13:21,579 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:13:21,912 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:13:22,198 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:13:22,224 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:13:22,578 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:13:22,885 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
2025-10-16 09:13:23,795 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:13:24,188 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:13:24,188 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): hq.vnstocks.com:443
2025-10-16 09:13:24,599 [DEBUG] urllib3.connectionpool: https://hq.vnstocks.com:443 "POST /analytics HTTP/1.1" 502 166
2025-10-16 09:13:24,620 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:13:25,076 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnstock/json HTTP/1.1" 200 28728
2025-10-16 09:13:25,157 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): pypi.org:443
2025-10-16 09:13:25,643 [DEBUG] urllib3.connectionpool: https://pypi.org:443 "GET /pypi/vnai/json HTTP/1.1" 200 2087
2025-10-16 09:13:25,712 [DEBUG] matplotlib: matplotlib data path: c:\Users\admin\AppData\Local\Programs\Python\Python311\Lib\site-packages\matplotlib\mpl-data
2025-10-16 09:13:25,720 [DEBUG] matplotlib: CONFIGDIR=C:\Users\admin\.matplotlib
2025-10-16 09:13:25,751 [DEBUG] matplotlib: interactive is False
2025-10-16 09:13:25,752 [DEBUG] matplotlib: platform is win32
2025-10-16 09:13:25,805 [DEBUG] matplotlib: CACHEDIR=C:\Users\admin\.matplotlib
2025-10-16 09:13:25,813 [DEBUG] matplotlib.font_manager: Using fontManager instance from C:\Users\admin\.matplotlib\fontlist-v390.json
2025-10-16 09:13:26,276 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:26,845 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "GET /api//price/symbols/getAll HTTP/1.1" 200 None
2025-10-16 09:13:27,242 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:27,693 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:27,709 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:28,163 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:28,174 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:28,817 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:30,820 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:31,274 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:33,279 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): trading.vietcap.com.vn:443
2025-10-16 09:13:33,738 [DEBUG] urllib3.connectionpool: https://trading.vietcap.com.vn:443 "POST /api/chart/OHLCChart/gap HTTP/1.1" 200 None
2025-10-16 09:13:33,745 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:13:37,201 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:13:38,154 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): apipubaws.tcbs.com.vn:443
2025-10-16 09:13:41,396 [DEBUG] urllib3.connectionpool: https://apipubaws.tcbs.com.vn:443 "POST /ligo/v1/watchlist/preview HTTP/1.1" 200 None
2025-10-16 09:13:42,231 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:13:42,234 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002900AB66AD0>
2025-10-16 09:13:42,235 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,237 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:42,238 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,239 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:42,240 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,242 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-encoding', b'br'), (b'content-type', b'application/json'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:13:41 GMT')])
2025-10-16 09:13:42,243 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/query "HTTP/1.1 200 OK"
2025-10-16 09:13:42,244 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,246 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:42,247 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:42,248 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:42,249 [DEBUG] httpcore.connection: close.started
2025-10-16 09:13:42,251 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:13:42,602 [DEBUG] openai._base_client: Request options: {'method': 'post', 'url': '/chat/completions', 'headers': {'X-Stainless-Raw-Response': 'true'}, 'files': None, 'idempotency_key': 'stainless-python-retry-d0c3de4e-6405-4e73-b56f-2e51965f3461', 'json_data': {'messages': [{'content': "- Lun tr li bng TING VIT nu c t ng chuyn ngnh (VNINDEX, VN30,..) th gi nguyn.\n\n## Instruction:\nBn l **tr l AI ti chnh Vit Nam**, chuyn phn tch xu hng th trng, c phiu v tin tc.\n1. Khi intent = 'market' th KT HP d liu API (gi c phiu, th trng) vi tin tc (Context).\n2. Khi intent = 'stock' th Trnh by thng tin gi c phiu ngn gn.\n3. KHNG khuyn ngh u t tuyt i.\n## Constraints:\n- Lun tr li bng TING VIT, ngn gn, t nhin.\n- KHNG dng m code, KHNG in cu trc JSON.\n- KHNG ni Ti khng phi chuyn gia ti chnh.\n- Gi nguyn cc k hiu nh VNINDEX, VCB, VN30,...\n## Bi cnh thi gian:\nHm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.\n\n\n## Retrieved Context:\nDi y l cc tin tc gn nht, hy u tin s dng chng  phn tch th trng:\n\n[Tin tc cp nhp n: Hm nay l Th Nm, Ngy 16 thng 10 nm 2025.\nNgy hm qua l Ngy 15 thng 10 nm 2025.\nNgy mai l Ngy 17 thng 10 nm 2025.\nTun sau s bt u t Ngy 23 thng 10 nm 2025.\nTun trc bt u t Ngy 09 thng 10 nm 2025.]\n\n[Chng khon ngy 16-10: C phiu ngn hng, bt ng sn dn dt dng tin? | 15-10-2025 22:47:00] (score=0.75, rerank=5.4403)\nDIG, NVL c mc tng gi ng ch . Kt thc phin giao dch, VN- Index ng ca ti 1.757 im, gim 3 im (tng ng 0,18%) Theo nhn nh ca Cng ty Chng khon VCBS, VN-Index ang trong giai on cng c ng lc quanh vng 1.750-1.780 im. S phn ha gia cc nhm c phiu blue-chip cho thy th trng ang iu chnh sau t tng gi mnh trc . VCBS khuyn ngh nh u t cn nhc cht li ngn hn i vi cc m  t mc tiu hoc c tn hiu o chiu, ng thi duy tr t trng  cc m vn gi xu hng tng. Trong khi , Cng ty Chng khon Rng Vit (VDSC) cho bit thanh khon phin 15-10 ...\n\n[SHS t 1.379 t ng li nhun sau 9 thng, hon thnh 100,7% k hoch nm 2025 | 15-10-2025 17:30:00] (score=0.5455, rerank=4.3467)\nLi nhun trc thu Qu 3 gp 8 ln cng k, hon thnh ...\n## D liu API:\n **TNG QUAN TH TRNG VIT NAM**  \n **VNINDEX**: 1,757.95 im (-3.11, -0.18%)  \n **VN30**: 2,009.64 im (-4.05, -0.20%)  \n\n **Top c phiu tng mnh**  \n BTH (172247.81%)  \n TCO (11900.59%)  \n VNI (8736.93%)  \n\n **Top c phiu gim mnh**  \n PTC (-99.96%)  \n TOP (-99.67%)  \n HTP (-98.51%)  \n Cp nht: 16-10-2025 09:13:42\n## Task Type:\nIntent: market\nM t: Phn tch xu hng c phiu hoc th trng bng cch kt hp d liu API v tin tc gn nht.\n\n## Task Input:\n**User:** Th trng chng khon hm qua c g bin ng?\n\n\n## Task Output:\n\n**Assistant:**", 'role': 'system'}, {'content': 'Th trng chng khon hm qua c g bin ng?', 'role': 'user'}], 'model': 'qwen3-30b-thinking', 'max_completion_tokens': 2048, 'stream': False, 'temperature': 0.7}}
2025-10-16 09:13:42,604 [DEBUG] openai._base_client: Sending HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions
2025-10-16 09:13:42,605 [DEBUG] httpcore.connection: connect_tcp.started host='nonomissible-winfred-doggedly.ngrok-free.dev' port=443 local_address=None timeout=None socket_options=None
2025-10-16 09:13:42,779 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000002900AB65310>
2025-10-16 09:13:42,781 [DEBUG] httpcore.connection: start_tls.started ssl_context=<ssl.SSLContext object at 0x0000029061AC2570> server_hostname='nonomissible-winfred-doggedly.ngrok-free.dev' timeout=None
2025-10-16 09:13:42,857 [DEBUG] httpcore.connection: start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x0000029006254C10>
2025-10-16 09:13:42,859 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:13:42,860 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:13:42,860 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:13:42,862 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:13:42,862 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:13:55,471 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Length', b'7630'), (b'Content-Type', b'application/json'), (b'Date', b'Thu, 16 Oct 2025 02:13:42 GMT'), (b'Ngrok-Agent-Ips', b'117.2.56.232'), (b'Server', b'uvicorn')])
2025-10-16 09:13:55,473 [INFO] httpx: HTTP Request: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "HTTP/1.1 200 OK"
2025-10-16 09:13:55,473 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:13:55,518 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:13:55,519 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:13:55,520 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:13:55,521 [DEBUG] openai._base_client: HTTP Response: POST https://nonomissible-winfred-doggedly.ngrok-free.dev/v1/chat/completions "200 OK" Headers({'content-length': '7630', 'content-type': 'application/json', 'date': 'Thu, 16 Oct 2025 02:13:42 GMT', 'ngrok-agent-ips': '117.2.56.232', 'server': 'uvicorn'})
2025-10-16 09:13:55,522 [DEBUG] openai._base_client: request_id: None
2025-10-16 09:13:55,533 [DEBUG] RAGPipeline: llm_status: response_generated
2025-10-16 09:13:55,534 [DEBUG] RAGPipeline: route: hybrid
2025-10-16 09:13:55,535 [DEBUG] RAGPipeline: intent: market
2025-10-16 09:13:55,535 [DEBUG] RAGPipeline: timestamp: 2025-10-16T09:13:55.535459
2025-10-16 09:15:32,725 [DEBUG] torchao: Skipping import of cpp extensions: Could not find libtorchao_ops_aten library in any of the provided paths
2025-10-16 09:15:33,639 [INFO] datasets: PyTorch version 2.8.0+cu128 available.
2025-10-16 09:15:34,205 [DEBUG] urllib3.connectionpool: Starting new HTTPS connection (1): huggingface.co:443
2025-10-16 09:15:34,858 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/whoami-v2 HTTP/1.1" 200 378
2025-10-16 09:15:34,860 [WARNING] huggingface_hub._login: Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
2025-10-16 09:15:35,667 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:35,670 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451B4ED690>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,670 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:35,675 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,675 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:15:35 GMT')])
2025-10-16 09:15:35,677 [INFO] httpx: HTTP Request: GET http://localhost:6333 "HTTP/1.1 200 OK"
2025-10-16 09:15:35,677 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,678 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:35,679 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:35,680 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:35,680 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:35,681 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:35,683 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:35,685 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451B4ED750>
2025-10-16 09:15:35,686 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,688 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:35,689 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,690 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:35,691 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'GET']>
2025-10-16 09:15:35,692 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'date', b'Thu, 16 Oct 2025 02:15:35 GMT')])
2025-10-16 09:15:35,693 [INFO] httpx: HTTP Request: GET http://localhost:6333/collections "HTTP/1.1 200 OK"
2025-10-16 09:15:35,694 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'GET']>
2025-10-16 09:15:35,695 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:35,696 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:35,696 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:35,697 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:35,697 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:37,758 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:37,784 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:15:38,157 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:15:38,484 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:38,513 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json HTTP/1.1" 200 0
2025-10-16 09:15:38,693 [DEBUG] httpcore.connection: connect_tcp.started host='localhost' port=6333 local_address=None timeout=5.0 socket_options=None
2025-10-16 09:15:38,697 [DEBUG] httpcore.connection: connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x000001451D146D10>
2025-10-16 09:15:38,698 [DEBUG] httpcore.http11: send_request_headers.started request=<Request [b'POST']>
2025-10-16 09:15:38,699 [DEBUG] httpcore.http11: send_request_headers.complete
2025-10-16 09:15:38,699 [DEBUG] httpcore.http11: send_request_body.started request=<Request [b'POST']>
2025-10-16 09:15:38,700 [DEBUG] httpcore.http11: send_request_body.complete
2025-10-16 09:15:38,701 [DEBUG] httpcore.http11: receive_response_headers.started request=<Request [b'POST']>
2025-10-16 09:15:38,704 [DEBUG] httpcore.http11: receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'transfer-encoding', b'chunked'), (b'content-type', b'application/json'), (b'content-encoding', b'br'), (b'vary', b'accept-encoding, Origin, Access-Control-Request-Method, Access-Control-Request-Headers'), (b'date', b'Thu, 16 Oct 2025 02:15:38 GMT')])
2025-10-16 09:15:38,704 [INFO] httpx: HTTP Request: POST http://localhost:6333/collections/cafef_articles/points/scroll "HTTP/1.1 200 OK"
2025-10-16 09:15:38,704 [DEBUG] httpcore.http11: receive_response_body.started request=<Request [b'POST']>
2025-10-16 09:15:38,711 [DEBUG] httpcore.http11: receive_response_body.complete
2025-10-16 09:15:38,712 [DEBUG] httpcore.http11: response_closed.started
2025-10-16 09:15:38,713 [DEBUG] httpcore.http11: response_closed.complete
2025-10-16 09:15:38,714 [DEBUG] httpcore.connection: close.started
2025-10-16 09:15:38,714 [DEBUG] httpcore.connection: close.complete
2025-10-16 09:15:39,019 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,304 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,331 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/config.json HTTP/1.1" 200 0
2025-10-16 09:15:39,654 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,940 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/tokenizer_config.json HTTP/1.1" 307 0
2025-10-16 09:15:39,967 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/tokenizer_config.json HTTP/1.1" 200 0
2025-10-16 09:15:40,253 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 307 147
2025-10-16 09:15:40,545 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1" 404 64
2025-10-16 09:15:40,856 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L-6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:15:41,147 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /cross-encoder/ms-marco-MiniLM-L6-v2/resolve/main/README.md HTTP/1.1" 307 0
2025-10-16 09:15:41,175 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "HEAD /api/resolve-cache/models/cross-encoder/ms-marco-MiniLM-L6-v2/c5ee24cb16019beea0893ab7796b1df96625c6b8/README.md HTTP/1.1" 200 0
2025-10-16 09:15:41,531 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L-6-v2 HTTP/1.1" 307 82
2025-10-16 09:15:41,836 [DEBUG] urllib3.connectionpool: https://huggingface.co:443 "GET /api/models/cross-encoder/ms-marco-MiniLM-L6-v2 HTTP/1.1" 200 5263
